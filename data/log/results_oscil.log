OPTION: 'compare' = 'aixi_uniform_random'
OPTION: 'profile' = 'False'
OPTION: 'ct-depth' = '30'
OPTION: 'learning-period' = '500'
OPTION: 'terminate-age' = '1000'
OPTION: 'verbose' = 'True'
OPTION: 'exploration' = '1'
OPTION: 'environment' = 'oscillator'
OPTION: 'mc-simulations' = '10'
OPTION: 'oscillator-delay' = '1'
OPTION: 'agent-horizon' = '5'
OPTION: 'agent' = 'mc_aixi_ctw'
OPTION: 'non-learning-only' = 'False'
OPTION: 'explore-decay' = '1'
OPTION: 'random-seed' = '0'
cycle, observation, reward, action, explored, explore_rate, total reward, average reward, time, model size
Agent is trying an action at random...
A: 1, 0, 0, 1, True, 1.000000, 0, 0.000000 (stdev 0.000000), 0:00:00, 3
B: 1, 0, 0, 0, True, 1.000000, 0, 0.000000 (stdev 0.000000), 0:00:00, 0
A: cycle: 1
average reward: 0.000000 (stdev 0.000000)
B: cycle: 1
average reward: 0.000000 (stdev 0.000000)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 2, 1, 1, 1, True, 1.000000, 1, 0.500000 (stdev 0.000000), 0:00:00, 6
B: 2, 1, 0, 0, True, 1.000000, 0, 0.000000 (stdev 0.000000), 0:00:00, 0
A: cycle: 2
average reward: 0.500000 (stdev 0.000000)
B: cycle: 2
average reward: 0.000000 (stdev 0.000000)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 3, 0, 0, 0, True, 1.000000, 1, 0.333333 (stdev 0.408248), 0:00:00, 9
B: 3, 0, 1, 0, True, 1.000000, 1, 0.333333 (stdev 0.000000), 0:00:00, 0
A: cycle: 3
average reward: 0.333333 (stdev 0.408248)
B: cycle: 3
average reward: 0.333333 (stdev 0.000000)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 4, 1, 0, 1, True, 1.000000, 1, 0.250000 (stdev 0.408248), 0:00:00, 12
B: 4, 1, 0, 1, True, 1.000000, 1, 0.250000 (stdev 0.408248), 0:00:00, 0
A: cycle: 4
average reward: 0.250000 (stdev 0.408248)
B: cycle: 4
average reward: 0.250000 (stdev 0.408248)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 5, 0, 0, 1, True, 1.000000, 1, 0.200000 (stdev 0.387298), 0:00:00, 15
B: 5, 0, 0, 1, True, 1.000000, 1, 0.200000 (stdev 0.387298), 0:00:00, 0
A: cycle: 5
average reward: 0.200000 (stdev 0.387298)
B: cycle: 5
average reward: 0.200000 (stdev 0.387298)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 6, 1, 1, 1, True, 1.000000, 2, 0.333333 (stdev 0.365148), 0:00:00, 18
B: 6, 1, 1, 1, True, 1.000000, 2, 0.333333 (stdev 0.365148), 0:00:00, 0
A: cycle: 6
average reward: 0.333333 (stdev 0.365148)
B: cycle: 6
average reward: 0.333333 (stdev 0.365148)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 7, 0, 0, 1, True, 1.000000, 2, 0.285714 (stdev 0.436436), 0:00:00, 21
B: 7, 0, 0, 0, True, 1.000000, 2, 0.285714 (stdev 0.436436), 0:00:00, 0
A: cycle: 7
average reward: 0.285714 (stdev 0.436436)
B: cycle: 7
average reward: 0.285714 (stdev 0.436436)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 8, 1, 1, 1, True, 1.000000, 3, 0.375000 (stdev 0.422577), 0:00:00, 24
B: 8, 1, 0, 1, True, 1.000000, 2, 0.250000 (stdev 0.422577), 0:00:00, 0
A: cycle: 8
average reward: 0.375000 (stdev 0.422577)
B: cycle: 8
average reward: 0.250000 (stdev 0.422577)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 9, 0, 0, 0, True, 1.000000, 3, 0.333333 (stdev 0.456435), 0:00:00, 27
B: 9, 0, 0, 0, True, 1.000000, 2, 0.222222 (stdev 0.408248), 0:00:00, 0
A: cycle: 9
average reward: 0.333333 (stdev 0.456435)
B: cycle: 9
average reward: 0.222222 (stdev 0.408248)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 10, 1, 0, 1, True, 1.000000, 3, 0.300000 (stdev 0.447214), 0:00:00, 30
B: 10, 1, 0, 1, True, 1.000000, 2, 0.200000 (stdev 0.394405), 0:00:00, 0
A: cycle: 10
average reward: 0.300000 (stdev 0.447214)
B: cycle: 10
average reward: 0.200000 (stdev 0.394405)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 11, 0, 0, 1, True, 1.000000, 3, 0.272727 (stdev 0.436931), 0:00:00, 33
B: 11, 0, 0, 0, True, 1.000000, 2, 0.181818 (stdev 0.381385), 0:00:00, 0
A: cycle: 11
average reward: 0.272727 (stdev 0.436931)
B: cycle: 11
average reward: 0.181818 (stdev 0.381385)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 12, 1, 1, 1, True, 1.000000, 4, 0.333333 (stdev 0.426401), 0:00:00, 36
B: 12, 1, 0, 0, True, 1.000000, 2, 0.166667 (stdev 0.369274), 0:00:00, 0
A: cycle: 12
average reward: 0.333333 (stdev 0.426401)
B: cycle: 12
average reward: 0.166667 (stdev 0.369274)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 13, 0, 0, 0, True, 1.000000, 4, 0.307692 (stdev 0.452911), 0:00:00, 39
B: 13, 0, 1, 1, True, 1.000000, 3, 0.230769 (stdev 0.358057), 0:00:00, 0
A: cycle: 13
average reward: 0.307692 (stdev 0.452911)
B: cycle: 13
average reward: 0.230769 (stdev 0.358057)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 14, 1, 0, 0, True, 1.000000, 4, 0.285714 (stdev 0.444750), 0:00:00, 42
B: 14, 1, 1, 0, True, 1.000000, 4, 0.285714 (stdev 0.405999), 0:00:00, 0
A: cycle: 14
average reward: 0.285714 (stdev 0.444750)
B: cycle: 14
average reward: 0.285714 (stdev 0.405999)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 15, 0, 1, 0, True, 1.000000, 5, 0.333333 (stdev 0.436436), 0:00:00, 45
B: 15, 0, 1, 0, True, 1.000000, 5, 0.333333 (stdev 0.436436), 0:00:00, 0
A: cycle: 15
average reward: 0.333333 (stdev 0.436436)
B: cycle: 15
average reward: 0.333333 (stdev 0.436436)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 16, 1, 0, 0, True, 1.000000, 5, 0.312500 (stdev 0.456435), 0:00:00, 48
B: 16, 1, 0, 1, True, 1.000000, 5, 0.312500 (stdev 0.456435), 0:00:00, 0
A: cycle: 16
average reward: 0.312500 (stdev 0.456435)
B: cycle: 16
average reward: 0.312500 (stdev 0.456435)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 17, 0, 1, 1, True, 1.000000, 6, 0.352941 (stdev 0.449673), 0:00:00, 51
B: 17, 0, 0, 1, True, 1.000000, 5, 0.294118 (stdev 0.449673), 0:00:00, 0
A: cycle: 17
average reward: 0.352941 (stdev 0.449673)
B: cycle: 17
average reward: 0.294118 (stdev 0.449673)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 18, 1, 1, 0, True, 1.000000, 7, 0.388889 (stdev 0.464420), 0:00:00, 54
B: 18, 1, 1, 0, True, 1.000000, 6, 0.333333 (stdev 0.442807), 0:00:00, 0
A: cycle: 18
average reward: 0.388889 (stdev 0.464420)
B: cycle: 18
average reward: 0.333333 (stdev 0.442807)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 19, 0, 1, 1, True, 1.000000, 8, 0.421053 (stdev 0.474496), 0:00:00, 57
B: 19, 0, 1, 0, True, 1.000000, 7, 0.368421 (stdev 0.458831), 0:00:00, 0
A: cycle: 19
average reward: 0.421053 (stdev 0.474496)
B: cycle: 19
average reward: 0.368421 (stdev 0.458831)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 20, 1, 1, 1, True, 1.000000, 9, 0.450000 (stdev 0.481227), 0:00:00, 60
B: 20, 1, 0, 1, True, 1.000000, 7, 0.350000 (stdev 0.470162), 0:00:00, 0
A: cycle: 20
average reward: 0.450000 (stdev 0.481227)
B: cycle: 20
average reward: 0.350000 (stdev 0.470162)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 21, 0, 0, 1, True, 1.000000, 9, 0.428571 (stdev 0.485504), 0:00:00, 63
B: 21, 0, 0, 1, True, 1.000000, 7, 0.333333 (stdev 0.465475), 0:00:00, 0
A: cycle: 21
average reward: 0.428571 (stdev 0.485504)
B: cycle: 21
average reward: 0.333333 (stdev 0.465475)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 22, 1, 1, 1, True, 1.000000, 10, 0.454545 (stdev 0.483494), 0:00:00, 66
B: 22, 1, 1, 0, True, 1.000000, 8, 0.363636 (stdev 0.460566), 0:00:00, 0
A: cycle: 22
average reward: 0.454545 (stdev 0.483494)
B: cycle: 22
average reward: 0.363636 (stdev 0.460566)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 23, 0, 0, 0, True, 1.000000, 10, 0.434783 (stdev 0.486985), 0:00:00, 69
B: 23, 0, 1, 1, True, 1.000000, 9, 0.391304 (stdev 0.470472), 0:00:00, 0
A: cycle: 23
average reward: 0.434783 (stdev 0.486985)
B: cycle: 23
average reward: 0.391304 (stdev 0.470472)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 24, 1, 0, 0, True, 1.000000, 10, 0.416667 (stdev 0.485291), 0:00:00, 72
B: 24, 1, 1, 0, True, 1.000000, 10, 0.416667 (stdev 0.477767), 0:00:00, 0
A: cycle: 24
average reward: 0.416667 (stdev 0.485291)
B: cycle: 24
average reward: 0.416667 (stdev 0.477767)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 25, 0, 1, 1, True, 1.000000, 11, 0.440000 (stdev 0.483046), 0:00:00, 75
B: 25, 0, 1, 0, True, 1.000000, 11, 0.440000 (stdev 0.483046), 0:00:00, 0
A: cycle: 25
average reward: 0.440000 (stdev 0.483046)
B: cycle: 25
average reward: 0.440000 (stdev 0.483046)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 26, 1, 1, 1, True, 1.000000, 12, 0.461538 (stdev 0.486747), 0:00:00, 78
B: 26, 1, 0, 1, True, 1.000000, 11, 0.423077 (stdev 0.486747), 0:00:00, 0
A: cycle: 26
average reward: 0.461538 (stdev 0.486747)
B: cycle: 26
average reward: 0.423077 (stdev 0.486747)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 27, 0, 0, 1, True, 1.000000, 12, 0.444444 (stdev 0.489200), 0:00:00, 81
B: 27, 0, 0, 1, True, 1.000000, 11, 0.407407 (stdev 0.484812), 0:00:00, 0
A: cycle: 27
average reward: 0.444444 (stdev 0.489200)
B: cycle: 27
average reward: 0.407407 (stdev 0.484812)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 28, 1, 1, 1, True, 1.000000, 13, 0.464286 (stdev 0.487950), 0:00:00, 84
B: 28, 1, 1, 0, True, 1.000000, 12, 0.428571 (stdev 0.482498), 0:00:00, 0
A: cycle: 28
average reward: 0.464286 (stdev 0.487950)
B: cycle: 28
average reward: 0.428571 (stdev 0.482498)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 29, 0, 0, 0, True, 1.000000, 13, 0.448276 (stdev 0.490049), 0:00:00, 87
B: 29, 0, 1, 1, True, 1.000000, 13, 0.448276 (stdev 0.486265), 0:00:00, 0
A: cycle: 29
average reward: 0.448276 (stdev 0.490049)
B: cycle: 29
average reward: 0.448276 (stdev 0.486265)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 30, 1, 0, 1, True, 1.000000, 13, 0.433333 (stdev 0.488959), 0:00:00, 90
B: 30, 1, 1, 1, True, 1.000000, 14, 0.466667 (stdev 0.488959), 0:00:00, 0
A: cycle: 30
average reward: 0.433333 (stdev 0.488959)
B: cycle: 30
average reward: 0.466667 (stdev 0.488959)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 31, 0, 0, 1, True, 1.000000, 13, 0.419355 (stdev 0.487478), 0:00:00, 93
B: 31, 0, 0, 0, True, 1.000000, 14, 0.451613 (stdev 0.490775), 0:00:00, 0
A: cycle: 31
average reward: 0.419355 (stdev 0.487478)
B: cycle: 31
average reward: 0.451613 (stdev 0.490775)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 32, 1, 1, 1, True, 1.000000, 14, 0.437500 (stdev 0.485682), 0:00:00, 96
B: 32, 1, 0, 1, True, 1.000000, 14, 0.437500 (stdev 0.489816), 0:00:00, 0
A: cycle: 32
average reward: 0.437500 (stdev 0.485682)
B: cycle: 32
average reward: 0.437500 (stdev 0.489816)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 33, 0, 0, 0, True, 1.000000, 14, 0.424242 (stdev 0.488504), 0:00:00, 99
B: 33, 0, 0, 1, True, 1.000000, 14, 0.424242 (stdev 0.488504), 0:00:00, 0
A: cycle: 33
average reward: 0.424242 (stdev 0.488504)
B: cycle: 33
average reward: 0.424242 (stdev 0.488504)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 34, 1, 0, 1, True, 1.000000, 14, 0.411765 (stdev 0.486905), 0:00:00, 102
B: 34, 1, 1, 1, True, 1.000000, 15, 0.441176 (stdev 0.486905), 0:00:00, 0
A: cycle: 34
average reward: 0.411765 (stdev 0.486905)
B: cycle: 34
average reward: 0.441176 (stdev 0.486905)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 35, 0, 0, 1, True, 1.000000, 14, 0.400000 (stdev 0.485071), 0:00:00, 105
B: 35, 0, 0, 0, True, 1.000000, 15, 0.428571 (stdev 0.489383), 0:00:00, 0
A: cycle: 35
average reward: 0.400000 (stdev 0.485071)
B: cycle: 35
average reward: 0.428571 (stdev 0.489383)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 36, 1, 1, 1, True, 1.000000, 15, 0.416667 (stdev 0.483046), 0:00:00, 108
B: 36, 1, 0, 0, True, 1.000000, 15, 0.416667 (stdev 0.487950), 0:00:00, 0
A: cycle: 36
average reward: 0.416667 (stdev 0.483046)
B: cycle: 36
average reward: 0.416667 (stdev 0.487950)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 37, 0, 0, 0, True, 1.000000, 15, 0.405405 (stdev 0.486299), 0:00:00, 111
B: 37, 0, 1, 0, True, 1.000000, 16, 0.432432 (stdev 0.486299), 0:00:00, 0
A: cycle: 37
average reward: 0.405405 (stdev 0.486299)
B: cycle: 37
average reward: 0.432432 (stdev 0.486299)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 38, 1, 0, 0, True, 1.000000, 15, 0.394737 (stdev 0.484467), 0:00:00, 114
B: 38, 1, 0, 1, True, 1.000000, 16, 0.421053 (stdev 0.488852), 0:00:00, 0
A: cycle: 38
average reward: 0.394737 (stdev 0.484467)
B: cycle: 38
average reward: 0.421053 (stdev 0.488852)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 39, 0, 1, 1, True, 1.000000, 16, 0.410256 (stdev 0.482487), 0:00:00, 117
B: 39, 0, 0, 1, True, 1.000000, 16, 0.410256 (stdev 0.487357), 0:00:00, 0
A: cycle: 39
average reward: 0.410256 (stdev 0.482487)
B: cycle: 39
average reward: 0.410256 (stdev 0.487357)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 40, 1, 1, 1, True, 1.000000, 17, 0.425000 (stdev 0.485693), 0:00:00, 120
B: 40, 1, 1, 1, True, 1.000000, 17, 0.425000 (stdev 0.485693), 0:00:00, 0
A: cycle: 40
average reward: 0.425000 (stdev 0.485693)
B: cycle: 40
average reward: 0.425000 (stdev 0.485693)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 41, 0, 0, 0, True, 1.000000, 17, 0.414634 (stdev 0.488277), 0:00:00, 123
B: 41, 0, 0, 0, True, 1.000000, 17, 0.414634 (stdev 0.488277), 0:00:00, 0
A: cycle: 41
average reward: 0.414634 (stdev 0.488277)
B: cycle: 41
average reward: 0.414634 (stdev 0.488277)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 42, 1, 0, 0, True, 1.000000, 17, 0.404762 (stdev 0.486758), 0:00:00, 126
B: 42, 1, 0, 0, True, 1.000000, 17, 0.404762 (stdev 0.486758), 0:00:00, 0
A: cycle: 42
average reward: 0.404762 (stdev 0.486758)
B: cycle: 42
average reward: 0.404762 (stdev 0.486758)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 43, 0, 1, 0, True, 1.000000, 18, 0.418605 (stdev 0.485105), 0:00:00, 129
B: 43, 0, 1, 0, True, 1.000000, 18, 0.418605 (stdev 0.485105), 0:00:00, 0
A: cycle: 43
average reward: 0.418605 (stdev 0.485105)
B: cycle: 43
average reward: 0.418605 (stdev 0.485105)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 44, 1, 0, 1, True, 1.000000, 18, 0.409091 (stdev 0.487692), 0:00:00, 132
B: 44, 1, 0, 1, True, 1.000000, 18, 0.409091 (stdev 0.487692), 0:00:00, 0
A: cycle: 44
average reward: 0.409091 (stdev 0.487692)
B: cycle: 44
average reward: 0.409091 (stdev 0.487692)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 45, 0, 0, 0, True, 1.000000, 18, 0.400000 (stdev 0.486172), 0:00:00, 135
B: 45, 0, 0, 0, True, 1.000000, 18, 0.400000 (stdev 0.486172), 0:00:00, 0
A: cycle: 45
average reward: 0.400000 (stdev 0.486172)
B: cycle: 45
average reward: 0.400000 (stdev 0.486172)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 46, 1, 0, 0, True, 1.000000, 18, 0.391304 (stdev 0.484544), 0:00:00, 138
B: 46, 1, 0, 1, True, 1.000000, 18, 0.391304 (stdev 0.484544), 0:00:00, 0
A: cycle: 46
average reward: 0.391304 (stdev 0.484544)
B: cycle: 46
average reward: 0.391304 (stdev 0.484544)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 47, 0, 1, 0, True, 1.000000, 19, 0.404255 (stdev 0.482822), 0:00:00, 141
B: 47, 0, 0, 1, True, 1.000000, 18, 0.382979 (stdev 0.482822), 0:00:00, 0
A: cycle: 47
average reward: 0.404255 (stdev 0.482822)
B: cycle: 47
average reward: 0.382979 (stdev 0.482822)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 48, 1, 0, 0, True, 1.000000, 19, 0.395833 (stdev 0.485608), 0:00:00.015625, 144
B: 48, 1, 1, 1, True, 1.000000, 19, 0.395833 (stdev 0.481023), 0:00:00, 0
A: cycle: 48
average reward: 0.395833 (stdev 0.485608)
B: cycle: 48
average reward: 0.395833 (stdev 0.481023)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 49, 0, 1, 0, True, 1.000000, 20, 0.408163 (stdev 0.484013), 0:00:00, 147
B: 49, 0, 0, 1, True, 1.000000, 19, 0.387755 (stdev 0.484013), 0:00:00, 0
A: cycle: 49
average reward: 0.408163 (stdev 0.484013)
B: cycle: 49
average reward: 0.387755 (stdev 0.484013)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 50, 1, 0, 1, True, 1.000000, 20, 0.400000 (stdev 0.486554), 0:00:00, 150
B: 50, 1, 1, 0, True, 1.000000, 20, 0.400000 (stdev 0.482341), 0:00:00, 0
A: cycle: 50
average reward: 0.400000 (stdev 0.486554)
B: cycle: 50
average reward: 0.400000 (stdev 0.482341)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1



explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 51, 0, 0, 1, True, 1.000000, 20, 0.392157 (stdev 0.485071), 0:00:00, 153
B: 51, 0, 1, 0, True, 1.000000, 21, 0.411765 (stdev 0.485071), 0:00:00, 0
A: cycle: 51
average reward: 0.392157 (stdev 0.485071)
B: cycle: 51
average reward: 0.411765 (stdev 0.485071)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 52, 1, 1, 1, True, 1.000000, 21, 0.403846 (stdev 0.483514), 0:00:00, 156
B: 52, 1, 0, 0, True, 1.000000, 21, 0.403846 (stdev 0.487398), 0:00:00, 0
A: cycle: 52
average reward: 0.403846 (stdev 0.483514)
B: cycle: 52
average reward: 0.403846 (stdev 0.487398)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 53, 0, 0, 1, True, 1.000000, 21, 0.396226 (stdev 0.486016), 0:00:00, 159
B: 53, 0, 1, 0, True, 1.000000, 22, 0.415094 (stdev 0.486016), 0:00:00, 0
A: cycle: 53
average reward: 0.396226 (stdev 0.486016)
B: cycle: 53
average reward: 0.415094 (stdev 0.486016)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 54, 1, 1, 0, True, 1.000000, 22, 0.407407 (stdev 0.484563), 0:00:00, 162
B: 54, 1, 0, 0, True, 1.000000, 22, 0.407407 (stdev 0.488155), 0:00:00, 0
A: cycle: 54
average reward: 0.407407 (stdev 0.484563)
B: cycle: 54
average reward: 0.407407 (stdev 0.488155)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 55, 0, 1, 1, True, 1.000000, 23, 0.418182 (stdev 0.486864), 0:00:00, 165
B: 55, 0, 1, 0, True, 1.000000, 23, 0.418182 (stdev 0.486864), 0:00:00, 0
A: cycle: 55
average reward: 0.418182 (stdev 0.486864)
B: cycle: 55
average reward: 0.418182 (stdev 0.486864)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 56, 1, 1, 1, True, 1.000000, 24, 0.428571 (stdev 0.488836), 0:00:00, 168
B: 56, 1, 0, 0, True, 1.000000, 23, 0.410714 (stdev 0.488836), 0:00:00, 0
A: cycle: 56
average reward: 0.428571 (stdev 0.488836)
B: cycle: 56
average reward: 0.410714 (stdev 0.488836)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 57, 0, 0, 0, True, 1.000000, 24, 0.421053 (stdev 0.490511), 0:00:00, 171
B: 57, 0, 1, 1, True, 1.000000, 24, 0.421053 (stdev 0.487629), 0:00:00, 0
A: cycle: 57
average reward: 0.421053 (stdev 0.490511)
B: cycle: 57
average reward: 0.421053 (stdev 0.487629)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 58, 1, 0, 0, True, 1.000000, 24, 0.413793 (stdev 0.489453), 0:00:00, 174
B: 58, 1, 1, 0, True, 1.000000, 25, 0.431034 (stdev 0.489453), 0:00:00, 0
A: cycle: 58
average reward: 0.413793 (stdev 0.489453)
B: cycle: 58
average reward: 0.431034 (stdev 0.489453)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 59, 0, 1, 1, True, 1.000000, 25, 0.423729 (stdev 0.488321), 0:00:00, 177
B: 59, 0, 1, 0, True, 1.000000, 26, 0.440678 (stdev 0.491006), 0:00:00, 0
A: cycle: 59
average reward: 0.423729 (stdev 0.488321)
B: cycle: 59
average reward: 0.440678 (stdev 0.491006)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 60, 1, 1, 0, True, 1.000000, 26, 0.433333 (stdev 0.490013), 0:00:00, 180
B: 60, 1, 0, 1, True, 1.000000, 26, 0.433333 (stdev 0.492314), 0:00:00, 0
A: cycle: 60
average reward: 0.433333 (stdev 0.490013)
B: cycle: 60
average reward: 0.433333 (stdev 0.492314)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 61, 0, 1, 1, True, 1.000000, 27, 0.442623 (stdev 0.491457), 0:00:00, 183
B: 61, 0, 0, 1, True, 1.000000, 26, 0.426230 (stdev 0.491457), 0:00:00, 0
A: cycle: 61
average reward: 0.442623 (stdev 0.491457)
B: cycle: 61
average reward: 0.426230 (stdev 0.491457)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 62, 1, 1, 0, True, 1.000000, 28, 0.451613 (stdev 0.492675), 0:00:00, 186
B: 62, 1, 1, 1, True, 1.000000, 27, 0.435484 (stdev 0.490524), 0:00:00, 0
A: cycle: 62
average reward: 0.451613 (stdev 0.492675)
B: cycle: 62
average reward: 0.435484 (stdev 0.490524)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 63, 0, 1, 0, True, 1.000000, 29, 0.460317 (stdev 0.493688), 0:00:00, 189
B: 63, 0, 0, 0, True, 1.000000, 27, 0.428571 (stdev 0.491869), 0:00:00, 0
A: cycle: 63
average reward: 0.460317 (stdev 0.493688)
B: cycle: 63
average reward: 0.428571 (stdev 0.491869)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 64, 1, 0, 1, True, 1.000000, 29, 0.453125 (stdev 0.494514), 0:00:00, 192
B: 64, 1, 0, 0, True, 1.000000, 27, 0.421875 (stdev 0.490990), 0:00:00, 0
A: cycle: 64
average reward: 0.453125 (stdev 0.494514)
B: cycle: 64
average reward: 0.421875 (stdev 0.490990)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 65, 0, 0, 1, True, 1.000000, 29, 0.446154 (stdev 0.493954), 0:00:00, 195
B: 65, 0, 1, 0, True, 1.000000, 28, 0.430769 (stdev 0.490045), 0:00:00, 0
A: cycle: 65
average reward: 0.446154 (stdev 0.493954)
B: cycle: 65
average reward: 0.430769 (stdev 0.490045)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 66, 1, 1, 1, True, 1.000000, 30, 0.454545 (stdev 0.493312), 0:00:00, 198
B: 66, 1, 0, 0, True, 1.000000, 28, 0.424242 (stdev 0.491418), 0:00:00, 0
A: cycle: 66
average reward: 0.454545 (stdev 0.493312)
B: cycle: 66
average reward: 0.424242 (stdev 0.491418)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 67, 0, 0, 0, True, 1.000000, 30, 0.447761 (stdev 0.494200), 0:00:00, 201
B: 67, 0, 1, 0, True, 1.000000, 29, 0.432836 (stdev 0.490525), 0:00:00, 0
A: cycle: 67
average reward: 0.447761 (stdev 0.494200)
B: cycle: 67
average reward: 0.432836 (stdev 0.490525)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 68, 1, 0, 0, True, 1.000000, 30, 0.441176 (stdev 0.493594), 0:00:00, 204
B: 68, 1, 0, 1, True, 1.000000, 29, 0.426471 (stdev 0.491812), 0:00:00, 0
A: cycle: 68
average reward: 0.441176 (stdev 0.493594)
B: cycle: 68
average reward: 0.426471 (stdev 0.491812)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 69, 0, 1, 1, True, 1.000000, 31, 0.449275 (stdev 0.492917), 0:00:00, 207
B: 69, 0, 0, 1, True, 1.000000, 29, 0.420290 (stdev 0.490967), 0:00:00, 0
A: cycle: 69
average reward: 0.449275 (stdev 0.492917)
B: cycle: 69
average reward: 0.420290 (stdev 0.490967)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 70, 1, 1, 0, True, 1.000000, 32, 0.457143 (stdev 0.493855), 0:00:00, 210
B: 70, 1, 1, 0, True, 1.000000, 30, 0.428571 (stdev 0.490067), 0:00:00, 0
A: cycle: 70
average reward: 0.457143 (stdev 0.493855)
B: cycle: 70
average reward: 0.428571 (stdev 0.490067)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 71, 0, 1, 1, True, 1.000000, 33, 0.464789 (stdev 0.494639), 0:00:00, 213
B: 71, 0, 1, 1, True, 1.000000, 31, 0.436620 (stdev 0.491374), 0:00:00, 0
A: cycle: 71
average reward: 0.464789 (stdev 0.494639)
B: cycle: 71
average reward: 0.436620 (stdev 0.491374)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 72, 1, 1, 0, True, 1.000000, 34, 0.472222 (stdev 0.495283), 0:00:00, 216
B: 72, 1, 1, 1, True, 1.000000, 32, 0.444444 (stdev 0.492510), 0:00:00, 0
A: cycle: 72
average reward: 0.472222 (stdev 0.495283)
B: cycle: 72
average reward: 0.444444 (stdev 0.492510)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 73, 0, 1, 0, True, 1.000000, 35, 0.479452 (stdev 0.495797), 0:00:00, 219
B: 73, 0, 0, 1, True, 1.000000, 32, 0.438356 (stdev 0.493489), 0:00:00, 0
A: cycle: 73
average reward: 0.479452 (stdev 0.495797)
B: cycle: 73
average reward: 0.438356 (stdev 0.493489)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 74, 1, 0, 0, True, 1.000000, 35, 0.472973 (stdev 0.496191), 0:00:00, 222
B: 74, 1, 1, 1, True, 1.000000, 33, 0.445946 (stdev 0.492821), 0:00:00, 0
A: cycle: 74
average reward: 0.472973 (stdev 0.496191)
B: cycle: 74
average reward: 0.445946 (stdev 0.492821)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 75, 0, 1, 0, True, 1.000000, 36, 0.480000 (stdev 0.495929), 0:00:00, 225
B: 75, 0, 0, 1, True, 1.000000, 33, 0.440000 (stdev 0.493745), 0:00:00, 0
A: cycle: 75
average reward: 0.480000 (stdev 0.495929)
B: cycle: 75
average reward: 0.440000 (stdev 0.493745)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 76, 1, 0, 1, True, 1.000000, 36, 0.473684 (stdev 0.496302), 0:00:00, 228
B: 76, 1, 1, 1, True, 1.000000, 34, 0.447368 (stdev 0.493110), 0:00:00, 0
A: cycle: 76
average reward: 0.473684 (stdev 0.496302)
B: cycle: 76
average reward: 0.447368 (stdev 0.493110)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 77, 0, 0, 0, True, 1.000000, 36, 0.467532 (stdev 0.496054), 0:00:00, 231
B: 77, 0, 0, 1, True, 1.000000, 34, 0.441558 (stdev 0.493983), 0:00:00, 0
A: cycle: 77
average reward: 0.467532 (stdev 0.496054)
B: cycle: 77
average reward: 0.441558 (stdev 0.493983)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 78, 1, 0, 0, True, 1.000000, 36, 0.461538 (stdev 0.495736), 0:00:00, 234
B: 78, 1, 1, 1, True, 1.000000, 35, 0.448718 (stdev 0.493379), 0:00:00, 0
A: cycle: 78
average reward: 0.461538 (stdev 0.495736)
B: cycle: 78
average reward: 0.448718 (stdev 0.493379)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 79, 0, 1, 1, True, 1.000000, 37, 0.468354 (stdev 0.495353), 0:00:00, 237
B: 79, 0, 0, 0, True, 1.000000, 35, 0.443038 (stdev 0.494205), 0:00:00, 0
A: cycle: 79
average reward: 0.468354 (stdev 0.495353)
B: cycle: 79
average reward: 0.443038 (stdev 0.494205)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 80, 1, 1, 0, True, 1.000000, 38, 0.475000 (stdev 0.495869), 0:00:00, 240
B: 80, 1, 0, 0, True, 1.000000, 35, 0.437500 (stdev 0.493630), 0:00:00, 0
A: cycle: 80
average reward: 0.475000 (stdev 0.495869)
B: cycle: 80
average reward: 0.437500 (stdev 0.493630)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 81, 0, 1, 1, True, 1.000000, 39, 0.481481 (stdev 0.496282), 0:00:00, 243
B: 81, 0, 1, 0, True, 1.000000, 36, 0.444444 (stdev 0.493007), 0:00:00, 0
A: cycle: 81
average reward: 0.481481 (stdev 0.496282)
B: cycle: 81
average reward: 0.444444 (stdev 0.493007)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 82, 1, 1, 1, True, 1.000000, 40, 0.487805 (stdev 0.496601), 0:00:00, 246
B: 82, 1, 0, 0, True, 1.000000, 36, 0.439024 (stdev 0.493865), 0:00:00, 0
A: cycle: 82
average reward: 0.487805 (stdev 0.496601)
B: cycle: 82
average reward: 0.439024 (stdev 0.493865)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 83, 0, 0, 0, True, 1.000000, 40, 0.481928 (stdev 0.496831), 0:00:00, 249
B: 83, 0, 1, 0, True, 1.000000, 37, 0.445783 (stdev 0.493269), 0:00:00, 0
A: cycle: 83
average reward: 0.481928 (stdev 0.496831)
B: cycle: 83
average reward: 0.445783 (stdev 0.493269)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 84, 1, 0, 1, True, 1.000000, 40, 0.476190 (stdev 0.496690), 0:00:00, 252
B: 84, 1, 0, 1, True, 1.000000, 37, 0.440476 (stdev 0.494084), 0:00:00, 0
A: cycle: 84
average reward: 0.476190 (stdev 0.496690)
B: cycle: 84
average reward: 0.440476 (stdev 0.494084)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 85, 0, 0, 1, True, 1.000000, 40, 0.470588 (stdev 0.496486), 0:00:00, 255
B: 85, 0, 0, 1, True, 1.000000, 37, 0.435294 (stdev 0.493515), 0:00:00, 0
A: cycle: 85
average reward: 0.470588 (stdev 0.496486)
B: cycle: 85
average reward: 0.435294 (stdev 0.493515)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 86, 1, 1, 1, True, 1.000000, 41, 0.476744 (stdev 0.496224), 0:00:00, 258
B: 86, 1, 1, 1, True, 1.000000, 38, 0.441860 (stdev 0.492905), 0:00:00, 0
A: cycle: 86
average reward: 0.476744 (stdev 0.496224)
B: cycle: 86
average reward: 0.441860 (stdev 0.492905)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 87, 0, 0, 1, True, 1.000000, 41, 0.471264 (stdev 0.496580), 0:00:00, 261
B: 87, 0, 0, 1, True, 1.000000, 38, 0.436782 (stdev 0.493746), 0:00:00, 0
A: cycle: 87
average reward: 0.471264 (stdev 0.496580)
B: cycle: 87
average reward: 0.436782 (stdev 0.493746)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 88, 1, 1, 0, True, 1.000000, 42, 0.477273 (stdev 0.496329), 0:00:00, 264
B: 88, 1, 1, 1, True, 1.000000, 39, 0.443182 (stdev 0.493161), 0:00:00, 0
A: cycle: 88
average reward: 0.477273 (stdev 0.496329)
B: cycle: 88
average reward: 0.443182 (stdev 0.493161)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 89, 0, 1, 1, True, 1.000000, 43, 0.483146 (stdev 0.496669), 0:00:00, 267
B: 89, 0, 0, 0, True, 1.000000, 39, 0.438202 (stdev 0.493963), 0:00:00, 0
A: cycle: 89
average reward: 0.483146 (stdev 0.496669)
B: cycle: 89
average reward: 0.438202 (stdev 0.493963)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 90, 1, 1, 0, True, 1.000000, 44, 0.488889 (stdev 0.496932), 0:00:00, 270
B: 90, 1, 0, 1, True, 1.000000, 39, 0.433333 (stdev 0.493402), 0:00:00, 0
A: cycle: 90
average reward: 0.488889 (stdev 0.496932)
B: cycle: 90
average reward: 0.433333 (stdev 0.493402)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 91, 0, 1, 0, True, 1.000000, 45, 0.494505 (stdev 0.497122), 0:00:00, 273
B: 91, 0, 0, 1, True, 1.000000, 39, 0.428571 (stdev 0.492805), 0:00:00, 0
A: cycle: 91
average reward: 0.494505 (stdev 0.497122)
B: cycle: 91
average reward: 0.428571 (stdev 0.492805)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 92, 1, 0, 0, True, 1.000000, 45, 0.489130 (stdev 0.497245), 0:00:00, 276
B: 92, 1, 1, 1, True, 1.000000, 40, 0.434783 (stdev 0.492175), 0:00:00, 0
A: cycle: 92
average reward: 0.489130 (stdev 0.497245)
B: cycle: 92
average reward: 0.434783 (stdev 0.492175)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 93, 0, 1, 0, True, 1.000000, 46, 0.494624 (stdev 0.497187), 0:00:00, 279
B: 93, 0, 0, 1, True, 1.000000, 40, 0.430108 (stdev 0.493056), 0:00:00, 0
A: cycle: 93
average reward: 0.494624 (stdev 0.497187)
B: cycle: 93
average reward: 0.430108 (stdev 0.493056)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 94, 1, 0, 0, True, 1.000000, 46, 0.489362 (stdev 0.497305), 0:00:00, 282
B: 94, 1, 1, 0, True, 1.000000, 41, 0.436170 (stdev 0.492450), 0:00:00, 0
A: cycle: 94
average reward: 0.489362 (stdev 0.497305)
B: cycle: 94
average reward: 0.436170 (stdev 0.492450)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 95, 0, 1, 0, True, 1.000000, 47, 0.494737 (stdev 0.497249), 0:00:00, 285
B: 95, 0, 1, 1, True, 1.000000, 42, 0.442105 (stdev 0.493292), 0:00:00, 0
A: cycle: 95
average reward: 0.494737 (stdev 0.497249)
B: cycle: 95
average reward: 0.442105 (stdev 0.493292)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 96, 1, 0, 0, True, 1.000000, 47, 0.489583 (stdev 0.497361), 0:00:00, 288
B: 96, 1, 1, 0, True, 1.000000, 43, 0.447917 (stdev 0.494043), 0:00:00, 0
A: cycle: 96
average reward: 0.489583 (stdev 0.497361)
B: cycle: 96
average reward: 0.447917 (stdev 0.494043)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 97, 0, 1, 0, True, 1.000000, 48, 0.494845 (stdev 0.497308), 0:00:00, 291
B: 97, 0, 1, 1, True, 1.000000, 44, 0.453608 (stdev 0.494710), 0:00:00, 0
A: cycle: 97
average reward: 0.494845 (stdev 0.497308)
B: cycle: 97
average reward: 0.453608 (stdev 0.494710)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 98, 1, 0, 1, True, 1.000000, 48, 0.489796 (stdev 0.497416), 0:00:00, 294
B: 98, 1, 1, 1, True, 1.000000, 45, 0.459184 (stdev 0.495297), 0:00:00, 0
A: cycle: 98
average reward: 0.489796 (stdev 0.497416)
B: cycle: 98
average reward: 0.459184 (stdev 0.495297)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 99, 0, 0, 0, True, 1.000000, 48, 0.484848 (stdev 0.497365), 0:00:00, 297
B: 99, 0, 0, 1, True, 1.000000, 45, 0.454545 (stdev 0.495808), 0:00:00, 0
A: cycle: 99
average reward: 0.484848 (stdev 0.497365)
B: cycle: 99
average reward: 0.454545 (stdev 0.495808)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 100, 1, 0, 0, True, 1.000000, 48, 0.480000 (stdev 0.497265), 0:00:00, 300
B: 100, 1, 1, 1, True, 1.000000, 46, 0.460000 (stdev 0.495434), 0:00:00, 0
A: cycle: 100
average reward: 0.480000 (stdev 0.497265)
B: cycle: 100
average reward: 0.460000 (stdev 0.495434)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 101, 0, 1, 1, True, 1.000000, 49, 0.485149 (stdev 0.497120), 0:00:00, 303
B: 101, 0, 0, 1, True, 1.000000, 46, 0.455446 (stdev 0.495924), 0:00:00, 0
A: cycle: 101
average reward: 0.485149 (stdev 0.497120)
B: cycle: 101
average reward: 0.455446 (stdev 0.495924)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 102, 1, 1, 1, True, 1.000000, 50, 0.490196 (stdev 0.497323), 0:00:00, 306
B: 102, 1, 1, 1, True, 1.000000, 47, 0.460784 (stdev 0.495564), 0:00:00, 0
A: cycle: 102
average reward: 0.490196 (stdev 0.497323)
B: cycle: 102
average reward: 0.460784 (stdev 0.495564)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 103, 0, 0, 0, True, 1.000000, 50, 0.485437 (stdev 0.497471), 0:00:00, 309
B: 103, 0, 0, 1, True, 1.000000, 47, 0.456311 (stdev 0.496034), 0:00:00, 0
A: cycle: 103
average reward: 0.485437 (stdev 0.497471)
B: cycle: 103
average reward: 0.456311 (stdev 0.496034)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 104, 1, 0, 0, True, 1.000000, 50, 0.480769 (stdev 0.497379), 0:00:00, 312
B: 104, 1, 1, 0, True, 1.000000, 48, 0.461538 (stdev 0.495687), 0:00:00, 0
A: cycle: 104
average reward: 0.480769 (stdev 0.497379)
B: cycle: 104
average reward: 0.461538 (stdev 0.495687)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 105, 0, 1, 0, True, 1.000000, 51, 0.485714 (stdev 0.497245), 0:00:00, 315
B: 105, 0, 1, 0, True, 1.000000, 49, 0.466667 (stdev 0.496139), 0:00:00, 0
A: cycle: 105
average reward: 0.485714 (stdev 0.497245)
B: cycle: 105
average reward: 0.466667 (stdev 0.496139)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 106, 1, 0, 1, True, 1.000000, 51, 0.481132 (stdev 0.497433), 0:00:00, 318
B: 106, 1, 0, 0, True, 1.000000, 49, 0.462264 (stdev 0.496529), 0:00:00, 0
A: cycle: 106
average reward: 0.481132 (stdev 0.497433)
B: cycle: 106
average reward: 0.462264 (stdev 0.496529)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 107, 0, 0, 1, True, 1.000000, 51, 0.476636 (stdev 0.497304), 0:00:00, 321
B: 107, 0, 1, 0, True, 1.000000, 50, 0.467290 (stdev 0.496239), 0:00:00, 0
A: cycle: 107
average reward: 0.476636 (stdev 0.497304)
B: cycle: 107
average reward: 0.467290 (stdev 0.496239)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 108, 1, 1, 0, True, 1.000000, 52, 0.481481 (stdev 0.497136), 0:00:00, 324
B: 108, 1, 0, 0, True, 1.000000, 50, 0.462963 (stdev 0.496614), 0:00:00, 0
A: cycle: 108
average reward: 0.481481 (stdev 0.497136)
B: cycle: 108
average reward: 0.462963 (stdev 0.496614)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 109, 0, 1, 1, True, 1.000000, 53, 0.486239 (stdev 0.497360), 0:00:00, 327
B: 109, 0, 1, 1, True, 1.000000, 51, 0.467890 (stdev 0.496334), 0:00:00, 0
A: cycle: 109
average reward: 0.486239 (stdev 0.497360)
B: cycle: 109
average reward: 0.467890 (stdev 0.496334)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 110, 1, 1, 0, True, 1.000000, 54, 0.490909 (stdev 0.497534), 0:00:00, 330
B: 110, 1, 1, 1, True, 1.000000, 52, 0.472727 (stdev 0.496695), 0:00:00, 0
A: cycle: 110
average reward: 0.490909 (stdev 0.497534)
B: cycle: 110
average reward: 0.472727 (stdev 0.496695)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 111, 0, 1, 0, True, 1.000000, 55, 0.495495 (stdev 0.497660), 0:00:00, 333
B: 111, 0, 0, 0, True, 1.000000, 52, 0.468468 (stdev 0.497002), 0:00:00, 0
A: cycle: 111
average reward: 0.495495 (stdev 0.497660)
B: cycle: 111
average reward: 0.468468 (stdev 0.497002)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 112, 1, 0, 1, True, 1.000000, 55, 0.491071 (stdev 0.497743), 0:00:00, 336
B: 112, 1, 0, 0, True, 1.000000, 52, 0.464286 (stdev 0.496772), 0:00:00, 0
A: cycle: 112
average reward: 0.491071 (stdev 0.497743)
B: cycle: 112
average reward: 0.464286 (stdev 0.496772)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 113, 0, 0, 0, True, 1.000000, 55, 0.486726 (stdev 0.497703), 0:00:00, 339
B: 113, 0, 1, 0, True, 1.000000, 53, 0.469027 (stdev 0.496511), 0:00:00, 0
A: cycle: 113
average reward: 0.486726 (stdev 0.497703)
B: cycle: 113
average reward: 0.469027 (stdev 0.496511)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 114, 1, 0, 0, True, 1.000000, 55, 0.482456 (stdev 0.497627), 0:00:00, 342
B: 114, 1, 0, 1, True, 1.000000, 53, 0.464912 (stdev 0.496846), 0:00:00, 0
A: cycle: 114
average reward: 0.482456 (stdev 0.497627)
B: cycle: 114
average reward: 0.464912 (stdev 0.496846)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 115, 0, 1, 0, True, 1.000000, 56, 0.486957 (stdev 0.497515), 0:00:00, 345
B: 115, 0, 0, 0, True, 1.000000, 53, 0.460870 (stdev 0.496594), 0:00:00, 0
A: cycle: 115
average reward: 0.486957 (stdev 0.497515)
B: cycle: 115
average reward: 0.460870 (stdev 0.496594)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 116, 1, 0, 1, True, 1.000000, 56, 0.482759 (stdev 0.497671), 0:00:00, 348
B: 116, 1, 0, 0, True, 1.000000, 53, 0.456897 (stdev 0.496313), 0:00:00, 0
A: cycle: 116
average reward: 0.482759 (stdev 0.497671)
B: cycle: 116
average reward: 0.456897 (stdev 0.496313)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 117, 0, 0, 0, True, 1.000000, 56, 0.478632 (stdev 0.497563), 0:00:00, 351
B: 117, 0, 1, 0, True, 1.000000, 54, 0.461538 (stdev 0.496005), 0:00:00, 0
A: cycle: 117
average reward: 0.478632 (stdev 0.497563)
B: cycle: 117
average reward: 0.461538 (stdev 0.496005)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 118, 1, 0, 1, True, 1.000000, 56, 0.474576 (stdev 0.497422), 0:00:00, 354
B: 118, 1, 0, 0, True, 1.000000, 54, 0.457627 (stdev 0.496402), 0:00:00, 0
A: cycle: 118
average reward: 0.474576 (stdev 0.497422)
B: cycle: 118
average reward: 0.457627 (stdev 0.496402)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 119, 0, 0, 0, True, 1.000000, 56, 0.470588 (stdev 0.497251), 0:00:00, 357
B: 119, 0, 1, 0, True, 1.000000, 55, 0.462185 (stdev 0.496104), 0:00:00, 0
A: cycle: 119
average reward: 0.470588 (stdev 0.497251)
B: cycle: 119
average reward: 0.462185 (stdev 0.496104)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 120, 1, 0, 1, True, 1.000000, 56, 0.466667 (stdev 0.497050), 0:00:00, 360
B: 120, 1, 0, 1, True, 1.000000, 55, 0.458333 (stdev 0.496486), 0:00:00, 0
A: cycle: 120
average reward: 0.466667 (stdev 0.497050)
B: cycle: 120
average reward: 0.458333 (stdev 0.496486)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 121, 0, 0, 0, True, 1.000000, 56, 0.462810 (stdev 0.496822), 0:00:00, 363
B: 121, 0, 0, 0, True, 1.000000, 55, 0.454545 (stdev 0.496198), 0:00:00, 0
A: cycle: 121
average reward: 0.462810 (stdev 0.496822)
B: cycle: 121
average reward: 0.454545 (stdev 0.496198)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 122, 1, 0, 1, True, 1.000000, 56, 0.459016 (stdev 0.496567), 0:00:00, 366
B: 122, 1, 0, 1, True, 1.000000, 55, 0.450820 (stdev 0.495885), 0:00:00, 0
A: cycle: 122
average reward: 0.459016 (stdev 0.496567)
B: cycle: 122
average reward: 0.450820 (stdev 0.495885)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 123, 0, 0, 1, True, 1.000000, 56, 0.455285 (stdev 0.496288), 0:00:00, 369
B: 123, 0, 0, 0, True, 1.000000, 55, 0.447154 (stdev 0.495549), 0:00:00, 0
A: cycle: 123
average reward: 0.455285 (stdev 0.496288)
B: cycle: 123
average reward: 0.447154 (stdev 0.495549)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 124, 1, 1, 1, True, 1.000000, 57, 0.459677 (stdev 0.495984), 0:00:00, 372
B: 124, 1, 0, 0, True, 1.000000, 55, 0.443548 (stdev 0.495191), 0:00:00, 0
A: cycle: 124
average reward: 0.459677 (stdev 0.495984)
B: cycle: 124
average reward: 0.443548 (stdev 0.495191)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 125, 0, 0, 0, True, 1.000000, 57, 0.456000 (stdev 0.496374), 0:00:00, 375
B: 125, 0, 1, 0, True, 1.000000, 56, 0.448000 (stdev 0.494812), 0:00:00, 0
A: cycle: 125
average reward: 0.456000 (stdev 0.496374)
B: cycle: 125
average reward: 0.448000 (stdev 0.494812)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 126, 1, 0, 0, True, 1.000000, 57, 0.452381 (stdev 0.496080), 0:00:00, 378
B: 126, 1, 0, 0, True, 1.000000, 56, 0.444444 (stdev 0.495311), 0:00:00, 0
A: cycle: 126
average reward: 0.452381 (stdev 0.496080)
B: cycle: 126
average reward: 0.444444 (stdev 0.495311)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 127, 0, 1, 1, True, 1.000000, 58, 0.456693 (stdev 0.495764), 0:00:00, 381
B: 127, 0, 1, 1, True, 1.000000, 57, 0.448819 (stdev 0.494944), 0:00:00, 0
A: cycle: 127
average reward: 0.456693 (stdev 0.495764)
B: cycle: 127
average reward: 0.448819 (stdev 0.494944)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 128, 1, 1, 1, True, 1.000000, 59, 0.460938 (stdev 0.496171), 0:00:00, 384
B: 128, 1, 1, 1, True, 1.000000, 58, 0.453125 (stdev 0.495427), 0:00:00, 0
A: cycle: 128
average reward: 0.460938 (stdev 0.496171)
B: cycle: 128
average reward: 0.453125 (stdev 0.495427)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 129, 0, 0, 1, True, 1.000000, 59, 0.457364 (stdev 0.496536), 0:00:00, 387
B: 129, 0, 0, 1, True, 1.000000, 58, 0.449612 (stdev 0.495865), 0:00:00, 0
A: cycle: 129
average reward: 0.457364 (stdev 0.496536)
B: cycle: 129
average reward: 0.449612 (stdev 0.495865)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 130, 1, 1, 1, True, 1.000000, 60, 0.461538 (stdev 0.496259), 0:00:00, 390
B: 130, 1, 1, 1, True, 1.000000, 59, 0.453846 (stdev 0.495538), 0:00:00, 0
A: cycle: 130
average reward: 0.461538 (stdev 0.496259)
B: cycle: 130
average reward: 0.453846 (stdev 0.495538)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 131, 0, 0, 0, True, 1.000000, 60, 0.458015 (stdev 0.496612), 0:00:00, 393
B: 131, 0, 0, 1, True, 1.000000, 59, 0.450382 (stdev 0.495961), 0:00:00, 0
A: cycle: 131
average reward: 0.458015 (stdev 0.496612)
B: cycle: 131
average reward: 0.450382 (stdev 0.495961)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 132, 1, 0, 1, True, 1.000000, 60, 0.454545 (stdev 0.496343), 0:00:00, 396
B: 132, 1, 1, 0, True, 1.000000, 60, 0.454545 (stdev 0.495644), 0:00:00, 0
A: cycle: 132
average reward: 0.454545 (stdev 0.496343)
B: cycle: 132
average reward: 0.454545 (stdev 0.495644)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 133, 0, 0, 0, True, 1.000000, 60, 0.451128 (stdev 0.496054), 0:00:00, 399
B: 133, 0, 1, 1, True, 1.000000, 61, 0.458647 (stdev 0.496054), 0:00:00, 0
A: cycle: 133
average reward: 0.451128 (stdev 0.496054)
B: cycle: 133
average reward: 0.458647 (stdev 0.496054)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 134, 1, 0, 1, True, 1.000000, 60, 0.447761 (stdev 0.495746), 0:00:00, 402
B: 134, 1, 1, 1, True, 1.000000, 62, 0.462687 (stdev 0.496424), 0:00:00, 0
A: cycle: 134
average reward: 0.447761 (stdev 0.495746)
B: cycle: 134
average reward: 0.462687 (stdev 0.496424)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 135, 0, 0, 0, True, 1.000000, 60, 0.444444 (stdev 0.495418), 0:00:00, 405
B: 135, 0, 0, 1, True, 1.000000, 62, 0.459259 (stdev 0.496756), 0:00:00, 0
A: cycle: 135
average reward: 0.444444 (stdev 0.495418)
B: cycle: 135
average reward: 0.459259 (stdev 0.496756)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 136, 1, 0, 0, True, 1.000000, 60, 0.441176 (stdev 0.495074), 0:00:00, 408
B: 136, 1, 1, 1, True, 1.000000, 63, 0.463235 (stdev 0.496502), 0:00:00, 0
A: cycle: 136
average reward: 0.441176 (stdev 0.495074)
B: cycle: 136
average reward: 0.463235 (stdev 0.496502)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 137, 0, 1, 0, True, 1.000000, 61, 0.445255 (stdev 0.494712), 0:00:00, 411
B: 137, 0, 0, 0, True, 1.000000, 63, 0.459854 (stdev 0.496823), 0:00:00, 0
A: cycle: 137
average reward: 0.445255 (stdev 0.494712)
B: cycle: 137
average reward: 0.459854 (stdev 0.496823)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 138, 1, 0, 0, True, 1.000000, 61, 0.442029 (stdev 0.495190), 0:00:00, 414
B: 138, 1, 0, 1, True, 1.000000, 63, 0.456522 (stdev 0.496577), 0:00:00, 0
A: cycle: 138
average reward: 0.442029 (stdev 0.495190)
B: cycle: 138
average reward: 0.456522 (stdev 0.496577)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 139, 0, 1, 0, True, 1.000000, 62, 0.446043 (stdev 0.494838), 0:00:00, 417
B: 139, 0, 0, 1, True, 1.000000, 63, 0.453237 (stdev 0.496311), 0:00:00, 0
A: cycle: 139
average reward: 0.446043 (stdev 0.494838)
B: cycle: 139
average reward: 0.453237 (stdev 0.496311)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 140, 1, 0, 0, True, 1.000000, 62, 0.442857 (stdev 0.495302), 0:00:00, 420
B: 140, 1, 1, 0, True, 1.000000, 64, 0.457143 (stdev 0.496027), 0:00:00, 0
A: cycle: 140
average reward: 0.442857 (stdev 0.495302)
B: cycle: 140
average reward: 0.457143 (stdev 0.496027)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 141, 0, 1, 1, True, 1.000000, 63, 0.446809 (stdev 0.494959), 0:00:00, 423
B: 141, 0, 1, 1, True, 1.000000, 65, 0.460993 (stdev 0.496390), 0:00:00, 0
A: cycle: 141
average reward: 0.446809 (stdev 0.494959)
B: cycle: 141
average reward: 0.460993 (stdev 0.496390)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 142, 1, 1, 0, True, 1.000000, 64, 0.450704 (stdev 0.495409), 0:00:00, 426
B: 142, 1, 1, 1, True, 1.000000, 66, 0.464789 (stdev 0.496718), 0:00:00, 0
A: cycle: 142
average reward: 0.450704 (stdev 0.495409)
B: cycle: 142
average reward: 0.464789 (stdev 0.496718)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 143, 0, 1, 1, True, 1.000000, 65, 0.454545 (stdev 0.495821), 0:00:00, 429
B: 143, 0, 0, 0, True, 1.000000, 66, 0.461538 (stdev 0.497012), 0:00:00, 0
A: cycle: 143
average reward: 0.454545 (stdev 0.495821)
B: cycle: 143
average reward: 0.461538 (stdev 0.497012)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 144, 1, 1, 0, True, 1.000000, 66, 0.458333 (stdev 0.496198), 0:00:00, 432
B: 144, 1, 0, 0, True, 1.000000, 66, 0.458333 (stdev 0.496785), 0:00:00, 0
A: cycle: 144
average reward: 0.458333 (stdev 0.496198)
B: cycle: 144
average reward: 0.458333 (stdev 0.496785)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 145, 0, 1, 1, True, 1.000000, 67, 0.462069 (stdev 0.496540), 0:00:00, 435
B: 145, 0, 1, 1, True, 1.000000, 67, 0.462069 (stdev 0.496540), 0:00:00, 0
A: cycle: 145
average reward: 0.462069 (stdev 0.496540)
B: cycle: 145
average reward: 0.462069 (stdev 0.496540)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 146, 1, 1, 1, True, 1.000000, 68, 0.465753 (stdev 0.496849), 0:00:00, 438
B: 146, 1, 1, 0, True, 1.000000, 68, 0.465753 (stdev 0.496849), 0:00:00, 0
A: cycle: 146
average reward: 0.465753 (stdev 0.496849)
B: cycle: 146
average reward: 0.465753 (stdev 0.496849)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 147, 0, 0, 1, True, 1.000000, 68, 0.462585 (stdev 0.497126), 0:00:00, 441
B: 147, 0, 1, 0, True, 1.000000, 69, 0.469388 (stdev 0.497126), 0:00:00, 0
A: cycle: 147
average reward: 0.462585 (stdev 0.497126)
B: cycle: 147
average reward: 0.469388 (stdev 0.497126)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 148, 1, 1, 1, True, 1.000000, 69, 0.466216 (stdev 0.496911), 0:00:00, 444
B: 148, 1, 0, 0, True, 1.000000, 69, 0.466216 (stdev 0.497373), 0:00:00, 0
A: cycle: 148
average reward: 0.466216 (stdev 0.496911)
B: cycle: 148
average reward: 0.466216 (stdev 0.497373)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 149, 0, 0, 0, True, 1.000000, 69, 0.463087 (stdev 0.497181), 0:00:00, 447
B: 149, 0, 1, 0, True, 1.000000, 70, 0.469799 (stdev 0.497181), 0:00:00, 0
A: cycle: 149
average reward: 0.463087 (stdev 0.497181)
B: cycle: 149
average reward: 0.469799 (stdev 0.497181)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 150, 1, 0, 1, True, 1.000000, 69, 0.460000 (stdev 0.496971), 0:00:00, 450
B: 150, 1, 0, 1, True, 1.000000, 70, 0.466667 (stdev 0.497421), 0:00:00, 0
A: cycle: 150
average reward: 0.460000 (stdev 0.496971)
B: cycle: 150
average reward: 0.466667 (stdev 0.497421)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0



explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 151, 0, 0, 1, True, 1.000000, 69, 0.456954 (stdev 0.496744), 0:00:00, 453
B: 151, 0, 0, 1, True, 1.000000, 70, 0.463576 (stdev 0.497233), 0:00:00, 0
A: cycle: 151
average reward: 0.456954 (stdev 0.496744)
B: cycle: 151
average reward: 0.463576 (stdev 0.497233)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 152, 1, 1, 1, True, 1.000000, 70, 0.460526 (stdev 0.496502), 0:00:00, 456
B: 152, 1, 1, 1, True, 1.000000, 71, 0.467105 (stdev 0.497028), 0:00:00, 0
A: cycle: 152
average reward: 0.460526 (stdev 0.496502)
B: cycle: 152
average reward: 0.467105 (stdev 0.497028)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 153, 0, 0, 1, True, 1.000000, 70, 0.457516 (stdev 0.496808), 0:00:00, 459
B: 153, 0, 0, 1, True, 1.000000, 71, 0.464052 (stdev 0.497284), 0:00:00, 0
A: cycle: 153
average reward: 0.457516 (stdev 0.496808)
B: cycle: 153
average reward: 0.464052 (stdev 0.497284)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 154, 1, 1, 1, True, 1.000000, 71, 0.461039 (stdev 0.496572), 0:00:00, 462
B: 154, 1, 1, 0, True, 1.000000, 72, 0.467532 (stdev 0.497084), 0:00:00, 0
A: cycle: 154
average reward: 0.461039 (stdev 0.496572)
B: cycle: 154
average reward: 0.467532 (stdev 0.497084)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 155, 0, 0, 0, True, 1.000000, 71, 0.458065 (stdev 0.496869), 0:00:00, 465
B: 155, 0, 1, 1, True, 1.000000, 73, 0.470968 (stdev 0.497333), 0:00:00, 0
A: cycle: 155
average reward: 0.458065 (stdev 0.496869)
B: cycle: 155
average reward: 0.470968 (stdev 0.497333)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 156, 1, 0, 0, True, 1.000000, 71, 0.455128 (stdev 0.496639), 0:00:00, 468
B: 156, 1, 1, 1, True, 1.000000, 74, 0.474359 (stdev 0.497554), 0:00:00, 0
A: cycle: 156
average reward: 0.455128 (stdev 0.496639)
B: cycle: 156
average reward: 0.474359 (stdev 0.497554)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 157, 0, 1, 1, True, 1.000000, 72, 0.458599 (stdev 0.496394), 0:00:00, 471
B: 157, 0, 0, 1, True, 1.000000, 74, 0.471338 (stdev 0.497749), 0:00:00, 0
A: cycle: 157
average reward: 0.458599 (stdev 0.496394)
B: cycle: 157
average reward: 0.471338 (stdev 0.497749)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 158, 1, 1, 1, True, 1.000000, 73, 0.462025 (stdev 0.496704), 0:00:00, 474
B: 158, 1, 1, 0, True, 1.000000, 75, 0.474684 (stdev 0.497596), 0:00:00, 0
A: cycle: 158
average reward: 0.462025 (stdev 0.496704)
B: cycle: 158
average reward: 0.474684 (stdev 0.497596)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 159, 0, 0, 1, True, 1.000000, 73, 0.459119 (stdev 0.496986), 0:00:00, 477
B: 159, 0, 1, 1, True, 1.000000, 76, 0.477987 (stdev 0.497786), 0:00:00, 0
A: cycle: 159
average reward: 0.459119 (stdev 0.496986)
B: cycle: 159
average reward: 0.477987 (stdev 0.497786)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 160, 1, 1, 1, True, 1.000000, 74, 0.462500 (stdev 0.496766), 0:00:00, 480
B: 160, 1, 1, 0, True, 1.000000, 77, 0.481250 (stdev 0.497952), 0:00:00, 0
A: cycle: 160
average reward: 0.462500 (stdev 0.496766)
B: cycle: 160
average reward: 0.481250 (stdev 0.497952)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 161, 0, 0, 0, True, 1.000000, 74, 0.459627 (stdev 0.497041), 0:00:00, 483
B: 161, 0, 1, 0, True, 1.000000, 78, 0.484472 (stdev 0.498094), 0:00:00, 0
A: cycle: 161
average reward: 0.459627 (stdev 0.497041)
B: cycle: 161
average reward: 0.484472 (stdev 0.498094)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 162, 1, 0, 1, True, 1.000000, 74, 0.456790 (stdev 0.496827), 0:00:00, 486
B: 162, 1, 0, 1, True, 1.000000, 78, 0.481481 (stdev 0.498214), 0:00:00, 0
A: cycle: 162
average reward: 0.456790 (stdev 0.496827)
B: cycle: 162
average reward: 0.481481 (stdev 0.498214)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 163, 0, 0, 0, True, 1.000000, 74, 0.453988 (stdev 0.496599), 0:00:00, 489
B: 163, 0, 0, 1, True, 1.000000, 78, 0.478528 (stdev 0.498122), 0:00:00, 0
A: cycle: 163
average reward: 0.453988 (stdev 0.496599)
B: cycle: 163
average reward: 0.478528 (stdev 0.498122)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 164, 1, 0, 0, True, 1.000000, 74, 0.451220 (stdev 0.496358), 0:00:00, 492
B: 164, 1, 1, 0, True, 1.000000, 79, 0.481707 (stdev 0.498013), 0:00:00, 0
A: cycle: 164
average reward: 0.451220 (stdev 0.496358)
B: cycle: 164
average reward: 0.481707 (stdev 0.498013)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 165, 0, 1, 0, True, 1.000000, 75, 0.454545 (stdev 0.496105), 0:00:00, 495
B: 165, 0, 1, 1, True, 1.000000, 80, 0.484848 (stdev 0.498149), 0:00:00, 0
A: cycle: 165
average reward: 0.454545 (stdev 0.496105)
B: cycle: 165
average reward: 0.484848 (stdev 0.498149)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 166, 1, 0, 1, True, 1.000000, 75, 0.451807 (stdev 0.496428), 0:00:00, 498
B: 166, 1, 1, 0, True, 1.000000, 81, 0.487952 (stdev 0.498263), 0:00:00, 0
A: cycle: 166
average reward: 0.451807 (stdev 0.496428)
B: cycle: 166
average reward: 0.487952 (stdev 0.498263)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 167, 0, 0, 0, True, 1.000000, 75, 0.449102 (stdev 0.496180), 0:00:00, 501
B: 167, 0, 1, 0, True, 1.000000, 82, 0.491018 (stdev 0.498356), 0:00:00, 0
A: cycle: 167
average reward: 0.449102 (stdev 0.496180)
B: cycle: 167
average reward: 0.491018 (stdev 0.498356)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 168, 1, 0, 0, True, 1.000000, 75, 0.446429 (stdev 0.495920), 0:00:00, 504
B: 168, 1, 0, 1, True, 1.000000, 82, 0.488095 (stdev 0.498429), 0:00:00, 0
A: cycle: 168
average reward: 0.446429 (stdev 0.495920)
B: cycle: 168
average reward: 0.488095 (stdev 0.498429)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 169, 0, 1, 0, True, 1.000000, 76, 0.449704 (stdev 0.495649), 0:00:00, 507
B: 169, 0, 0, 1, True, 1.000000, 82, 0.485207 (stdev 0.498377), 0:00:00, 0
A: cycle: 169
average reward: 0.449704 (stdev 0.495649)
B: cycle: 169
average reward: 0.485207 (stdev 0.498377)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 170, 1, 0, 0, True, 1.000000, 76, 0.447059 (stdev 0.495999), 0:00:00, 510
B: 170, 1, 1, 1, True, 1.000000, 83, 0.488235 (stdev 0.498309), 0:00:00, 0
A: cycle: 170
average reward: 0.447059 (stdev 0.495999)
B: cycle: 170
average reward: 0.488235 (stdev 0.498309)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 171, 0, 1, 0, True, 1.000000, 77, 0.450292 (stdev 0.495733), 0:00:00, 513
B: 171, 0, 0, 0, True, 1.000000, 83, 0.485380 (stdev 0.498398), 0:00:00, 0
A: cycle: 171
average reward: 0.450292 (stdev 0.495733)
B: cycle: 171
average reward: 0.485380 (stdev 0.498398)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 172, 1, 0, 0, True, 1.000000, 77, 0.447674 (stdev 0.496075), 0:00:00, 516
B: 172, 1, 0, 1, True, 1.000000, 83, 0.482558 (stdev 0.498331), 0:00:00, 0
A: cycle: 172
average reward: 0.447674 (stdev 0.496075)
B: cycle: 172
average reward: 0.482558 (stdev 0.498331)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 173, 0, 1, 0, True, 1.000000, 78, 0.450867 (stdev 0.495815), 0:00:00, 519
B: 173, 0, 0, 0, True, 1.000000, 83, 0.479769 (stdev 0.498249), 0:00:00, 0
A: cycle: 173
average reward: 0.450867 (stdev 0.495815)
B: cycle: 173
average reward: 0.479769 (stdev 0.498249)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 174, 1, 0, 1, True, 1.000000, 78, 0.448276 (stdev 0.496148), 0:00:00, 522
B: 174, 1, 0, 0, True, 1.000000, 83, 0.477011 (stdev 0.498153), 0:00:00, 0
A: cycle: 174
average reward: 0.448276 (stdev 0.496148)
B: cycle: 174
average reward: 0.477011 (stdev 0.498153)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 175, 0, 0, 0, True, 1.000000, 78, 0.445714 (stdev 0.495894), 0:00:00, 525
B: 175, 0, 1, 0, True, 1.000000, 84, 0.480000 (stdev 0.498042), 0:00:00, 0
A: cycle: 175
average reward: 0.445714 (stdev 0.495894)
B: cycle: 175
average reward: 0.480000 (stdev 0.498042)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 176, 1, 0, 1, True, 1.000000, 78, 0.443182 (stdev 0.495630), 0:00:00, 528
B: 176, 1, 0, 1, True, 1.000000, 84, 0.477273 (stdev 0.498179), 0:00:00, 0
A: cycle: 176
average reward: 0.443182 (stdev 0.495630)
B: cycle: 176
average reward: 0.477273 (stdev 0.498179)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 177, 0, 0, 0, True, 1.000000, 78, 0.440678 (stdev 0.495356), 0:00:00, 531
B: 177, 0, 0, 1, True, 1.000000, 84, 0.474576 (stdev 0.498070), 0:00:00, 0
A: cycle: 177
average reward: 0.440678 (stdev 0.495356)
B: cycle: 177
average reward: 0.474576 (stdev 0.498070)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 178, 1, 0, 1, True, 1.000000, 78, 0.438202 (stdev 0.495072), 0:00:00, 534
B: 178, 1, 1, 0, True, 1.000000, 85, 0.477528 (stdev 0.497949), 0:00:00, 0
A: cycle: 178
average reward: 0.438202 (stdev 0.495072)
B: cycle: 178
average reward: 0.477528 (stdev 0.497949)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 179, 0, 0, 1, True, 1.000000, 78, 0.435754 (stdev 0.494778), 0:00:00, 537
B: 179, 0, 1, 1, True, 1.000000, 86, 0.480447 (stdev 0.498098), 0:00:00, 0
A: cycle: 179
average reward: 0.435754 (stdev 0.494778)
B: cycle: 179
average reward: 0.480447 (stdev 0.498098)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 180, 1, 1, 0, True, 1.000000, 79, 0.438889 (stdev 0.494476), 0:00:00, 540
B: 180, 1, 1, 1, True, 1.000000, 87, 0.483333 (stdev 0.498228), 0:00:00, 0
A: cycle: 180
average reward: 0.438889 (stdev 0.494476)
B: cycle: 180
average reward: 0.483333 (stdev 0.498228)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 181, 0, 1, 0, True, 1.000000, 80, 0.441989 (stdev 0.494879), 0:00:00, 543
B: 181, 0, 0, 0, True, 1.000000, 87, 0.480663 (stdev 0.498340), 0:00:00, 0
A: cycle: 181
average reward: 0.441989 (stdev 0.494879)
B: cycle: 181
average reward: 0.480663 (stdev 0.498340)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 182, 1, 0, 0, True, 1.000000, 80, 0.439560 (stdev 0.495257), 0:00:00, 546
B: 182, 1, 0, 0, True, 1.000000, 87, 0.478022 (stdev 0.498251), 0:00:00, 0
A: cycle: 182
average reward: 0.439560 (stdev 0.495257)
B: cycle: 182
average reward: 0.478022 (stdev 0.498251)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 183, 0, 1, 0, True, 1.000000, 81, 0.442623 (stdev 0.494976), 0:00:00, 549
B: 183, 0, 1, 1, True, 1.000000, 88, 0.480874 (stdev 0.498150), 0:00:00, 0
A: cycle: 183
average reward: 0.442623 (stdev 0.494976)
B: cycle: 183
average reward: 0.480874 (stdev 0.498150)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 184, 1, 0, 0, True, 1.000000, 81, 0.440217 (stdev 0.495345), 0:00:00, 552
B: 184, 1, 1, 0, True, 1.000000, 89, 0.483696 (stdev 0.498275), 0:00:00, 0
A: cycle: 184
average reward: 0.440217 (stdev 0.495345)
B: cycle: 184
average reward: 0.483696 (stdev 0.498275)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 185, 0, 1, 0, True, 1.000000, 82, 0.443243 (stdev 0.495070), 0:00:00, 555
B: 185, 0, 1, 0, True, 1.000000, 90, 0.486486 (stdev 0.498382), 0:00:00, 0
A: cycle: 185
average reward: 0.443243 (stdev 0.495070)
B: cycle: 185
average reward: 0.486486 (stdev 0.498382)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 186, 1, 0, 1, True, 1.000000, 82, 0.440860 (stdev 0.495431), 0:00:00, 558
B: 186, 1, 0, 0, True, 1.000000, 90, 0.483871 (stdev 0.498472), 0:00:00, 0
A: cycle: 186
average reward: 0.440860 (stdev 0.495431)
B: cycle: 186
average reward: 0.483871 (stdev 0.498472)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 187, 0, 0, 0, True, 1.000000, 82, 0.438503 (stdev 0.495161), 0:00:00, 561
B: 187, 0, 1, 1, True, 1.000000, 91, 0.486631 (stdev 0.498402), 0:00:00, 0
A: cycle: 187
average reward: 0.438503 (stdev 0.495161)
B: cycle: 187
average reward: 0.486631 (stdev 0.498402)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 188, 1, 0, 0, True, 1.000000, 82, 0.436170 (stdev 0.494882), 0:00:00, 564
B: 188, 1, 1, 0, True, 1.000000, 92, 0.489362 (stdev 0.498490), 0:00:00, 0
A: cycle: 188
average reward: 0.436170 (stdev 0.494882)
B: cycle: 188
average reward: 0.489362 (stdev 0.498490)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 189, 0, 1, 1, True, 1.000000, 83, 0.439153 (stdev 0.494595), 0:00:00, 567
B: 189, 0, 1, 1, True, 1.000000, 93, 0.492063 (stdev 0.498563), 0:00:00, 0
A: cycle: 189
average reward: 0.439153 (stdev 0.494595)
B: cycle: 189
average reward: 0.492063 (stdev 0.498563)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 190, 1, 1, 1, True, 1.000000, 84, 0.442105 (stdev 0.494976), 0:00:00, 570
B: 190, 1, 1, 1, True, 1.000000, 94, 0.494737 (stdev 0.498620), 0:00:00, 0
A: cycle: 190
average reward: 0.442105 (stdev 0.494976)
B: cycle: 190
average reward: 0.494737 (stdev 0.498620)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 191, 0, 0, 0, True, 1.000000, 84, 0.439791 (stdev 0.495335), 0:00:00, 573
B: 191, 0, 0, 0, True, 1.000000, 94, 0.492147 (stdev 0.498662), 0:00:00, 0
A: cycle: 191
average reward: 0.439791 (stdev 0.495335)
B: cycle: 191
average reward: 0.492147 (stdev 0.498662)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 192, 1, 0, 0, True, 1.000000, 84, 0.437500 (stdev 0.495067), 0:00:00, 576
B: 192, 1, 0, 0, True, 1.000000, 94, 0.489583 (stdev 0.498635), 0:00:00, 0
A: cycle: 192
average reward: 0.437500 (stdev 0.495067)
B: cycle: 192
average reward: 0.489583 (stdev 0.498635)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 193, 0, 1, 1, True, 1.000000, 85, 0.440415 (stdev 0.494792), 0:00:00, 579
B: 193, 0, 1, 0, True, 1.000000, 95, 0.492228 (stdev 0.498595), 0:00:00, 0
A: cycle: 193
average reward: 0.440415 (stdev 0.494792)
B: cycle: 193
average reward: 0.492228 (stdev 0.498595)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 194, 1, 1, 1, True, 1.000000, 86, 0.443299 (stdev 0.495156), 0:00:00, 582
B: 194, 1, 0, 0, True, 1.000000, 95, 0.489691 (stdev 0.498649), 0:00:00, 0
A: cycle: 194
average reward: 0.443299 (stdev 0.495156)
B: cycle: 194
average reward: 0.489691 (stdev 0.498649)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 195, 0, 0, 0, True, 1.000000, 86, 0.441026 (stdev 0.495499), 0:00:00, 585
B: 195, 0, 1, 1, True, 1.000000, 96, 0.492308 (stdev 0.498610), 0:00:00, 0
A: cycle: 195
average reward: 0.441026 (stdev 0.495499)
B: cycle: 195
average reward: 0.492308 (stdev 0.498610)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 196, 1, 0, 0, True, 1.000000, 86, 0.438776 (stdev 0.495242), 0:00:00, 588
B: 196, 1, 1, 0, True, 1.000000, 97, 0.494898 (stdev 0.498664), 0:00:00, 0
A: cycle: 196
average reward: 0.438776 (stdev 0.495242)
B: cycle: 196
average reward: 0.494898 (stdev 0.498664)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 197, 0, 1, 1, True, 1.000000, 87, 0.441624 (stdev 0.494976), 0:00:00, 591
B: 197, 0, 1, 1, True, 1.000000, 98, 0.497462 (stdev 0.498703), 0:00:00, 0
A: cycle: 197
average reward: 0.441624 (stdev 0.494976)
B: cycle: 197
average reward: 0.497462 (stdev 0.498703)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 198, 1, 1, 1, True, 1.000000, 88, 0.444444 (stdev 0.495325), 0:00:00, 594
B: 198, 1, 1, 0, True, 1.000000, 99, 0.500000 (stdev 0.498729), 0:00:00, 0
A: cycle: 198
average reward: 0.444444 (stdev 0.495325)
B: cycle: 198
average reward: 0.500000 (stdev 0.498729)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 199, 0, 0, 1, True, 1.000000, 88, 0.442211 (stdev 0.495654), 0:00:00, 597
B: 199, 0, 1, 0, True, 1.000000, 100, 0.502513 (stdev 0.498742), 0:00:00, 0
A: cycle: 199
average reward: 0.442211 (stdev 0.495654)
B: cycle: 199
average reward: 0.502513 (stdev 0.498742)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 200, 1, 1, 0, True, 1.000000, 89, 0.445000 (stdev 0.495406), 0:00:00, 600
B: 200, 1, 0, 1, True, 1.000000, 100, 0.500000 (stdev 0.498742), 0:00:00, 0
A: cycle: 200
average reward: 0.445000 (stdev 0.495406)
B: cycle: 200
average reward: 0.500000 (stdev 0.498742)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 201, 0, 1, 1, True, 1.000000, 90, 0.447761 (stdev 0.495728), 0:00:00, 603
B: 201, 0, 0, 0, True, 1.000000, 100, 0.497512 (stdev 0.498755), 0:00:00, 0
A: cycle: 201
average reward: 0.447761 (stdev 0.495728)
B: cycle: 201
average reward: 0.497512 (stdev 0.498755)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 202, 1, 1, 1, True, 1.000000, 91, 0.450495 (stdev 0.496031), 0:00:00, 606
B: 202, 1, 0, 1, True, 1.000000, 100, 0.495050 (stdev 0.498755), 0:00:00, 0
A: cycle: 202
average reward: 0.450495 (stdev 0.496031)
B: cycle: 202
average reward: 0.495050 (stdev 0.498755)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 203, 0, 0, 0, True, 1.000000, 91, 0.448276 (stdev 0.496316), 0:00:00, 609
B: 203, 0, 0, 0, True, 1.000000, 100, 0.492611 (stdev 0.498743), 0:00:00, 0
A: cycle: 203
average reward: 0.448276 (stdev 0.496316)
B: cycle: 203
average reward: 0.492611 (stdev 0.498743)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 204, 1, 0, 1, True, 1.000000, 91, 0.446078 (stdev 0.496097), 0:00:00, 612
B: 204, 1, 0, 1, True, 1.000000, 100, 0.490196 (stdev 0.498719), 0:00:00, 0
A: cycle: 204
average reward: 0.446078 (stdev 0.496097)
B: cycle: 204
average reward: 0.490196 (stdev 0.498719)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 205, 0, 0, 0, True, 1.000000, 91, 0.443902 (stdev 0.495870), 0:00:00, 615
B: 205, 0, 0, 1, True, 1.000000, 100, 0.487805 (stdev 0.498683), 0:00:00, 0
A: cycle: 205
average reward: 0.443902 (stdev 0.495870)
B: cycle: 205
average reward: 0.487805 (stdev 0.498683)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 206, 1, 0, 0, True, 1.000000, 91, 0.441748 (stdev 0.495636), 0:00:00, 618
B: 206, 1, 1, 1, True, 1.000000, 101, 0.490291 (stdev 0.498637), 0:00:00, 0
A: cycle: 206
average reward: 0.441748 (stdev 0.495636)
B: cycle: 206
average reward: 0.490291 (stdev 0.498637)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 207, 0, 1, 1, True, 1.000000, 92, 0.444444 (stdev 0.495394), 0:00:00, 621
B: 207, 0, 0, 0, True, 1.000000, 101, 0.487923 (stdev 0.498697), 0:00:00, 0
A: cycle: 207
average reward: 0.444444 (stdev 0.495394)
B: cycle: 207
average reward: 0.487923 (stdev 0.498697)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 208, 1, 1, 0, True, 1.000000, 93, 0.447115 (stdev 0.495708), 0:00:00, 624
B: 208, 1, 0, 1, True, 1.000000, 101, 0.485577 (stdev 0.498651), 0:00:00, 0
A: cycle: 208
average reward: 0.447115 (stdev 0.495708)
B: cycle: 208
average reward: 0.485577 (stdev 0.498651)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 209, 0, 1, 1, True, 1.000000, 94, 0.449761 (stdev 0.496004), 0:00:00.015625, 627
B: 209, 0, 0, 1, True, 1.000000, 101, 0.483254 (stdev 0.498595), 0:00:00, 0
A: cycle: 209
average reward: 0.449761 (stdev 0.496004)
B: cycle: 209
average reward: 0.483254 (stdev 0.498595)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 210, 1, 1, 1, True, 1.000000, 95, 0.452381 (stdev 0.496284), 0:00:00, 630
B: 210, 1, 1, 0, True, 1.000000, 102, 0.485714 (stdev 0.498528), 0:00:00, 0
A: cycle: 210
average reward: 0.452381 (stdev 0.496284)
B: cycle: 210
average reward: 0.485714 (stdev 0.498528)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 211, 0, 0, 1, True, 1.000000, 95, 0.450237 (stdev 0.496546), 0:00:00, 633
B: 211, 0, 1, 0, True, 1.000000, 103, 0.488152 (stdev 0.498610), 0:00:00, 0
A: cycle: 211
average reward: 0.450237 (stdev 0.496546)
B: cycle: 211
average reward: 0.488152 (stdev 0.498610)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 212, 1, 1, 1, True, 1.000000, 96, 0.452830 (stdev 0.496343), 0:00:00, 636
B: 212, 1, 0, 0, True, 1.000000, 103, 0.485849 (stdev 0.498679), 0:00:00, 0
A: cycle: 212
average reward: 0.452830 (stdev 0.496343)
B: cycle: 212
average reward: 0.485849 (stdev 0.498679)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 213, 0, 0, 0, True, 1.000000, 96, 0.450704 (stdev 0.496600), 0:00:00, 639
B: 213, 0, 1, 1, True, 1.000000, 104, 0.488263 (stdev 0.498625), 0:00:00, 0
A: cycle: 213
average reward: 0.450704 (stdev 0.496600)
B: cycle: 213
average reward: 0.488263 (stdev 0.498625)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 214, 1, 0, 1, True, 1.000000, 96, 0.448598 (stdev 0.496400), 0:00:00, 642
B: 214, 1, 1, 0, True, 1.000000, 105, 0.490654 (stdev 0.498693), 0:00:00, 0
A: cycle: 214
average reward: 0.448598 (stdev 0.496400)
B: cycle: 214
average reward: 0.490654 (stdev 0.498693)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 215, 0, 0, 0, True, 1.000000, 96, 0.446512 (stdev 0.496193), 0:00:00, 645
B: 215, 0, 1, 0, True, 1.000000, 106, 0.493023 (stdev 0.498749), 0:00:00, 0
A: cycle: 215
average reward: 0.446512 (stdev 0.496193)
B: cycle: 215
average reward: 0.493023 (stdev 0.498749)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 216, 1, 0, 0, True, 1.000000, 96, 0.444444 (stdev 0.495979), 0:00:00, 648
B: 216, 1, 0, 1, True, 1.000000, 106, 0.490741 (stdev 0.498793), 0:00:00, 0
A: cycle: 216
average reward: 0.444444 (stdev 0.495979)
B: cycle: 216
average reward: 0.490741 (stdev 0.498793)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 217, 0, 1, 0, True, 1.000000, 97, 0.447005 (stdev 0.495758), 0:00:00, 651
B: 217, 0, 0, 1, True, 1.000000, 106, 0.488479 (stdev 0.498761), 0:00:00, 0
A: cycle: 217
average reward: 0.447005 (stdev 0.495758)
B: cycle: 217
average reward: 0.488479 (stdev 0.498761)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 218, 1, 0, 1, True, 1.000000, 97, 0.444954 (stdev 0.496042), 0:00:00, 654
B: 218, 1, 1, 0, True, 1.000000, 107, 0.490826 (stdev 0.498719), 0:00:00, 0
A: cycle: 218
average reward: 0.444954 (stdev 0.496042)
B: cycle: 218
average reward: 0.490826 (stdev 0.498719)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 219, 0, 0, 1, True, 1.000000, 97, 0.442922 (stdev 0.495825), 0:00:00, 657
B: 219, 0, 1, 0, True, 1.000000, 108, 0.493151 (stdev 0.498773), 0:00:00, 0
A: cycle: 219
average reward: 0.442922 (stdev 0.495825)
B: cycle: 219
average reward: 0.493151 (stdev 0.498773)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 220, 1, 1, 0, True, 1.000000, 98, 0.445455 (stdev 0.495601), 0:00:00, 660
B: 220, 1, 0, 1, True, 1.000000, 108, 0.490909 (stdev 0.498816), 0:00:00, 0
A: cycle: 220
average reward: 0.445455 (stdev 0.495601)
B: cycle: 220
average reward: 0.490909 (stdev 0.498816)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 221, 0, 1, 1, True, 1.000000, 99, 0.447964 (stdev 0.495890), 0:00:00, 663
B: 221, 0, 0, 1, True, 1.000000, 108, 0.488688 (stdev 0.498785), 0:00:00, 0
A: cycle: 221
average reward: 0.447964 (stdev 0.495890)
B: cycle: 221
average reward: 0.488688 (stdev 0.498785)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 222, 1, 1, 0, True, 1.000000, 100, 0.450450 (stdev 0.496164), 0:00:00, 666
B: 222, 1, 1, 1, True, 1.000000, 109, 0.490991 (stdev 0.498745), 0:00:00, 0
A: cycle: 222
average reward: 0.450450 (stdev 0.496164)
B: cycle: 222
average reward: 0.490991 (stdev 0.498745)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 223, 0, 1, 1, True, 1.000000, 101, 0.452915 (stdev 0.496422), 0:00:00, 669
B: 223, 0, 0, 1, True, 1.000000, 109, 0.488789 (stdev 0.498797), 0:00:00, 0
A: cycle: 223
average reward: 0.452915 (stdev 0.496422)
B: cycle: 223
average reward: 0.488789 (stdev 0.498797)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 224, 1, 1, 0, True, 1.000000, 102, 0.455357 (stdev 0.496666), 0:00:00, 672
B: 224, 1, 1, 1, True, 1.000000, 110, 0.491071 (stdev 0.498757), 0:00:00, 0
A: cycle: 224
average reward: 0.455357 (stdev 0.496666)
B: cycle: 224
average reward: 0.491071 (stdev 0.498757)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 225, 0, 1, 0, True, 1.000000, 103, 0.457778 (stdev 0.496895), 0:00:00, 675
B: 225, 0, 0, 0, True, 1.000000, 110, 0.488889 (stdev 0.498808), 0:00:00, 0
A: cycle: 225
average reward: 0.457778 (stdev 0.496895)
B: cycle: 225
average reward: 0.488889 (stdev 0.498808)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 226, 1, 0, 0, True, 1.000000, 103, 0.455752 (stdev 0.497111), 0:00:00, 678
B: 226, 1, 0, 0, True, 1.000000, 110, 0.486726 (stdev 0.498769), 0:00:00, 0
A: cycle: 226
average reward: 0.455752 (stdev 0.497111)
B: cycle: 226
average reward: 0.486726 (stdev 0.498769)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 227, 0, 1, 0, True, 1.000000, 104, 0.458150 (stdev 0.496940), 0:00:00, 681
B: 227, 0, 1, 0, True, 1.000000, 111, 0.488987 (stdev 0.498722), 0:00:00, 0
A: cycle: 227
average reward: 0.458150 (stdev 0.496940)
B: cycle: 227
average reward: 0.488987 (stdev 0.498722)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 228, 1, 0, 1, True, 1.000000, 104, 0.456140 (stdev 0.497152), 0:00:00, 684
B: 228, 1, 0, 0, True, 1.000000, 111, 0.486842 (stdev 0.498781), 0:00:00, 0
A: cycle: 228
average reward: 0.456140 (stdev 0.497152)
B: cycle: 228
average reward: 0.486842 (stdev 0.498781)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 229, 0, 0, 0, True, 1.000000, 104, 0.454148 (stdev 0.496984), 0:00:00, 687
B: 229, 0, 1, 1, True, 1.000000, 112, 0.489083 (stdev 0.498734), 0:00:00, 0
A: cycle: 229
average reward: 0.454148 (stdev 0.496984)
B: cycle: 229
average reward: 0.489083 (stdev 0.498734)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 230, 1, 0, 1, True, 1.000000, 104, 0.452174 (stdev 0.496810), 0:00:00, 690
B: 230, 1, 1, 0, True, 1.000000, 113, 0.491304 (stdev 0.498793), 0:00:00, 0
A: cycle: 230
average reward: 0.452174 (stdev 0.496810)
B: cycle: 230
average reward: 0.491304 (stdev 0.498793)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 231, 0, 0, 0, True, 1.000000, 104, 0.450216 (stdev 0.496629), 0:00:00, 693
B: 231, 0, 1, 1, True, 1.000000, 114, 0.493506 (stdev 0.498841), 0:00:00, 0
A: cycle: 231
average reward: 0.450216 (stdev 0.496629)
B: cycle: 231
average reward: 0.493506 (stdev 0.498841)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 232, 1, 0, 0, True, 1.000000, 104, 0.448276 (stdev 0.496442), 0:00:00, 696
B: 232, 1, 1, 0, True, 1.000000, 115, 0.495690 (stdev 0.498879), 0:00:00, 0
A: cycle: 232
average reward: 0.448276 (stdev 0.496442)
B: cycle: 232
average reward: 0.495690 (stdev 0.498879)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 233, 0, 1, 0, True, 1.000000, 105, 0.450644 (stdev 0.496249), 0:00:00, 699
B: 233, 0, 1, 0, True, 1.000000, 116, 0.497854 (stdev 0.498907), 0:00:00, 0
A: cycle: 233
average reward: 0.450644 (stdev 0.496249)
B: cycle: 233
average reward: 0.497854 (stdev 0.498907)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 234, 1, 0, 1, True, 1.000000, 105, 0.448718 (stdev 0.496494), 0:00:00, 702
B: 234, 1, 0, 0, True, 1.000000, 116, 0.495726 (stdev 0.498926), 0:00:00, 0
A: cycle: 234
average reward: 0.448718 (stdev 0.496494)
B: cycle: 234
average reward: 0.495726 (stdev 0.498926)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 235, 0, 0, 1, True, 1.000000, 105, 0.446809 (stdev 0.496304), 0:00:00, 705
B: 235, 0, 1, 1, True, 1.000000, 117, 0.497872 (stdev 0.498917), 0:00:00, 0
A: cycle: 235
average reward: 0.446809 (stdev 0.496304)
B: cycle: 235
average reward: 0.497872 (stdev 0.498917)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 236, 1, 1, 0, True, 1.000000, 106, 0.449153 (stdev 0.496108), 0:00:00, 708
B: 236, 1, 1, 1, True, 1.000000, 118, 0.500000 (stdev 0.498935), 0:00:00, 0
A: cycle: 236
average reward: 0.449153 (stdev 0.496108)
B: cycle: 236
average reward: 0.500000 (stdev 0.498935)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 237, 0, 1, 0, True, 1.000000, 107, 0.451477 (stdev 0.496357), 0:00:00, 711
B: 237, 0, 0, 1, True, 1.000000, 118, 0.497890 (stdev 0.498944), 0:00:00, 0
A: cycle: 237
average reward: 0.451477 (stdev 0.496357)
B: cycle: 237
average reward: 0.497890 (stdev 0.498944)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 238, 1, 0, 1, True, 1.000000, 107, 0.449580 (stdev 0.496593), 0:00:00, 714
B: 238, 1, 1, 1, True, 1.000000, 119, 0.500000 (stdev 0.498944), 0:00:00, 0
A: cycle: 238
average reward: 0.449580 (stdev 0.496593)
B: cycle: 238
average reward: 0.500000 (stdev 0.498944)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 239, 0, 0, 1, True, 1.000000, 107, 0.447699 (stdev 0.496410), 0:00:00, 717
B: 239, 0, 0, 1, True, 1.000000, 119, 0.497908 (stdev 0.498953), 0:00:00, 0
A: cycle: 239
average reward: 0.447699 (stdev 0.496410)
B: cycle: 239
average reward: 0.497908 (stdev 0.498953)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 240, 1, 1, 1, True, 1.000000, 108, 0.450000 (stdev 0.496220), 0:00:00, 720
B: 240, 1, 1, 0, True, 1.000000, 120, 0.500000 (stdev 0.498953), 0:00:00, 0
A: cycle: 240
average reward: 0.450000 (stdev 0.496220)
B: cycle: 240
average reward: 0.500000 (stdev 0.498953)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 241, 0, 0, 0, True, 1.000000, 108, 0.448133 (stdev 0.496461), 0:00:00, 723
B: 241, 0, 1, 0, True, 1.000000, 121, 0.502075 (stdev 0.498962), 0:00:00, 0
A: cycle: 241
average reward: 0.448133 (stdev 0.496461)
B: cycle: 241
average reward: 0.502075 (stdev 0.498962)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 242, 1, 0, 1, True, 1.000000, 108, 0.446281 (stdev 0.496274), 0:00:00, 726
B: 242, 1, 0, 0, True, 1.000000, 121, 0.500000 (stdev 0.498962), 0:00:00, 0
A: cycle: 242
average reward: 0.446281 (stdev 0.496274)
B: cycle: 242
average reward: 0.500000 (stdev 0.498962)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 243, 0, 0, 1, True, 1.000000, 108, 0.444444 (stdev 0.496082), 0:00:00, 729
B: 243, 0, 1, 1, True, 1.000000, 122, 0.502058 (stdev 0.498970), 0:00:00, 0
A: cycle: 243
average reward: 0.444444 (stdev 0.496082)
B: cycle: 243
average reward: 0.502058 (stdev 0.498970)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 244, 1, 1, 1, True, 1.000000, 109, 0.446721 (stdev 0.495885), 0:00:00, 732
B: 244, 1, 1, 0, True, 1.000000, 123, 0.504098 (stdev 0.498970), 0:00:00, 0
A: cycle: 244
average reward: 0.446721 (stdev 0.495885)
B: cycle: 244
average reward: 0.504098 (stdev 0.498970)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 245, 0, 0, 0, True, 1.000000, 109, 0.444898 (stdev 0.496138), 0:00:00, 735
B: 245, 0, 1, 1, True, 1.000000, 124, 0.506122 (stdev 0.498962), 0:00:00, 0
A: cycle: 245
average reward: 0.444898 (stdev 0.496138)
B: cycle: 245
average reward: 0.506122 (stdev 0.498962)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 246, 1, 0, 0, True, 1.000000, 109, 0.443089 (stdev 0.495943), 0:00:00, 738
B: 246, 1, 1, 0, True, 1.000000, 125, 0.508130 (stdev 0.498945), 0:00:00, 0
A: cycle: 246
average reward: 0.443089 (stdev 0.495943)
B: cycle: 246
average reward: 0.508130 (stdev 0.498945)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 247, 0, 1, 0, True, 1.000000, 110, 0.445344 (stdev 0.495744), 0:00:00, 741
B: 247, 0, 1, 0, True, 1.000000, 126, 0.510121 (stdev 0.498921), 0:00:00, 0
A: cycle: 247
average reward: 0.445344 (stdev 0.495744)
B: cycle: 247
average reward: 0.510121 (stdev 0.498921)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 248, 1, 0, 0, True, 1.000000, 110, 0.443548 (stdev 0.496001), 0:00:00, 744
B: 248, 1, 0, 1, True, 1.000000, 126, 0.508065 (stdev 0.498889), 0:00:00, 0
A: cycle: 248
average reward: 0.443548 (stdev 0.496001)
B: cycle: 248
average reward: 0.508065 (stdev 0.498889)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 249, 0, 1, 0, True, 1.000000, 111, 0.445783 (stdev 0.495804), 0:00:00.015624, 747
B: 249, 0, 0, 1, True, 1.000000, 126, 0.506024 (stdev 0.498930), 0:00:00, 0
A: cycle: 249
average reward: 0.445783 (stdev 0.495804)
B: cycle: 249
average reward: 0.506024 (stdev 0.498930)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 250, 1, 0, 0, True, 1.000000, 111, 0.444000 (stdev 0.496057), 0:00:00, 750
B: 250, 1, 1, 1, True, 1.000000, 127, 0.508000 (stdev 0.498963), 0:00:00, 0
A: cycle: 250
average reward: 0.444000 (stdev 0.496057)
B: cycle: 250
average reward: 0.508000 (stdev 0.498963)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 251, 0, 1, 0, True, 1.000000, 112, 0.446215 (stdev 0.495863), 0:00:00, 753
B: 251, 0, 0, 1, True, 1.000000, 127, 0.505976 (stdev 0.498939), 0:00:00, 0
A: cycle: 251
average reward: 0.446215 (stdev 0.495863)
B: cycle: 251
average reward: 0.505976 (stdev 0.498939)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 252, 1, 0, 1, True, 1.000000, 112, 0.444444 (stdev 0.496111), 0:00:00, 756
B: 252, 1, 1, 0, True, 1.000000, 128, 0.507937 (stdev 0.498971), 0:00:00, 0
A: cycle: 252
average reward: 0.444444 (stdev 0.496111)
B: cycle: 252
average reward: 0.507937 (stdev 0.498971)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 253, 0, 0, 1, True, 1.000000, 112, 0.442688 (stdev 0.495921), 0:00:00, 759
B: 253, 0, 1, 0, True, 1.000000, 129, 0.509881 (stdev 0.498948), 0:00:00, 0
A: cycle: 253
average reward: 0.442688 (stdev 0.495921)
B: cycle: 253
average reward: 0.509881 (stdev 0.498948)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 254, 1, 1, 1, True, 1.000000, 113, 0.444882 (stdev 0.495726), 0:00:00, 762
B: 254, 1, 0, 0, True, 1.000000, 129, 0.507874 (stdev 0.498917), 0:00:00, 0
A: cycle: 254
average reward: 0.444882 (stdev 0.495726)
B: cycle: 254
average reward: 0.507874 (stdev 0.498917)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 255, 0, 0, 0, True, 1.000000, 113, 0.443137 (stdev 0.495977), 0:00:00, 765
B: 255, 0, 1, 0, True, 1.000000, 130, 0.509804 (stdev 0.498957), 0:00:00, 0
A: cycle: 255
average reward: 0.443137 (stdev 0.495977)
B: cycle: 255
average reward: 0.509804 (stdev 0.498957)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 256, 1, 0, 0, True, 1.000000, 113, 0.441406 (stdev 0.495785), 0:00:00, 768
B: 256, 1, 0, 1, True, 1.000000, 130, 0.507812 (stdev 0.498927), 0:00:00, 0
A: cycle: 256
average reward: 0.441406 (stdev 0.495785)
B: cycle: 256
average reward: 0.507812 (stdev 0.498927)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 257, 0, 1, 0, True, 1.000000, 114, 0.443580 (stdev 0.495588), 0:00:00, 771
B: 257, 0, 0, 0, True, 1.000000, 130, 0.505837 (stdev 0.498965), 0:00:00, 0
A: cycle: 257
average reward: 0.443580 (stdev 0.495588)
B: cycle: 257
average reward: 0.505837 (stdev 0.498965)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 258, 1, 0, 1, True, 1.000000, 114, 0.441860 (stdev 0.495843), 0:00:00, 774
B: 258, 1, 0, 0, True, 1.000000, 130, 0.503876 (stdev 0.498996), 0:00:00, 0
A: cycle: 258
average reward: 0.441860 (stdev 0.495843)
B: cycle: 258
average reward: 0.503876 (stdev 0.498996)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 259, 0, 0, 0, True, 1.000000, 114, 0.440154 (stdev 0.495649), 0:00:00, 777
B: 259, 0, 1, 0, True, 1.000000, 131, 0.505792 (stdev 0.499019), 0:00:00, 0
A: cycle: 259
average reward: 0.440154 (stdev 0.495649)
B: cycle: 259
average reward: 0.505792 (stdev 0.499019)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 260, 1, 0, 1, True, 1.000000, 114, 0.438462 (stdev 0.495450), 0:00:00, 780
B: 260, 1, 0, 0, True, 1.000000, 131, 0.503846 (stdev 0.499004), 0:00:00, 0
A: cycle: 260
average reward: 0.438462 (stdev 0.495450)
B: cycle: 260
average reward: 0.503846 (stdev 0.499004)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 261, 0, 0, 1, True, 1.000000, 114, 0.436782 (stdev 0.495247), 0:00:00, 783
B: 261, 0, 1, 0, True, 1.000000, 132, 0.505747 (stdev 0.499026), 0:00:00, 0
A: cycle: 261
average reward: 0.436782 (stdev 0.495247)
B: cycle: 261
average reward: 0.505747 (stdev 0.499026)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 262, 1, 1, 0, True, 1.000000, 115, 0.438931 (stdev 0.495040), 0:00:00, 786
B: 262, 1, 0, 0, True, 1.000000, 132, 0.503817 (stdev 0.499012), 0:00:00, 0
A: cycle: 262
average reward: 0.438931 (stdev 0.495040)
B: cycle: 262
average reward: 0.503817 (stdev 0.499012)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 263, 0, 1, 1, True, 1.000000, 116, 0.441065 (stdev 0.495312), 0:00:00, 789
B: 263, 0, 1, 1, True, 1.000000, 133, 0.505703 (stdev 0.499034), 0:00:00, 0
A: cycle: 263
average reward: 0.441065 (stdev 0.495312)
B: cycle: 263
average reward: 0.505703 (stdev 0.499034)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 264, 1, 1, 0, True, 1.000000, 117, 0.443182 (stdev 0.495573), 0:00:00, 792
B: 264, 1, 1, 0, True, 1.000000, 134, 0.507576 (stdev 0.499020), 0:00:00, 0
A: cycle: 264
average reward: 0.443182 (stdev 0.495573)
B: cycle: 264
average reward: 0.507576 (stdev 0.499020)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 265, 0, 1, 0, True, 1.000000, 118, 0.445283 (stdev 0.495823), 0:00:00, 795
B: 265, 0, 1, 1, True, 1.000000, 135, 0.509434 (stdev 0.498998), 0:00:00, 0
A: cycle: 265
average reward: 0.445283 (stdev 0.495823)
B: cycle: 265
average reward: 0.509434 (stdev 0.498998)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 266, 1, 0, 0, True, 1.000000, 118, 0.443609 (stdev 0.496062), 0:00:00, 798
B: 266, 1, 1, 1, True, 1.000000, 136, 0.511278 (stdev 0.498970), 0:00:00, 0
A: cycle: 266
average reward: 0.443609 (stdev 0.496062)
B: cycle: 266
average reward: 0.511278 (stdev 0.498970)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 267, 0, 1, 1, True, 1.000000, 119, 0.445693 (stdev 0.495879), 0:00:00, 801
B: 267, 0, 0, 1, True, 1.000000, 136, 0.509363 (stdev 0.498936), 0:00:00, 0
A: cycle: 267
average reward: 0.445693 (stdev 0.495879)
B: cycle: 267
average reward: 0.509363 (stdev 0.498936)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 268, 1, 1, 0, True, 1.000000, 120, 0.447761 (stdev 0.496114), 0:00:00, 804
B: 268, 1, 1, 1, True, 1.000000, 137, 0.511194 (stdev 0.498979), 0:00:00, 0
A: cycle: 268
average reward: 0.447761 (stdev 0.496114)
B: cycle: 268
average reward: 0.511194 (stdev 0.498979)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 269, 0, 1, 1, True, 1.000000, 121, 0.449814 (stdev 0.496338), 0:00:00, 807
B: 269, 0, 0, 0, True, 1.000000, 137, 0.509294 (stdev 0.498945), 0:00:00, 0
A: cycle: 269
average reward: 0.449814 (stdev 0.496338)
B: cycle: 269
average reward: 0.509294 (stdev 0.498945)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 270, 1, 1, 1, True, 1.000000, 122, 0.451852 (stdev 0.496553), 0:00:00, 810
B: 270, 1, 0, 1, True, 1.000000, 137, 0.507407 (stdev 0.498987), 0:00:00, 0
A: cycle: 270
average reward: 0.451852 (stdev 0.496553)
B: cycle: 270
average reward: 0.507407 (stdev 0.498987)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 271, 0, 0, 1, True, 1.000000, 122, 0.450185 (stdev 0.496757), 0:00:00, 813
B: 271, 0, 0, 0, True, 1.000000, 137, 0.505535 (stdev 0.499022), 0:00:00, 0
A: cycle: 271
average reward: 0.450185 (stdev 0.496757)
B: cycle: 271
average reward: 0.505535 (stdev 0.499022)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 272, 1, 1, 1, True, 1.000000, 123, 0.452206 (stdev 0.496597), 0:00:00, 816
B: 272, 1, 0, 0, True, 1.000000, 137, 0.503676 (stdev 0.499049), 0:00:00, 0
A: cycle: 272
average reward: 0.452206 (stdev 0.496597)
B: cycle: 272
average reward: 0.503676 (stdev 0.499049)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 273, 0, 0, 0, True, 1.000000, 123, 0.450549 (stdev 0.496798), 0:00:00, 819
B: 273, 0, 1, 0, True, 1.000000, 138, 0.505495 (stdev 0.499070), 0:00:00, 0
A: cycle: 273
average reward: 0.450549 (stdev 0.496798)
B: cycle: 273
average reward: 0.505495 (stdev 0.499070)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 274, 1, 0, 1, True, 1.000000, 123, 0.448905 (stdev 0.496640), 0:00:00, 822
B: 274, 1, 0, 0, True, 1.000000, 138, 0.503650 (stdev 0.499057), 0:00:00, 0
A: cycle: 274
average reward: 0.448905 (stdev 0.496640)
B: cycle: 274
average reward: 0.503650 (stdev 0.499057)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 275, 0, 0, 0, True, 1.000000, 123, 0.447273 (stdev 0.496477), 0:00:00, 825
B: 275, 0, 1, 0, True, 1.000000, 139, 0.505455 (stdev 0.499077), 0:00:00, 0
A: cycle: 275
average reward: 0.447273 (stdev 0.496477)
B: cycle: 275
average reward: 0.505455 (stdev 0.499077)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 276, 1, 0, 1, True, 1.000000, 123, 0.445652 (stdev 0.496310), 0:00:00, 828
B: 276, 1, 0, 1, True, 1.000000, 139, 0.503623 (stdev 0.499064), 0:00:00, 0
A: cycle: 276
average reward: 0.445652 (stdev 0.496310)
B: cycle: 276
average reward: 0.503623 (stdev 0.499064)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 277, 0, 0, 1, True, 1.000000, 123, 0.444043 (stdev 0.496140), 0:00:00, 831
B: 277, 0, 0, 1, True, 1.000000, 139, 0.501805 (stdev 0.499084), 0:00:00, 0
A: cycle: 277
average reward: 0.444043 (stdev 0.496140)
B: cycle: 277
average reward: 0.501805 (stdev 0.499084)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 278, 1, 1, 1, True, 1.000000, 124, 0.446043 (stdev 0.495965), 0:00:00, 834
B: 278, 1, 1, 1, True, 1.000000, 140, 0.503597 (stdev 0.499097), 0:00:00, 0
A: cycle: 278
average reward: 0.446043 (stdev 0.495965)
B: cycle: 278
average reward: 0.503597 (stdev 0.499097)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 279, 0, 0, 1, True, 1.000000, 124, 0.444444 (stdev 0.496189), 0:00:00, 837
B: 279, 0, 0, 1, True, 1.000000, 140, 0.501792 (stdev 0.499090), 0:00:00, 0
A: cycle: 279
average reward: 0.444444 (stdev 0.496189)
B: cycle: 279
average reward: 0.501792 (stdev 0.499090)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 280, 1, 1, 0, True, 1.000000, 125, 0.446429 (stdev 0.496016), 0:00:00, 840
B: 280, 1, 1, 1, True, 1.000000, 141, 0.503571 (stdev 0.499103), 0:00:00, 0
A: cycle: 280
average reward: 0.446429 (stdev 0.496016)
B: cycle: 280
average reward: 0.503571 (stdev 0.499103)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 281, 0, 1, 1, True, 1.000000, 126, 0.448399 (stdev 0.496236), 0:00:00, 843
B: 281, 0, 0, 0, True, 1.000000, 141, 0.501779 (stdev 0.499097), 0:00:00, 0
A: cycle: 281
average reward: 0.448399 (stdev 0.496236)
B: cycle: 281
average reward: 0.501779 (stdev 0.499097)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 282, 1, 1, 1, True, 1.000000, 127, 0.450355 (stdev 0.496448), 0:00:00, 846
B: 282, 1, 0, 0, True, 1.000000, 141, 0.500000 (stdev 0.499110), 0:00:00, 0
A: cycle: 282
average reward: 0.450355 (stdev 0.496448)
B: cycle: 282
average reward: 0.500000 (stdev 0.499110)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 283, 0, 0, 0, True, 1.000000, 127, 0.448763 (stdev 0.496649), 0:00:00, 849
B: 283, 0, 1, 0, True, 1.000000, 142, 0.501767 (stdev 0.499116), 0:00:00, 0
A: cycle: 283
average reward: 0.448763 (stdev 0.496649)
B: cycle: 283
average reward: 0.501767 (stdev 0.499116)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 284, 1, 0, 1, True, 1.000000, 127, 0.447183 (stdev 0.496491), 0:00:00.015625, 852
B: 284, 1, 0, 0, True, 1.000000, 142, 0.500000 (stdev 0.499116), 0:00:00, 0
A: cycle: 284
average reward: 0.447183 (stdev 0.496491)
B: cycle: 284
average reward: 0.500000 (stdev 0.499116)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 285, 0, 0, 0, True, 1.000000, 127, 0.445614 (stdev 0.496329), 0:00:00, 855
B: 285, 0, 1, 0, True, 1.000000, 143, 0.501754 (stdev 0.499122), 0:00:00, 0
A: cycle: 285
average reward: 0.445614 (stdev 0.496329)
B: cycle: 285
average reward: 0.501754 (stdev 0.499122)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 286, 1, 0, 0, True, 1.000000, 127, 0.444056 (stdev 0.496164), 0:00:00, 858
B: 286, 1, 0, 1, True, 1.000000, 143, 0.500000 (stdev 0.499122), 0:00:00, 0
A: cycle: 286
average reward: 0.444056 (stdev 0.496164)
B: cycle: 286
average reward: 0.500000 (stdev 0.499122)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 287, 0, 1, 1, True, 1.000000, 128, 0.445993 (stdev 0.495994), 0:00:00, 861
B: 287, 0, 0, 1, True, 1.000000, 143, 0.498258 (stdev 0.499128), 0:00:00, 0
A: cycle: 287
average reward: 0.445993 (stdev 0.495994)
B: cycle: 287
average reward: 0.498258 (stdev 0.499128)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 288, 1, 1, 0, True, 1.000000, 129, 0.447917 (stdev 0.496211), 0:00:00, 864
B: 288, 1, 1, 0, True, 1.000000, 144, 0.500000 (stdev 0.499128), 0:00:00, 0
A: cycle: 288
average reward: 0.447917 (stdev 0.496211)
B: cycle: 288
average reward: 0.500000 (stdev 0.499128)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 289, 0, 1, 1, True, 1.000000, 130, 0.449827 (stdev 0.496419), 0:00:00, 867
B: 289, 0, 1, 0, True, 1.000000, 145, 0.501730 (stdev 0.499134), 0:00:00, 0
A: cycle: 289
average reward: 0.449827 (stdev 0.496419)
B: cycle: 289
average reward: 0.501730 (stdev 0.499134)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 290, 1, 1, 1, True, 1.000000, 131, 0.451724 (stdev 0.496618), 0:00:00, 870
B: 290, 1, 0, 1, True, 1.000000, 145, 0.500000 (stdev 0.499134), 0:00:00, 0
A: cycle: 290
average reward: 0.451724 (stdev 0.496618)
B: cycle: 290
average reward: 0.500000 (stdev 0.499134)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 291, 0, 0, 1, True, 1.000000, 131, 0.450172 (stdev 0.496808), 0:00:00, 873
B: 291, 0, 0, 0, True, 1.000000, 145, 0.498282 (stdev 0.499140), 0:00:00, 0
A: cycle: 291
average reward: 0.450172 (stdev 0.496808)
B: cycle: 291
average reward: 0.498282 (stdev 0.499140)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 292, 1, 1, 1, True, 1.000000, 132, 0.452055 (stdev 0.496658), 0:00:00, 876
B: 292, 1, 0, 1, True, 1.000000, 145, 0.496575 (stdev 0.499140), 0:00:00, 0
A: cycle: 292
average reward: 0.452055 (stdev 0.496658)
B: cycle: 292
average reward: 0.496575 (stdev 0.499140)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 293, 0, 0, 0, True, 1.000000, 132, 0.450512 (stdev 0.496846), 0:00:00, 879
B: 293, 0, 0, 1, True, 1.000000, 145, 0.494881 (stdev 0.499134), 0:00:00, 0
A: cycle: 293
average reward: 0.450512 (stdev 0.496846)
B: cycle: 293
average reward: 0.494881 (stdev 0.499134)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 294, 1, 0, 0, True, 1.000000, 132, 0.448980 (stdev 0.496698), 0:00:00, 882
B: 294, 1, 1, 0, True, 1.000000, 146, 0.496599 (stdev 0.499123), 0:00:00, 0
A: cycle: 294
average reward: 0.448980 (stdev 0.496698)
B: cycle: 294
average reward: 0.496599 (stdev 0.499123)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 295, 0, 1, 0, True, 1.000000, 133, 0.450847 (stdev 0.496546), 0:00:00, 885
B: 295, 0, 1, 0, True, 1.000000, 147, 0.498305 (stdev 0.499140), 0:00:00, 0
A: cycle: 295
average reward: 0.450847 (stdev 0.496546)
B: cycle: 295
average reward: 0.498305 (stdev 0.499140)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 296, 1, 0, 0, True, 1.000000, 133, 0.449324 (stdev 0.496737), 0:00:00, 888
B: 296, 1, 0, 1, True, 1.000000, 147, 0.496622 (stdev 0.499152), 0:00:00, 0
A: cycle: 296
average reward: 0.449324 (stdev 0.496737)
B: cycle: 296
average reward: 0.496622 (stdev 0.499152)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 297, 0, 1, 0, True, 1.000000, 134, 0.451178 (stdev 0.496587), 0:00:00, 891
B: 297, 0, 0, 0, True, 1.000000, 147, 0.494949 (stdev 0.499146), 0:00:00, 0
A: cycle: 297
average reward: 0.451178 (stdev 0.496587)
B: cycle: 297
average reward: 0.494949 (stdev 0.499146)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 298, 1, 0, 0, True, 1.000000, 134, 0.449664 (stdev 0.496775), 0:00:00, 894
B: 298, 1, 0, 1, True, 1.000000, 147, 0.493289 (stdev 0.499135), 0:00:00, 0
A: cycle: 298
average reward: 0.449664 (stdev 0.496775)
B: cycle: 298
average reward: 0.493289 (stdev 0.499135)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 299, 0, 1, 0, True, 1.000000, 135, 0.451505 (stdev 0.496627), 0:00:00, 897
B: 299, 0, 0, 0, True, 1.000000, 147, 0.491639 (stdev 0.499118), 0:00:00, 0
A: cycle: 299
average reward: 0.451505 (stdev 0.496627)
B: cycle: 299
average reward: 0.491639 (stdev 0.499118)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 300, 1, 0, 1, True, 1.000000, 135, 0.450000 (stdev 0.496813), 0:00:00, 900
B: 300, 1, 0, 1, True, 1.000000, 147, 0.490000 (stdev 0.499096), 0:00:00, 0
A: cycle: 300
average reward: 0.450000 (stdev 0.496813)
B: cycle: 300
average reward: 0.490000 (stdev 0.499096)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0



explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 301, 0, 0, 0, True, 1.000000, 135, 0.448505 (stdev 0.496667), 0:00:00, 903
B: 301, 0, 0, 0, True, 1.000000, 147, 0.488372 (stdev 0.499069), 0:00:00, 0
A: cycle: 301
average reward: 0.448505 (stdev 0.496667)
B: cycle: 301
average reward: 0.488372 (stdev 0.499069)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 302, 1, 0, 0, True, 1.000000, 135, 0.447020 (stdev 0.496517), 0:00:00, 906
B: 302, 1, 0, 0, True, 1.000000, 147, 0.486755 (stdev 0.499036), 0:00:00, 0
A: cycle: 302
average reward: 0.447020 (stdev 0.496517)
B: cycle: 302
average reward: 0.486755 (stdev 0.499036)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 303, 0, 1, 0, True, 1.000000, 136, 0.448845 (stdev 0.496364), 0:00:00, 909
B: 303, 0, 1, 1, True, 1.000000, 148, 0.488449 (stdev 0.498999), 0:00:00, 0
A: cycle: 303
average reward: 0.448845 (stdev 0.496364)
B: cycle: 303
average reward: 0.488449 (stdev 0.498999)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 304, 1, 0, 1, True, 1.000000, 136, 0.447368 (stdev 0.496558), 0:00:00, 912
B: 304, 1, 1, 0, True, 1.000000, 149, 0.490132 (stdev 0.499044), 0:00:00, 0
A: cycle: 304
average reward: 0.447368 (stdev 0.496558)
B: cycle: 304
average reward: 0.490132 (stdev 0.499044)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 305, 0, 0, 1, True, 1.000000, 136, 0.445902 (stdev 0.496406), 0:00:00, 915
B: 305, 0, 1, 1, True, 1.000000, 150, 0.491803 (stdev 0.499082), 0:00:00, 0
A: cycle: 305
average reward: 0.445902 (stdev 0.496406)
B: cycle: 305
average reward: 0.491803 (stdev 0.499082)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 306, 1, 1, 0, True, 1.000000, 137, 0.447712 (stdev 0.496252), 0:00:00, 918
B: 306, 1, 1, 1, True, 1.000000, 151, 0.493464 (stdev 0.499115), 0:00:00, 0
A: cycle: 306
average reward: 0.447712 (stdev 0.496252)
B: cycle: 306
average reward: 0.493464 (stdev 0.499115)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 307, 0, 1, 1, True, 1.000000, 138, 0.449511 (stdev 0.496448), 0:00:00, 921
B: 307, 0, 0, 1, True, 1.000000, 151, 0.491857 (stdev 0.499142), 0:00:00, 0
A: cycle: 307
average reward: 0.449511 (stdev 0.496448)
B: cycle: 307
average reward: 0.491857 (stdev 0.499142)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 308, 1, 1, 0, True, 1.000000, 139, 0.451299 (stdev 0.496636), 0:00:00, 924
B: 308, 1, 1, 1, True, 1.000000, 152, 0.493506 (stdev 0.499121), 0:00:00, 0
A: cycle: 308
average reward: 0.451299 (stdev 0.496636)
B: cycle: 308
average reward: 0.493506 (stdev 0.499121)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 309, 0, 1, 1, True, 1.000000, 140, 0.453074 (stdev 0.496817), 0:00:00, 927
B: 309, 0, 0, 0, True, 1.000000, 152, 0.491909 (stdev 0.499148), 0:00:00, 0
A: cycle: 309
average reward: 0.453074 (stdev 0.496817)
B: cycle: 309
average reward: 0.491909 (stdev 0.499148)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 310, 1, 1, 1, True, 1.000000, 141, 0.454839 (stdev 0.496990), 0:00:00, 930
B: 310, 1, 0, 0, True, 1.000000, 152, 0.490323 (stdev 0.499128), 0:00:00, 0
A: cycle: 310
average reward: 0.454839 (stdev 0.496990)
B: cycle: 310
average reward: 0.490323 (stdev 0.499128)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 311, 0, 0, 1, True, 1.000000, 141, 0.453376 (stdev 0.497155), 0:00:00, 933
B: 311, 0, 1, 0, True, 1.000000, 153, 0.491961 (stdev 0.499102), 0:00:00, 0
A: cycle: 311
average reward: 0.453376 (stdev 0.497155)
B: cycle: 311
average reward: 0.491961 (stdev 0.499102)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 312, 1, 1, 0, True, 1.000000, 142, 0.455128 (stdev 0.497023), 0:00:00, 936
B: 312, 1, 0, 0, True, 1.000000, 153, 0.490385 (stdev 0.499134), 0:00:00, 0
A: cycle: 312
average reward: 0.455128 (stdev 0.497023)
B: cycle: 312
average reward: 0.490385 (stdev 0.499134)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 313, 0, 1, 0, True, 1.000000, 143, 0.456869 (stdev 0.497186), 0:00:00, 939
B: 313, 0, 1, 0, True, 1.000000, 154, 0.492013 (stdev 0.499108), 0:00:00, 0
A: cycle: 313
average reward: 0.456869 (stdev 0.497186)
B: cycle: 313
average reward: 0.492013 (stdev 0.499108)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 314, 1, 0, 1, True, 1.000000, 143, 0.455414 (stdev 0.497342), 0:00:00, 942
B: 314, 1, 0, 0, True, 1.000000, 154, 0.490446 (stdev 0.499139), 0:00:00, 0
A: cycle: 314
average reward: 0.455414 (stdev 0.497342)
B: cycle: 314
average reward: 0.490446 (stdev 0.499139)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 315, 0, 0, 0, True, 1.000000, 143, 0.453968 (stdev 0.497217), 0:00:00.015625, 945
B: 315, 0, 1, 0, True, 1.000000, 155, 0.492063 (stdev 0.499115), 0:00:00, 0
A: cycle: 315
average reward: 0.453968 (stdev 0.497217)
B: cycle: 315
average reward: 0.492063 (stdev 0.499115)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 316, 1, 0, 1, True, 1.000000, 143, 0.452532 (stdev 0.497088), 0:00:00, 948
B: 316, 1, 0, 1, True, 1.000000, 155, 0.490506 (stdev 0.499145), 0:00:00, 0
A: cycle: 316
average reward: 0.452532 (stdev 0.497088)
B: cycle: 316
average reward: 0.490506 (stdev 0.499145)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 317, 0, 0, 1, True, 1.000000, 143, 0.451104 (stdev 0.496956), 0:00:00, 951
B: 317, 0, 0, 1, True, 1.000000, 155, 0.488959 (stdev 0.499121), 0:00:00, 0
A: cycle: 317
average reward: 0.451104 (stdev 0.496956)
B: cycle: 317
average reward: 0.488959 (stdev 0.499121)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 318, 1, 1, 1, True, 1.000000, 144, 0.452830 (stdev 0.496820), 0:00:00, 954
B: 318, 1, 1, 0, True, 1.000000, 156, 0.490566 (stdev 0.499091), 0:00:00, 0
A: cycle: 318
average reward: 0.452830 (stdev 0.496820)
B: cycle: 318
average reward: 0.490566 (stdev 0.499091)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 319, 0, 0, 0, True, 1.000000, 144, 0.451411 (stdev 0.496989), 0:00:00, 957
B: 319, 0, 1, 0, True, 1.000000, 157, 0.492163 (stdev 0.499127), 0:00:00, 0
A: cycle: 319
average reward: 0.451411 (stdev 0.496989)
B: cycle: 319
average reward: 0.492163 (stdev 0.499127)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 320, 1, 0, 1, True, 1.000000, 144, 0.450000 (stdev 0.496855), 0:00:00, 960
B: 320, 1, 0, 0, True, 1.000000, 157, 0.490625 (stdev 0.499157), 0:00:00, 0
A: cycle: 320
average reward: 0.450000 (stdev 0.496855)
B: cycle: 320
average reward: 0.490625 (stdev 0.499157)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 321, 0, 0, 1, True, 1.000000, 144, 0.448598 (stdev 0.496718), 0:00:00, 963
B: 321, 0, 1, 1, True, 1.000000, 158, 0.492212 (stdev 0.499133), 0:00:00, 0
A: cycle: 321
average reward: 0.448598 (stdev 0.496718)
B: cycle: 321
average reward: 0.492212 (stdev 0.499133)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 322, 1, 1, 1, True, 1.000000, 145, 0.450311 (stdev 0.496578), 0:00:00, 966
B: 322, 1, 1, 0, True, 1.000000, 159, 0.493789 (stdev 0.499162), 0:00:00, 0
A: cycle: 322
average reward: 0.450311 (stdev 0.496578)
B: cycle: 322
average reward: 0.493789 (stdev 0.499162)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 323, 0, 0, 0, True, 1.000000, 145, 0.448916 (stdev 0.496754), 0:00:00, 969
B: 323, 0, 1, 1, True, 1.000000, 160, 0.495356 (stdev 0.499187), 0:00:00, 0
A: cycle: 323
average reward: 0.448916 (stdev 0.496754)
B: cycle: 323
average reward: 0.495356 (stdev 0.499187)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 324, 1, 0, 0, True, 1.000000, 145, 0.447531 (stdev 0.496615), 0:00:00, 972
B: 324, 1, 1, 1, True, 1.000000, 161, 0.496914 (stdev 0.499206), 0:00:00, 0
A: cycle: 324
average reward: 0.447531 (stdev 0.496615)
B: cycle: 324
average reward: 0.496914 (stdev 0.499206)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 325, 0, 1, 1, True, 1.000000, 146, 0.449231 (stdev 0.496474), 0:00:00, 975
B: 325, 0, 0, 1, True, 1.000000, 161, 0.495385 (stdev 0.499221), 0:00:00, 0
A: cycle: 325
average reward: 0.449231 (stdev 0.496474)
B: cycle: 325
average reward: 0.495385 (stdev 0.499221)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 326, 1, 1, 1, True, 1.000000, 147, 0.450920 (stdev 0.496652), 0:00:00, 978
B: 326, 1, 1, 1, True, 1.000000, 162, 0.496933 (stdev 0.499211), 0:00:00, 0
A: cycle: 326
average reward: 0.450920 (stdev 0.496652)
B: cycle: 326
average reward: 0.496933 (stdev 0.499211)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 327, 0, 0, 1, True, 1.000000, 147, 0.449541 (stdev 0.496824), 0:00:00, 981
B: 327, 0, 0, 1, True, 1.000000, 162, 0.495413 (stdev 0.499225), 0:00:00, 0
A: cycle: 327
average reward: 0.449541 (stdev 0.496824)
B: cycle: 327
average reward: 0.495413 (stdev 0.499225)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 328, 1, 1, 1, True, 1.000000, 148, 0.451220 (stdev 0.496689), 0:00:00, 984
B: 328, 1, 1, 0, True, 1.000000, 163, 0.496951 (stdev 0.499216), 0:00:00, 0
A: cycle: 328
average reward: 0.451220 (stdev 0.496689)
B: cycle: 328
average reward: 0.496951 (stdev 0.499216)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 329, 0, 0, 1, True, 1.000000, 148, 0.449848 (stdev 0.496858), 0:00:00, 987
B: 329, 0, 1, 1, True, 1.000000, 164, 0.498480 (stdev 0.499230), 0:00:00, 0
A: cycle: 329
average reward: 0.449848 (stdev 0.496858)
B: cycle: 329
average reward: 0.498480 (stdev 0.499230)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 330, 1, 1, 1, True, 1.000000, 149, 0.451515 (stdev 0.496724), 0:00:00, 990
B: 330, 1, 1, 0, True, 1.000000, 165, 0.500000 (stdev 0.499240), 0:00:00, 0
A: cycle: 330
average reward: 0.451515 (stdev 0.496724)
B: cycle: 330
average reward: 0.500000 (stdev 0.499240)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 331, 0, 0, 1, True, 1.000000, 149, 0.450151 (stdev 0.496891), 0:00:00, 993
B: 331, 0, 1, 1, True, 1.000000, 166, 0.501511 (stdev 0.499244), 0:00:00, 0
A: cycle: 331
average reward: 0.450151 (stdev 0.496891)
B: cycle: 331
average reward: 0.501511 (stdev 0.499244)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 332, 1, 1, 0, True, 1.000000, 150, 0.451807 (stdev 0.496759), 0:00:00, 996
B: 332, 1, 1, 0, True, 1.000000, 167, 0.503012 (stdev 0.499244), 0:00:00, 0
A: cycle: 332
average reward: 0.451807 (stdev 0.496759)
B: cycle: 332
average reward: 0.503012 (stdev 0.499244)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 333, 0, 1, 1, True, 1.000000, 151, 0.453453 (stdev 0.496924), 0:00:00, 999
B: 333, 0, 1, 1, True, 1.000000, 168, 0.504505 (stdev 0.499240), 0:00:00, 0
A: cycle: 333
average reward: 0.453453 (stdev 0.496924)
B: cycle: 333
average reward: 0.504505 (stdev 0.499240)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 334, 1, 1, 1, True, 1.000000, 152, 0.455090 (stdev 0.497083), 0:00:00, 1002
B: 334, 1, 1, 1, True, 1.000000, 169, 0.505988 (stdev 0.499231), 0:00:00, 0
A: cycle: 334
average reward: 0.455090 (stdev 0.497083)
B: cycle: 334
average reward: 0.505988 (stdev 0.499231)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 335, 0, 0, 1, True, 1.000000, 152, 0.453731 (stdev 0.497235), 0:00:00, 1005
B: 335, 0, 0, 0, True, 1.000000, 169, 0.504478 (stdev 0.499217), 0:00:00, 0
A: cycle: 335
average reward: 0.453731 (stdev 0.497235)
B: cycle: 335
average reward: 0.504478 (stdev 0.499217)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 336, 1, 1, 0, True, 1.000000, 153, 0.455357 (stdev 0.497113), 0:00:00, 1008
B: 336, 1, 0, 1, True, 1.000000, 169, 0.502976 (stdev 0.499235), 0:00:00, 0
A: cycle: 336
average reward: 0.455357 (stdev 0.497113)
B: cycle: 336
average reward: 0.502976 (stdev 0.499235)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 337, 0, 1, 0, True, 1.000000, 154, 0.456973 (stdev 0.497264), 0:00:00, 1011
B: 337, 0, 0, 1, True, 1.000000, 169, 0.501484 (stdev 0.499249), 0:00:00, 0
A: cycle: 337
average reward: 0.456973 (stdev 0.497264)
B: cycle: 337
average reward: 0.501484 (stdev 0.499249)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 338, 1, 0, 0, True, 1.000000, 154, 0.455621 (stdev 0.497408), 0:00:00, 1014
B: 338, 1, 1, 1, True, 1.000000, 170, 0.502959 (stdev 0.499258), 0:00:00, 0
A: cycle: 338
average reward: 0.455621 (stdev 0.497408)
B: cycle: 338
average reward: 0.502959 (stdev 0.499258)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 339, 0, 1, 1, True, 1.000000, 155, 0.457227 (stdev 0.497292), 0:00:00, 1017
B: 339, 0, 0, 1, True, 1.000000, 170, 0.501475 (stdev 0.499253), 0:00:00, 0
A: cycle: 339
average reward: 0.457227 (stdev 0.497292)
B: cycle: 339
average reward: 0.501475 (stdev 0.499253)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 340, 1, 1, 0, True, 1.000000, 156, 0.458824 (stdev 0.497434), 0:00:00, 1020
B: 340, 1, 1, 0, True, 1.000000, 171, 0.502941 (stdev 0.499262), 0:00:00, 0
A: cycle: 340
average reward: 0.458824 (stdev 0.497434)
B: cycle: 340
average reward: 0.502941 (stdev 0.499262)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 341, 0, 1, 1, True, 1.000000, 157, 0.460411 (stdev 0.497570), 0:00:00, 1023
B: 341, 0, 1, 1, True, 1.000000, 172, 0.504399 (stdev 0.499258), 0:00:00, 0
A: cycle: 341
average reward: 0.460411 (stdev 0.497570)
B: cycle: 341
average reward: 0.504399 (stdev 0.499258)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 342, 1, 1, 1, True, 1.000000, 158, 0.461988 (stdev 0.497701), 0:00:00, 1026
B: 342, 1, 1, 1, True, 1.000000, 173, 0.505848 (stdev 0.499249), 0:00:00, 0
A: cycle: 342
average reward: 0.461988 (stdev 0.497701)
B: cycle: 342
average reward: 0.505848 (stdev 0.499249)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 343, 0, 0, 1, True, 1.000000, 158, 0.460641 (stdev 0.497826), 0:00:00, 1029
B: 343, 0, 0, 1, True, 1.000000, 173, 0.504373 (stdev 0.499236), 0:00:00, 0
A: cycle: 343
average reward: 0.460641 (stdev 0.497826)
B: cycle: 343
average reward: 0.504373 (stdev 0.499236)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 344, 1, 1, 1, True, 1.000000, 159, 0.462209 (stdev 0.497723), 0:00:00, 1032
B: 344, 1, 1, 0, True, 1.000000, 174, 0.505814 (stdev 0.499254), 0:00:00, 0
A: cycle: 344
average reward: 0.462209 (stdev 0.497723)
B: cycle: 344
average reward: 0.505814 (stdev 0.499254)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 345, 0, 0, 1, True, 1.000000, 159, 0.460870 (stdev 0.497847), 0:00:00, 1035
B: 345, 0, 1, 1, True, 1.000000, 175, 0.507246 (stdev 0.499241), 0:00:00, 0
A: cycle: 345
average reward: 0.460870 (stdev 0.497847)
B: cycle: 345
average reward: 0.507246 (stdev 0.499241)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 346, 1, 1, 1, True, 1.000000, 160, 0.462428 (stdev 0.497746), 0:00:00, 1038
B: 346, 1, 1, 1, True, 1.000000, 176, 0.508671 (stdev 0.499224), 0:00:00, 0
A: cycle: 346
average reward: 0.462428 (stdev 0.497746)
B: cycle: 346
average reward: 0.508671 (stdev 0.499224)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 347, 0, 0, 1, True, 1.000000, 160, 0.461095 (stdev 0.497867), 0:00:00, 1041
B: 347, 0, 0, 1, True, 1.000000, 176, 0.507205 (stdev 0.499204), 0:00:00, 0
A: cycle: 347
average reward: 0.461095 (stdev 0.497867)
B: cycle: 347
average reward: 0.507205 (stdev 0.499204)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 348, 1, 1, 0, True, 1.000000, 161, 0.462644 (stdev 0.497767), 0:00:00, 1044
B: 348, 1, 1, 1, True, 1.000000, 177, 0.508621 (stdev 0.499229), 0:00:00, 0
A: cycle: 348
average reward: 0.462644 (stdev 0.497767)
B: cycle: 348
average reward: 0.508621 (stdev 0.499229)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 349, 0, 1, 1, True, 1.000000, 162, 0.464183 (stdev 0.497888), 0:00:00.015625, 1047
B: 349, 0, 0, 1, True, 1.000000, 177, 0.507163 (stdev 0.499209), 0:00:00, 0
A: cycle: 349
average reward: 0.464183 (stdev 0.497888)
B: cycle: 349
average reward: 0.507163 (stdev 0.499209)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 350, 1, 1, 0, True, 1.000000, 163, 0.465714 (stdev 0.498003), 0:00:00, 1050
B: 350, 1, 1, 1, True, 1.000000, 178, 0.508571 (stdev 0.499234), 0:00:00, 0
A: cycle: 350
average reward: 0.465714 (stdev 0.498003)
B: cycle: 350
average reward: 0.508571 (stdev 0.499234)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 351, 0, 1, 1, True, 1.000000, 164, 0.467236 (stdev 0.498112), 0:00:00, 1053
B: 351, 0, 0, 0, True, 1.000000, 178, 0.507123 (stdev 0.499214), 0:00:00, 0
A: cycle: 351
average reward: 0.467236 (stdev 0.498112)
B: cycle: 351
average reward: 0.507123 (stdev 0.499214)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 352, 1, 1, 1, True, 1.000000, 165, 0.468750 (stdev 0.498216), 0:00:00, 1056
B: 352, 1, 0, 0, True, 1.000000, 178, 0.505682 (stdev 0.499239), 0:00:00, 0
A: cycle: 352
average reward: 0.468750 (stdev 0.498216)
B: cycle: 352
average reward: 0.505682 (stdev 0.499239)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 353, 0, 0, 1, True, 1.000000, 165, 0.467422 (stdev 0.498315), 0:00:00, 1059
B: 353, 0, 1, 0, True, 1.000000, 179, 0.507082 (stdev 0.499259), 0:00:00, 0
A: cycle: 353
average reward: 0.467422 (stdev 0.498315)
B: cycle: 353
average reward: 0.507082 (stdev 0.499259)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 354, 1, 1, 1, True, 1.000000, 166, 0.468927 (stdev 0.498232), 0:00:00, 1062
B: 354, 1, 0, 1, True, 1.000000, 179, 0.505650 (stdev 0.499243), 0:00:00, 0
A: cycle: 354
average reward: 0.468927 (stdev 0.498232)
B: cycle: 354
average reward: 0.505650 (stdev 0.499243)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 355, 0, 0, 0, True, 1.000000, 166, 0.467606 (stdev 0.498330), 0:00:00, 1065
B: 355, 0, 0, 1, True, 1.000000, 179, 0.504225 (stdev 0.499263), 0:00:00, 0
A: cycle: 355
average reward: 0.467606 (stdev 0.498330)
B: cycle: 355
average reward: 0.504225 (stdev 0.499263)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 356, 1, 0, 1, True, 1.000000, 166, 0.466292 (stdev 0.498248), 0:00:00, 1068
B: 356, 1, 1, 1, True, 1.000000, 180, 0.505618 (stdev 0.499279), 0:00:00, 0
A: cycle: 356
average reward: 0.466292 (stdev 0.498248)
B: cycle: 356
average reward: 0.505618 (stdev 0.499279)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 357, 0, 0, 1, True, 1.000000, 166, 0.464986 (stdev 0.498163), 0:00:00, 1071
B: 357, 0, 0, 1, True, 1.000000, 180, 0.504202 (stdev 0.499268), 0:00:00, 0
A: cycle: 357
average reward: 0.464986 (stdev 0.498163)
B: cycle: 357
average reward: 0.504202 (stdev 0.499268)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 358, 1, 1, 0, True, 1.000000, 167, 0.466480 (stdev 0.498075), 0:00:00, 1074
B: 358, 1, 1, 0, True, 1.000000, 181, 0.505587 (stdev 0.499284), 0:00:00, 0
A: cycle: 358
average reward: 0.466480 (stdev 0.498075)
B: cycle: 358
average reward: 0.505587 (stdev 0.499284)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 359, 0, 1, 0, True, 1.000000, 168, 0.467967 (stdev 0.498180), 0:00:00, 1077
B: 359, 0, 1, 1, True, 1.000000, 182, 0.506964 (stdev 0.499272), 0:00:00, 0
A: cycle: 359
average reward: 0.467967 (stdev 0.498180)
B: cycle: 359
average reward: 0.506964 (stdev 0.499272)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 360, 1, 0, 1, True, 1.000000, 168, 0.466667 (stdev 0.498279), 0:00:00, 1080
B: 360, 1, 1, 1, True, 1.000000, 183, 0.508333 (stdev 0.499257), 0:00:00, 0
A: cycle: 360
average reward: 0.466667 (stdev 0.498279)
B: cycle: 360
average reward: 0.508333 (stdev 0.499257)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 361, 0, 0, 1, True, 1.000000, 168, 0.465374 (stdev 0.498196), 0:00:00, 1083
B: 361, 0, 0, 0, True, 1.000000, 183, 0.506925 (stdev 0.499238), 0:00:00, 0
A: cycle: 361
average reward: 0.465374 (stdev 0.498196)
B: cycle: 361
average reward: 0.506925 (stdev 0.499238)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 362, 1, 1, 1, True, 1.000000, 169, 0.466851 (stdev 0.498110), 0:00:00, 1086
B: 362, 1, 0, 0, True, 1.000000, 183, 0.505525 (stdev 0.499261), 0:00:00, 0
A: cycle: 362
average reward: 0.466851 (stdev 0.498110)
B: cycle: 362
average reward: 0.505525 (stdev 0.499261)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 363, 0, 0, 0, True, 1.000000, 169, 0.465565 (stdev 0.498212), 0:00:00, 1089
B: 363, 0, 1, 0, True, 1.000000, 184, 0.506887 (stdev 0.499280), 0:00:00, 0
A: cycle: 363
average reward: 0.465565 (stdev 0.498212)
B: cycle: 363
average reward: 0.506887 (stdev 0.499280)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 364, 1, 0, 1, True, 1.000000, 169, 0.464286 (stdev 0.498127), 0:00:00, 1092
B: 364, 1, 0, 0, True, 1.000000, 184, 0.505495 (stdev 0.499265), 0:00:00, 0
A: cycle: 364
average reward: 0.464286 (stdev 0.498127)
B: cycle: 364
average reward: 0.505495 (stdev 0.499265)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 365, 0, 0, 0, True, 1.000000, 169, 0.463014 (stdev 0.498039), 0:00:00, 1095
B: 365, 0, 1, 0, True, 1.000000, 185, 0.506849 (stdev 0.499284), 0:00:00, 0
A: cycle: 365
average reward: 0.463014 (stdev 0.498039)
B: cycle: 365
average reward: 0.506849 (stdev 0.499284)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 366, 1, 0, 0, True, 1.000000, 169, 0.461749 (stdev 0.497948), 0:00:00, 1098
B: 366, 1, 0, 1, True, 1.000000, 185, 0.505464 (stdev 0.499270), 0:00:00, 0
A: cycle: 366
average reward: 0.461749 (stdev 0.497948)
B: cycle: 366
average reward: 0.505464 (stdev 0.499270)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 367, 0, 1, 1, True, 1.000000, 170, 0.463215 (stdev 0.497855), 0:00:00, 1101
B: 367, 0, 0, 1, True, 1.000000, 185, 0.504087 (stdev 0.499289), 0:00:00, 0
A: cycle: 367
average reward: 0.463215 (stdev 0.497855)
B: cycle: 367
average reward: 0.504087 (stdev 0.499289)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 368, 1, 1, 0, True, 1.000000, 171, 0.464674 (stdev 0.497967), 0:00:00, 1104
B: 368, 1, 1, 1, True, 1.000000, 186, 0.505435 (stdev 0.499304), 0:00:00, 0
A: cycle: 368
average reward: 0.464674 (stdev 0.497967)
B: cycle: 368
average reward: 0.505435 (stdev 0.499304)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 369, 0, 1, 1, True, 1.000000, 172, 0.466125 (stdev 0.498074), 0:00:00, 1107
B: 369, 0, 0, 0, True, 1.000000, 186, 0.504065 (stdev 0.499293), 0:00:00, 0
A: cycle: 369
average reward: 0.466125 (stdev 0.498074)
B: cycle: 369
average reward: 0.504065 (stdev 0.499293)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 370, 1, 1, 1, True, 1.000000, 173, 0.467568 (stdev 0.498177), 0:00:00, 1110
B: 370, 1, 0, 0, True, 1.000000, 186, 0.502703 (stdev 0.499307), 0:00:00, 0
A: cycle: 370
average reward: 0.467568 (stdev 0.498177)
B: cycle: 370
average reward: 0.502703 (stdev 0.499307)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 371, 0, 0, 0, True, 1.000000, 173, 0.466307 (stdev 0.498274), 0:00:00, 1113
B: 371, 0, 1, 0, True, 1.000000, 187, 0.504043 (stdev 0.499318), 0:00:00, 0
A: cycle: 371
average reward: 0.466307 (stdev 0.498274)
B: cycle: 371
average reward: 0.504043 (stdev 0.499318)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 372, 1, 0, 0, True, 1.000000, 173, 0.465054 (stdev 0.498193), 0:00:00, 1116
B: 372, 1, 0, 1, True, 1.000000, 187, 0.502688 (stdev 0.499311), 0:00:00, 0
A: cycle: 372
average reward: 0.465054 (stdev 0.498193)
B: cycle: 372
average reward: 0.502688 (stdev 0.499311)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 373, 0, 1, 0, True, 1.000000, 174, 0.466488 (stdev 0.498108), 0:00:00, 1119
B: 373, 0, 0, 1, True, 1.000000, 187, 0.501340 (stdev 0.499322), 0:00:00, 0
A: cycle: 373
average reward: 0.466488 (stdev 0.498108)
B: cycle: 373
average reward: 0.501340 (stdev 0.499322)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 374, 1, 0, 1, True, 1.000000, 174, 0.465241 (stdev 0.498208), 0:00:00, 1122
B: 374, 1, 1, 1, True, 1.000000, 188, 0.502674 (stdev 0.499329), 0:00:00, 0
A: cycle: 374
average reward: 0.465241 (stdev 0.498208)
B: cycle: 374
average reward: 0.502674 (stdev 0.499329)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 375, 0, 0, 1, True, 1.000000, 174, 0.464000 (stdev 0.498125), 0:00:00, 1125
B: 375, 0, 0, 0, True, 1.000000, 188, 0.501333 (stdev 0.499326), 0:00:00, 0
A: cycle: 375
average reward: 0.464000 (stdev 0.498125)
B: cycle: 375
average reward: 0.501333 (stdev 0.499326)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 376, 1, 1, 0, True, 1.000000, 175, 0.465426 (stdev 0.498039), 0:00:00, 1128
B: 376, 1, 0, 1, True, 1.000000, 188, 0.500000 (stdev 0.499333), 0:00:00, 0
A: cycle: 376
average reward: 0.465426 (stdev 0.498039)
B: cycle: 376
average reward: 0.500000 (stdev 0.499333)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 377, 0, 1, 0, True, 1.000000, 176, 0.466844 (stdev 0.498141), 0:00:00, 1131
B: 377, 0, 0, 0, True, 1.000000, 188, 0.498674 (stdev 0.499336), 0:00:00, 0
A: cycle: 377
average reward: 0.466844 (stdev 0.498141)
B: cycle: 377
average reward: 0.498674 (stdev 0.499336)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 378, 1, 0, 0, True, 1.000000, 176, 0.465608 (stdev 0.498239), 0:00:00, 1134
B: 378, 1, 0, 0, True, 1.000000, 188, 0.497354 (stdev 0.499336), 0:00:00, 0
A: cycle: 378
average reward: 0.465608 (stdev 0.498239)
B: cycle: 378
average reward: 0.497354 (stdev 0.499336)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 379, 0, 1, 1, True, 1.000000, 177, 0.467018 (stdev 0.498157), 0:00:00, 1137
B: 379, 0, 1, 0, True, 1.000000, 189, 0.498681 (stdev 0.499333), 0:00:00, 0
A: cycle: 379
average reward: 0.467018 (stdev 0.498157)
B: cycle: 379
average reward: 0.498681 (stdev 0.499333)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 380, 1, 1, 1, True, 1.000000, 178, 0.468421 (stdev 0.498254), 0:00:00, 1140
B: 380, 1, 0, 0, True, 1.000000, 189, 0.497368 (stdev 0.499340), 0:00:00, 0
A: cycle: 380
average reward: 0.468421 (stdev 0.498254)
B: cycle: 380
average reward: 0.497368 (stdev 0.499340)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 381, 0, 0, 1, True, 1.000000, 178, 0.467192 (stdev 0.498346), 0:00:00, 1143
B: 381, 0, 1, 0, True, 1.000000, 190, 0.498688 (stdev 0.499336), 0:00:00, 0
A: cycle: 381
average reward: 0.467192 (stdev 0.498346)
B: cycle: 381
average reward: 0.498688 (stdev 0.499336)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 382, 1, 1, 1, True, 1.000000, 179, 0.468586 (stdev 0.498269), 0:00:00, 1146
B: 382, 1, 0, 0, True, 1.000000, 190, 0.497382 (stdev 0.499343), 0:00:00, 0
A: cycle: 382
average reward: 0.468586 (stdev 0.498269)
B: cycle: 382
average reward: 0.497382 (stdev 0.499343)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 383, 0, 0, 0, True, 1.000000, 179, 0.467363 (stdev 0.498360), 0:00:00.015625, 1149
B: 383, 0, 1, 0, True, 1.000000, 191, 0.498695 (stdev 0.499340), 0:00:00, 0
A: cycle: 383
average reward: 0.467363 (stdev 0.498360)
B: cycle: 383
average reward: 0.498695 (stdev 0.499340)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 384, 1, 0, 0, True, 1.000000, 179, 0.466146 (stdev 0.498284), 0:00:00, 1152
B: 384, 1, 0, 0, True, 1.000000, 191, 0.497396 (stdev 0.499347), 0:00:00, 0
A: cycle: 384
average reward: 0.466146 (stdev 0.498284)
B: cycle: 384
average reward: 0.497396 (stdev 0.499347)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 385, 0, 1, 0, True, 1.000000, 180, 0.467532 (stdev 0.498204), 0:00:00, 1155
B: 385, 0, 1, 1, True, 1.000000, 192, 0.498701 (stdev 0.499343), 0:00:00, 0
A: cycle: 385
average reward: 0.467532 (stdev 0.498204)
B: cycle: 385
average reward: 0.498701 (stdev 0.499343)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 386, 1, 0, 1, True, 1.000000, 180, 0.466321 (stdev 0.498298), 0:00:00, 1158
B: 386, 1, 1, 0, True, 1.000000, 193, 0.500000 (stdev 0.499350), 0:00:00, 0
A: cycle: 386
average reward: 0.466321 (stdev 0.498298)
B: cycle: 386
average reward: 0.500000 (stdev 0.499350)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 387, 0, 0, 0, True, 1.000000, 180, 0.465116 (stdev 0.498220), 0:00:00, 1161
B: 387, 0, 1, 0, True, 1.000000, 194, 0.501292 (stdev 0.499354), 0:00:00, 0
A: cycle: 387
average reward: 0.465116 (stdev 0.498220)
B: cycle: 387
average reward: 0.501292 (stdev 0.499354)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 388, 1, 0, 0, True, 1.000000, 180, 0.463918 (stdev 0.498138), 0:00:00, 1164
B: 388, 1, 0, 1, True, 1.000000, 194, 0.500000 (stdev 0.499354), 0:00:00, 0
A: cycle: 388
average reward: 0.463918 (stdev 0.498138)
B: cycle: 388
average reward: 0.500000 (stdev 0.499354)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 389, 0, 1, 1, True, 1.000000, 181, 0.465296 (stdev 0.498055), 0:00:00, 1167
B: 389, 0, 0, 1, True, 1.000000, 194, 0.498715 (stdev 0.499357), 0:00:00, 0
A: cycle: 389
average reward: 0.465296 (stdev 0.498055)
B: cycle: 389
average reward: 0.498715 (stdev 0.499357)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 390, 1, 1, 0, True, 1.000000, 182, 0.466667 (stdev 0.498154), 0:00:00, 1170
B: 390, 1, 1, 0, True, 1.000000, 195, 0.500000 (stdev 0.499357), 0:00:00, 0
A: cycle: 390
average reward: 0.466667 (stdev 0.498154)
B: cycle: 390
average reward: 0.500000 (stdev 0.499357)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 391, 0, 1, 0, True, 1.000000, 183, 0.468031 (stdev 0.498249), 0:00:00, 1173
B: 391, 0, 1, 1, True, 1.000000, 196, 0.501279 (stdev 0.499360), 0:00:00, 0
A: cycle: 391
average reward: 0.468031 (stdev 0.498249)
B: cycle: 391
average reward: 0.501279 (stdev 0.499360)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 392, 1, 0, 0, True, 1.000000, 183, 0.466837 (stdev 0.498340), 0:00:00, 1176
B: 392, 1, 1, 0, True, 1.000000, 197, 0.502551 (stdev 0.499360), 0:00:00, 0
A: cycle: 392
average reward: 0.466837 (stdev 0.498340)
B: cycle: 392
average reward: 0.502551 (stdev 0.499360)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 393, 0, 1, 0, True, 1.000000, 184, 0.468193 (stdev 0.498264), 0:00:00, 1179
B: 393, 0, 1, 0, True, 1.000000, 198, 0.503817 (stdev 0.499357), 0:00:00, 0
A: cycle: 393
average reward: 0.468193 (stdev 0.498264)
B: cycle: 393
average reward: 0.503817 (stdev 0.499357)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 394, 1, 0, 1, True, 1.000000, 184, 0.467005 (stdev 0.498354), 0:00:00, 1182
B: 394, 1, 0, 0, True, 1.000000, 198, 0.502538 (stdev 0.499351), 0:00:00, 0
A: cycle: 394
average reward: 0.467005 (stdev 0.498354)
B: cycle: 394
average reward: 0.502538 (stdev 0.499351)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 395, 0, 0, 0, True, 1.000000, 184, 0.465823 (stdev 0.498278), 0:00:00, 1185
B: 395, 0, 1, 0, True, 1.000000, 199, 0.503797 (stdev 0.499360), 0:00:00, 0
A: cycle: 395
average reward: 0.465823 (stdev 0.498278)
B: cycle: 395
average reward: 0.503797 (stdev 0.499360)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 396, 1, 0, 1, True, 1.000000, 184, 0.464646 (stdev 0.498200), 0:00:00, 1188
B: 396, 1, 0, 1, True, 1.000000, 199, 0.502525 (stdev 0.499354), 0:00:00, 0
A: cycle: 396
average reward: 0.464646 (stdev 0.498200)
B: cycle: 396
average reward: 0.502525 (stdev 0.499354)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 397, 0, 0, 1, True, 1.000000, 184, 0.463476 (stdev 0.498120), 0:00:00, 1191
B: 397, 0, 0, 1, True, 1.000000, 199, 0.501259 (stdev 0.499364), 0:00:00, 0
A: cycle: 397
average reward: 0.463476 (stdev 0.498120)
B: cycle: 397
average reward: 0.501259 (stdev 0.499364)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 398, 1, 1, 0, True, 1.000000, 185, 0.464824 (stdev 0.498037), 0:00:00, 1194
B: 398, 1, 1, 1, True, 1.000000, 200, 0.502513 (stdev 0.499370), 0:00:00, 0
A: cycle: 398
average reward: 0.464824 (stdev 0.498037)
B: cycle: 398
average reward: 0.502513 (stdev 0.499370)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 399, 0, 1, 0, True, 1.000000, 186, 0.466165 (stdev 0.498136), 0:00:00, 1197
B: 399, 0, 0, 0, True, 1.000000, 200, 0.501253 (stdev 0.499367), 0:00:00, 0
A: cycle: 399
average reward: 0.466165 (stdev 0.498136)
B: cycle: 399
average reward: 0.501253 (stdev 0.499367)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 400, 1, 0, 0, True, 1.000000, 186, 0.465000 (stdev 0.498230), 0:00:00, 1200
B: 400, 1, 0, 0, True, 1.000000, 200, 0.500000 (stdev 0.499373), 0:00:00, 0
A: cycle: 400
average reward: 0.465000 (stdev 0.498230)
B: cycle: 400
average reward: 0.500000 (stdev 0.499373)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 401, 0, 1, 1, True, 1.000000, 187, 0.466334 (stdev 0.498151), 0:00:00, 1203
B: 401, 0, 1, 0, True, 1.000000, 201, 0.501247 (stdev 0.499376), 0:00:00, 0
A: cycle: 401
average reward: 0.466334 (stdev 0.498151)
B: cycle: 401
average reward: 0.501247 (stdev 0.499376)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 402, 1, 1, 1, True, 1.000000, 188, 0.467662 (stdev 0.498244), 0:00:00, 1206
B: 402, 1, 0, 1, True, 1.000000, 201, 0.500000 (stdev 0.499376), 0:00:00, 0
A: cycle: 402
average reward: 0.467662 (stdev 0.498244)
B: cycle: 402
average reward: 0.500000 (stdev 0.499376)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 403, 0, 0, 0, True, 1.000000, 188, 0.466501 (stdev 0.498334), 0:00:00, 1209
B: 403, 0, 0, 0, True, 1.000000, 201, 0.498759 (stdev 0.499379), 0:00:00, 0
A: cycle: 403
average reward: 0.466501 (stdev 0.498334)
B: cycle: 403
average reward: 0.498759 (stdev 0.499379)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 404, 1, 0, 1, True, 1.000000, 188, 0.465347 (stdev 0.498259), 0:00:00, 1212
B: 404, 1, 0, 1, True, 1.000000, 201, 0.497525 (stdev 0.499379), 0:00:00, 0
A: cycle: 404
average reward: 0.465347 (stdev 0.498259)
B: cycle: 404
average reward: 0.497525 (stdev 0.499379)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 405, 0, 0, 1, True, 1.000000, 188, 0.464198 (stdev 0.498182), 0:00:00, 1215
B: 405, 0, 0, 0, True, 1.000000, 201, 0.496296 (stdev 0.499376), 0:00:00, 0
A: cycle: 405
average reward: 0.464198 (stdev 0.498182)
B: cycle: 405
average reward: 0.496296 (stdev 0.499376)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 406, 1, 1, 0, True, 1.000000, 189, 0.465517 (stdev 0.498102), 0:00:00, 1218
B: 406, 1, 0, 1, True, 1.000000, 201, 0.495074 (stdev 0.499370), 0:00:00, 0
A: cycle: 406
average reward: 0.465517 (stdev 0.498102)
B: cycle: 406
average reward: 0.495074 (stdev 0.499370)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 407, 0, 1, 0, True, 1.000000, 190, 0.466830 (stdev 0.498196), 0:00:00, 1221
B: 407, 0, 0, 1, True, 1.000000, 201, 0.493857 (stdev 0.499361), 0:00:00, 0
A: cycle: 407
average reward: 0.466830 (stdev 0.498196)
B: cycle: 407
average reward: 0.493857 (stdev 0.499361)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 408, 1, 0, 0, True, 1.000000, 190, 0.465686 (stdev 0.498287), 0:00:00, 1224
B: 408, 1, 1, 0, True, 1.000000, 202, 0.495098 (stdev 0.499349), 0:00:00, 0
A: cycle: 408
average reward: 0.465686 (stdev 0.498287)
B: cycle: 408
average reward: 0.495098 (stdev 0.499349)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 409, 0, 1, 0, True, 1.000000, 191, 0.466993 (stdev 0.498211), 0:00:00, 1227
B: 409, 0, 1, 1, True, 1.000000, 203, 0.496333 (stdev 0.499364), 0:00:00, 0
A: cycle: 409
average reward: 0.466993 (stdev 0.498211)
B: cycle: 409
average reward: 0.496333 (stdev 0.499364)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 410, 1, 0, 0, True, 1.000000, 191, 0.465854 (stdev 0.498301), 0:00:00, 1230
B: 410, 1, 1, 1, True, 1.000000, 204, 0.497561 (stdev 0.499376), 0:00:00, 0
A: cycle: 410
average reward: 0.465854 (stdev 0.498301)
B: cycle: 410
average reward: 0.497561 (stdev 0.499376)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 411, 0, 1, 0, True, 1.000000, 192, 0.467153 (stdev 0.498225), 0:00:00.015625, 1233
B: 411, 0, 0, 1, True, 1.000000, 204, 0.496350 (stdev 0.499385), 0:00:00, 0
A: cycle: 411
average reward: 0.467153 (stdev 0.498225)
B: cycle: 411
average reward: 0.496350 (stdev 0.499385)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 412, 1, 0, 1, True, 1.000000, 192, 0.466019 (stdev 0.498314), 0:00:00, 1236
B: 412, 1, 1, 0, True, 1.000000, 205, 0.497573 (stdev 0.499380), 0:00:00, 0
A: cycle: 412
average reward: 0.466019 (stdev 0.498314)
B: cycle: 412
average reward: 0.497573 (stdev 0.499380)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 413, 0, 0, 1, True, 1.000000, 192, 0.464891 (stdev 0.498240), 0:00:00, 1239
B: 413, 0, 1, 0, True, 1.000000, 206, 0.498789 (stdev 0.499388), 0:00:00, 0
A: cycle: 413
average reward: 0.464891 (stdev 0.498240)
B: cycle: 413
average reward: 0.498789 (stdev 0.499388)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 414, 1, 1, 0, True, 1.000000, 193, 0.466184 (stdev 0.498163), 0:00:00, 1242
B: 414, 1, 0, 0, True, 1.000000, 206, 0.497585 (stdev 0.499394), 0:00:00, 0
A: cycle: 414
average reward: 0.466184 (stdev 0.498163)
B: cycle: 414
average reward: 0.497585 (stdev 0.499394)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 415, 0, 1, 0, True, 1.000000, 194, 0.467470 (stdev 0.498254), 0:00:00, 1245
B: 415, 0, 1, 1, True, 1.000000, 207, 0.498795 (stdev 0.499391), 0:00:00, 0
A: cycle: 415
average reward: 0.467470 (stdev 0.498254)
B: cycle: 415
average reward: 0.498795 (stdev 0.499391)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 416, 1, 0, 1, True, 1.000000, 194, 0.466346 (stdev 0.498341), 0:00:00, 1248
B: 416, 1, 1, 0, True, 1.000000, 208, 0.500000 (stdev 0.499397), 0:00:00, 0
A: cycle: 416
average reward: 0.466346 (stdev 0.498341)
B: cycle: 416
average reward: 0.500000 (stdev 0.499397)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 417, 0, 0, 0, True, 1.000000, 194, 0.465228 (stdev 0.498268), 0:00:00, 1251
B: 417, 0, 1, 1, True, 1.000000, 209, 0.501199 (stdev 0.499400), 0:00:00, 0
A: cycle: 417
average reward: 0.465228 (stdev 0.498268)
B: cycle: 417
average reward: 0.501199 (stdev 0.499400)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 418, 1, 0, 0, True, 1.000000, 194, 0.464115 (stdev 0.498192), 0:00:00, 1254
B: 418, 1, 1, 1, True, 1.000000, 210, 0.502392 (stdev 0.499400), 0:00:00, 0
A: cycle: 418
average reward: 0.464115 (stdev 0.498192)
B: cycle: 418
average reward: 0.502392 (stdev 0.499400)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 419, 0, 1, 0, True, 1.000000, 195, 0.465394 (stdev 0.498115), 0:00:00, 1257
B: 419, 0, 0, 1, True, 1.000000, 210, 0.501193 (stdev 0.499397), 0:00:00, 0
A: cycle: 419
average reward: 0.465394 (stdev 0.498115)
B: cycle: 419
average reward: 0.501193 (stdev 0.499397)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 420, 1, 0, 0, True, 1.000000, 195, 0.464286 (stdev 0.498207), 0:00:00, 1260
B: 420, 1, 1, 1, True, 1.000000, 211, 0.502381 (stdev 0.499403), 0:00:00, 0
A: cycle: 420
average reward: 0.464286 (stdev 0.498207)
B: cycle: 420
average reward: 0.502381 (stdev 0.499403)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 421, 0, 1, 1, True, 1.000000, 196, 0.465558 (stdev 0.498130), 0:00:00, 1263
B: 421, 0, 0, 1, True, 1.000000, 211, 0.501188 (stdev 0.499400), 0:00:00, 0
A: cycle: 421
average reward: 0.465558 (stdev 0.498130)
B: cycle: 421
average reward: 0.501188 (stdev 0.499400)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 422, 1, 1, 0, True, 1.000000, 197, 0.466825 (stdev 0.498221), 0:00:00, 1266
B: 422, 1, 1, 0, True, 1.000000, 212, 0.502370 (stdev 0.499406), 0:00:00, 0
A: cycle: 422
average reward: 0.466825 (stdev 0.498221)
B: cycle: 422
average reward: 0.502370 (stdev 0.499406)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 423, 0, 1, 1, True, 1.000000, 198, 0.468085 (stdev 0.498308), 0:00:00, 1269
B: 423, 0, 1, 0, True, 1.000000, 213, 0.503546 (stdev 0.499403), 0:00:00, 0
A: cycle: 423
average reward: 0.468085 (stdev 0.498308)
B: cycle: 423
average reward: 0.503546 (stdev 0.499403)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 424, 1, 1, 0, True, 1.000000, 199, 0.469340 (stdev 0.498392), 0:00:00, 1272
B: 424, 1, 0, 1, True, 1.000000, 213, 0.502358 (stdev 0.499397), 0:00:00, 0
A: cycle: 424
average reward: 0.469340 (stdev 0.498392)
B: cycle: 424
average reward: 0.502358 (stdev 0.499397)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 425, 0, 1, 0, True, 1.000000, 200, 0.470588 (stdev 0.498472), 0:00:00, 1275
B: 425, 0, 0, 0, True, 1.000000, 213, 0.501176 (stdev 0.499406), 0:00:00, 0
A: cycle: 425
average reward: 0.470588 (stdev 0.498472)
B: cycle: 425
average reward: 0.501176 (stdev 0.499406)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 426, 1, 0, 1, True, 1.000000, 200, 0.469484 (stdev 0.498548), 0:00:00, 1278
B: 426, 1, 0, 0, True, 1.000000, 213, 0.500000 (stdev 0.499411), 0:00:00, 0
A: cycle: 426
average reward: 0.469484 (stdev 0.498548)
B: cycle: 426
average reward: 0.500000 (stdev 0.499411)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 427, 0, 0, 0, True, 1.000000, 200, 0.468384 (stdev 0.498483), 0:00:00, 1281
B: 427, 0, 1, 0, True, 1.000000, 214, 0.501171 (stdev 0.499414), 0:00:00, 0
A: cycle: 427
average reward: 0.468384 (stdev 0.498483)
B: cycle: 427
average reward: 0.501171 (stdev 0.499414)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 428, 1, 0, 1, True, 1.000000, 200, 0.467290 (stdev 0.498416), 0:00:00, 1284
B: 428, 1, 0, 0, True, 1.000000, 214, 0.500000 (stdev 0.499414), 0:00:00, 0
A: cycle: 428
average reward: 0.467290 (stdev 0.498416)
B: cycle: 428
average reward: 0.500000 (stdev 0.499414)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 429, 0, 0, 1, True, 1.000000, 200, 0.466200 (stdev 0.498347), 0:00:00, 1287
B: 429, 0, 1, 1, True, 1.000000, 215, 0.501166 (stdev 0.499417), 0:00:00, 0
A: cycle: 429
average reward: 0.466200 (stdev 0.498347)
B: cycle: 429
average reward: 0.501166 (stdev 0.499417)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 430, 1, 1, 0, True, 1.000000, 201, 0.467442 (stdev 0.498276), 0:00:00, 1290
B: 430, 1, 1, 0, True, 1.000000, 216, 0.502326 (stdev 0.499417), 0:00:00, 0
A: cycle: 430
average reward: 0.467442 (stdev 0.498276)
B: cycle: 430
average reward: 0.502326 (stdev 0.499417)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 431, 0, 1, 0, True, 1.000000, 202, 0.468677 (stdev 0.498360), 0:00:00, 1293
B: 431, 0, 1, 0, True, 1.000000, 217, 0.503480 (stdev 0.499414), 0:00:00, 0
A: cycle: 431
average reward: 0.468677 (stdev 0.498360)
B: cycle: 431
average reward: 0.503480 (stdev 0.499414)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 432, 1, 0, 0, True, 1.000000, 202, 0.467593 (stdev 0.498440), 0:00:00, 1296
B: 432, 1, 0, 1, True, 1.000000, 217, 0.502315 (stdev 0.499409), 0:00:00, 0
A: cycle: 432
average reward: 0.467593 (stdev 0.498440)
B: cycle: 432
average reward: 0.502315 (stdev 0.499409)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 433, 0, 1, 0, True, 1.000000, 203, 0.468822 (stdev 0.498372), 0:00:00, 1299
B: 433, 0, 0, 1, True, 1.000000, 217, 0.501155 (stdev 0.499417), 0:00:00, 0
A: cycle: 433
average reward: 0.468822 (stdev 0.498372)
B: cycle: 433
average reward: 0.501155 (stdev 0.499417)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 434, 1, 0, 1, True, 1.000000, 203, 0.467742 (stdev 0.498452), 0:00:00, 1302
B: 434, 1, 1, 0, True, 1.000000, 218, 0.502304 (stdev 0.499422), 0:00:00, 0
A: cycle: 434
average reward: 0.467742 (stdev 0.498452)
B: cycle: 434
average reward: 0.502304 (stdev 0.499422)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 435, 0, 0, 1, True, 1.000000, 203, 0.466667 (stdev 0.498384), 0:00:00, 1305
B: 435, 0, 1, 0, True, 1.000000, 219, 0.503448 (stdev 0.499420), 0:00:00, 0
A: cycle: 435
average reward: 0.466667 (stdev 0.498384)
B: cycle: 435
average reward: 0.503448 (stdev 0.499420)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 436, 1, 1, 1, True, 1.000000, 204, 0.467890 (stdev 0.498315), 0:00:00, 1308
B: 436, 1, 0, 1, True, 1.000000, 219, 0.502294 (stdev 0.499414), 0:00:00, 0
A: cycle: 436
average reward: 0.467890 (stdev 0.498315)
B: cycle: 436
average reward: 0.502294 (stdev 0.499414)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 437, 0, 0, 0, True, 1.000000, 204, 0.466819 (stdev 0.498397), 0:00:00, 1311
B: 437, 0, 0, 0, True, 1.000000, 219, 0.501144 (stdev 0.499422), 0:00:00, 0
A: cycle: 437
average reward: 0.466819 (stdev 0.498397)
B: cycle: 437
average reward: 0.501144 (stdev 0.499422)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 438, 1, 0, 1, True, 1.000000, 204, 0.465753 (stdev 0.498328), 0:00:00, 1314
B: 438, 1, 0, 0, True, 1.000000, 219, 0.500000 (stdev 0.499428), 0:00:00, 0
A: cycle: 438
average reward: 0.465753 (stdev 0.498328)
B: cycle: 438
average reward: 0.500000 (stdev 0.499428)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 439, 0, 0, 1, True, 1.000000, 204, 0.464692 (stdev 0.498257), 0:00:00, 1317
B: 439, 0, 1, 0, True, 1.000000, 220, 0.501139 (stdev 0.499430), 0:00:00, 0
A: cycle: 439
average reward: 0.464692 (stdev 0.498257)
B: cycle: 439
average reward: 0.501139 (stdev 0.499430)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 440, 1, 1, 1, True, 1.000000, 205, 0.465909 (stdev 0.498185), 0:00:00, 1320
B: 440, 1, 0, 1, True, 1.000000, 220, 0.500000 (stdev 0.499430), 0:00:00, 0
A: cycle: 440
average reward: 0.465909 (stdev 0.498185)
B: cycle: 440
average reward: 0.500000 (stdev 0.499430)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 441, 0, 0, 0, True, 1.000000, 205, 0.464853 (stdev 0.498271), 0:00:00, 1323
B: 441, 0, 0, 1, True, 1.000000, 220, 0.498866 (stdev 0.499433), 0:00:00, 0
A: cycle: 441
average reward: 0.464853 (stdev 0.498271)
B: cycle: 441
average reward: 0.498866 (stdev 0.499433)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 442, 1, 0, 1, True, 1.000000, 205, 0.463801 (stdev 0.498199), 0:00:00, 1326
B: 442, 1, 1, 0, True, 1.000000, 221, 0.500000 (stdev 0.499433), 0:00:00, 0
A: cycle: 442
average reward: 0.463801 (stdev 0.498199)
B: cycle: 442
average reward: 0.500000 (stdev 0.499433)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 443, 0, 0, 0, True, 1.000000, 205, 0.462754 (stdev 0.498125), 0:00:00, 1329
B: 443, 0, 1, 0, True, 1.000000, 222, 0.501129 (stdev 0.499435), 0:00:00, 0
A: cycle: 443
average reward: 0.462754 (stdev 0.498125)
B: cycle: 443
average reward: 0.501129 (stdev 0.499435)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 444, 1, 0, 0, True, 1.000000, 205, 0.461712 (stdev 0.498049), 0:00:00, 1332
B: 444, 1, 0, 1, True, 1.000000, 222, 0.500000 (stdev 0.499435), 0:00:00, 0
A: cycle: 444
average reward: 0.461712 (stdev 0.498049)
B: cycle: 444
average reward: 0.500000 (stdev 0.499435)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 445, 0, 1, 0, True, 1.000000, 206, 0.462921 (stdev 0.497971), 0:00:00, 1335
B: 445, 0, 0, 1, True, 1.000000, 222, 0.498876 (stdev 0.499438), 0:00:00, 0
A: cycle: 445
average reward: 0.462921 (stdev 0.497971)
B: cycle: 445
average reward: 0.498876 (stdev 0.499438)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 446, 1, 0, 0, True, 1.000000, 206, 0.461883 (stdev 0.498064), 0:00:00, 1338
B: 446, 1, 1, 0, True, 1.000000, 223, 0.500000 (stdev 0.499438), 0:00:00, 0
A: cycle: 446
average reward: 0.461883 (stdev 0.498064)
B: cycle: 446
average reward: 0.500000 (stdev 0.499438)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 447, 0, 1, 1, True, 1.000000, 207, 0.463087 (stdev 0.497987), 0:00:00, 1341
B: 447, 0, 1, 1, True, 1.000000, 224, 0.501119 (stdev 0.499440), 0:00:00, 0
A: cycle: 447
average reward: 0.463087 (stdev 0.497987)
B: cycle: 447
average reward: 0.501119 (stdev 0.499440)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 448, 1, 1, 1, True, 1.000000, 208, 0.464286 (stdev 0.498079), 0:00:00, 1344
B: 448, 1, 1, 1, True, 1.000000, 225, 0.502232 (stdev 0.499440), 0:00:00, 0
A: cycle: 448
average reward: 0.464286 (stdev 0.498079)
B: cycle: 448
average reward: 0.502232 (stdev 0.499440)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 449, 0, 0, 0, True, 1.000000, 208, 0.463252 (stdev 0.498167), 0:00:00.015625, 1347
B: 449, 0, 0, 0, True, 1.000000, 225, 0.501114 (stdev 0.499438), 0:00:00, 0
A: cycle: 449
average reward: 0.463252 (stdev 0.498167)
B: cycle: 449
average reward: 0.501114 (stdev 0.499438)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 450, 1, 0, 1, True, 1.000000, 208, 0.462222 (stdev 0.498093), 0:00:00, 1350
B: 450, 1, 0, 0, True, 1.000000, 225, 0.500000 (stdev 0.499443), 0:00:00, 0
A: cycle: 450
average reward: 0.462222 (stdev 0.498093)
B: cycle: 450
average reward: 0.500000 (stdev 0.499443)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0



explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 451, 0, 0, 1, True, 1.000000, 208, 0.461197 (stdev 0.498018), 0:00:00, 1353
B: 451, 0, 1, 1, True, 1.000000, 226, 0.501109 (stdev 0.499445), 0:00:00, 0
A: cycle: 451
average reward: 0.461197 (stdev 0.498018)
B: cycle: 451
average reward: 0.501109 (stdev 0.499445)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 452, 1, 1, 0, True, 1.000000, 209, 0.462389 (stdev 0.497940), 0:00:00, 1356
B: 452, 1, 1, 1, True, 1.000000, 227, 0.502212 (stdev 0.499445), 0:00:00, 0
A: cycle: 452
average reward: 0.462389 (stdev 0.497940)
B: cycle: 452
average reward: 0.502212 (stdev 0.499445)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 453, 0, 1, 0, True, 1.000000, 210, 0.463576 (stdev 0.498033), 0:00:00, 1359
B: 453, 0, 0, 1, True, 1.000000, 227, 0.501104 (stdev 0.499443), 0:00:00, 0
A: cycle: 453
average reward: 0.463576 (stdev 0.498033)
B: cycle: 453
average reward: 0.501104 (stdev 0.499443)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 454, 1, 0, 0, True, 1.000000, 210, 0.462555 (stdev 0.498122), 0:00:00, 1362
B: 454, 1, 1, 1, True, 1.000000, 228, 0.502203 (stdev 0.499448), 0:00:00, 0
A: cycle: 454
average reward: 0.462555 (stdev 0.498122)
B: cycle: 454
average reward: 0.502203 (stdev 0.499448)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 455, 0, 1, 1, True, 1.000000, 211, 0.463736 (stdev 0.498048), 0:00:00, 1365
B: 455, 0, 0, 1, True, 1.000000, 228, 0.501099 (stdev 0.499445), 0:00:00, 0
A: cycle: 455
average reward: 0.463736 (stdev 0.498048)
B: cycle: 455
average reward: 0.501099 (stdev 0.499445)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 456, 1, 1, 1, True, 1.000000, 212, 0.464912 (stdev 0.498136), 0:00:00, 1368
B: 456, 1, 1, 0, True, 1.000000, 229, 0.502193 (stdev 0.499450), 0:00:00, 0
A: cycle: 456
average reward: 0.464912 (stdev 0.498136)
B: cycle: 456
average reward: 0.502193 (stdev 0.499450)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 457, 0, 0, 1, True, 1.000000, 212, 0.463895 (stdev 0.498221), 0:00:00, 1371
B: 457, 0, 1, 0, True, 1.000000, 230, 0.503282 (stdev 0.499448), 0:00:00, 0
A: cycle: 457
average reward: 0.463895 (stdev 0.498221)
B: cycle: 457
average reward: 0.503282 (stdev 0.499448)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 458, 1, 1, 1, True, 1.000000, 213, 0.465066 (stdev 0.498150), 0:00:00, 1374
B: 458, 1, 0, 1, True, 1.000000, 230, 0.502183 (stdev 0.499443), 0:00:00, 0
A: cycle: 458
average reward: 0.465066 (stdev 0.498150)
B: cycle: 458
average reward: 0.502183 (stdev 0.499443)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 459, 0, 0, 1, True, 1.000000, 213, 0.464052 (stdev 0.498234), 0:00:00, 1377
B: 459, 0, 0, 1, True, 1.000000, 230, 0.501089 (stdev 0.499450), 0:00:00, 0
A: cycle: 459
average reward: 0.464052 (stdev 0.498234)
B: cycle: 459
average reward: 0.501089 (stdev 0.499450)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 460, 1, 1, 0, True, 1.000000, 214, 0.465217 (stdev 0.498164), 0:00:00, 1380
B: 460, 1, 1, 1, True, 1.000000, 231, 0.502174 (stdev 0.499455), 0:00:00, 0
A: cycle: 460
average reward: 0.465217 (stdev 0.498164)
B: cycle: 460
average reward: 0.502174 (stdev 0.499455)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 461, 0, 1, 1, True, 1.000000, 215, 0.466377 (stdev 0.498247), 0:00:00, 1383
B: 461, 0, 0, 1, True, 1.000000, 231, 0.501085 (stdev 0.499453), 0:00:00, 0
A: cycle: 461
average reward: 0.466377 (stdev 0.498247)
B: cycle: 461
average reward: 0.501085 (stdev 0.499453)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 462, 1, 1, 1, True, 1.000000, 216, 0.467532 (stdev 0.498328), 0:00:00, 1386
B: 462, 1, 1, 0, True, 1.000000, 232, 0.502165 (stdev 0.499457), 0:00:00, 0
A: cycle: 462
average reward: 0.467532 (stdev 0.498328)
B: cycle: 462
average reward: 0.502165 (stdev 0.499457)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 463, 0, 0, 1, True, 1.000000, 216, 0.466523 (stdev 0.498406), 0:00:00, 1389
B: 463, 0, 1, 0, True, 1.000000, 233, 0.503240 (stdev 0.499455), 0:00:00, 0
A: cycle: 463
average reward: 0.466523 (stdev 0.498406)
B: cycle: 463
average reward: 0.503240 (stdev 0.499455)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 464, 1, 1, 1, True, 1.000000, 217, 0.467672 (stdev 0.498340), 0:00:00, 1392
B: 464, 1, 0, 0, True, 1.000000, 233, 0.502155 (stdev 0.499450), 0:00:00, 0
A: cycle: 464
average reward: 0.467672 (stdev 0.498340)
B: cycle: 464
average reward: 0.502155 (stdev 0.499450)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 465, 0, 0, 0, True, 1.000000, 217, 0.466667 (stdev 0.498417), 0:00:00, 1395
B: 465, 0, 1, 1, True, 1.000000, 234, 0.503226 (stdev 0.499457), 0:00:00, 0
A: cycle: 465
average reward: 0.466667 (stdev 0.498417)
B: cycle: 465
average reward: 0.503226 (stdev 0.499457)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 466, 1, 0, 0, True, 1.000000, 217, 0.465665 (stdev 0.498352), 0:00:00, 1398
B: 466, 1, 1, 0, True, 1.000000, 235, 0.504292 (stdev 0.499453), 0:00:00, 0
A: cycle: 466
average reward: 0.465665 (stdev 0.498352)
B: cycle: 466
average reward: 0.504292 (stdev 0.499453)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 467, 0, 1, 1, True, 1.000000, 218, 0.466809 (stdev 0.498285), 0:00:00, 1401
B: 467, 0, 1, 0, True, 1.000000, 236, 0.505353 (stdev 0.499446), 0:00:00, 0
A: cycle: 467
average reward: 0.466809 (stdev 0.498285)
B: cycle: 467
average reward: 0.505353 (stdev 0.499446)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 468, 1, 1, 1, True, 1.000000, 219, 0.467949 (stdev 0.498364), 0:00:00, 1404
B: 468, 1, 0, 1, True, 1.000000, 236, 0.504274 (stdev 0.499437), 0:00:00, 0
A: cycle: 468
average reward: 0.467949 (stdev 0.498364)
B: cycle: 468
average reward: 0.504274 (stdev 0.499437)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 469, 0, 0, 1, True, 1.000000, 219, 0.466951 (stdev 0.498439), 0:00:00, 1407
B: 469, 0, 0, 0, True, 1.000000, 236, 0.503198 (stdev 0.499448), 0:00:00, 0
A: cycle: 469
average reward: 0.466951 (stdev 0.498439)
B: cycle: 469
average reward: 0.503198 (stdev 0.499448)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 470, 1, 1, 1, True, 1.000000, 220, 0.468085 (stdev 0.498376), 0:00:00, 1410
B: 470, 1, 0, 0, True, 1.000000, 236, 0.502128 (stdev 0.499458), 0:00:00, 0
A: cycle: 470
average reward: 0.468085 (stdev 0.498376)
B: cycle: 470
average reward: 0.502128 (stdev 0.499458)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 471, 0, 0, 1, True, 1.000000, 220, 0.467091 (stdev 0.498450), 0:00:00, 1413
B: 471, 0, 1, 1, True, 1.000000, 237, 0.503185 (stdev 0.499464), 0:00:00, 0
A: cycle: 471
average reward: 0.467091 (stdev 0.498450)
B: cycle: 471
average reward: 0.503185 (stdev 0.499464)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 472, 1, 1, 1, True, 1.000000, 221, 0.468220 (stdev 0.498387), 0:00:00, 1416
B: 472, 1, 1, 0, True, 1.000000, 238, 0.504237 (stdev 0.499460), 0:00:00, 0
A: cycle: 472
average reward: 0.468220 (stdev 0.498387)
B: cycle: 472
average reward: 0.504237 (stdev 0.499460)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 473, 0, 0, 0, True, 1.000000, 221, 0.467230 (stdev 0.498461), 0:00:00, 1419
B: 473, 0, 1, 0, True, 1.000000, 239, 0.505285 (stdev 0.499453), 0:00:00, 0
A: cycle: 473
average reward: 0.467230 (stdev 0.498461)
B: cycle: 473
average reward: 0.505285 (stdev 0.499453)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 474, 1, 0, 0, True, 1.000000, 221, 0.466245 (stdev 0.498398), 0:00:00, 1422
B: 474, 1, 0, 1, True, 1.000000, 239, 0.504219 (stdev 0.499444), 0:00:00, 0
A: cycle: 474
average reward: 0.466245 (stdev 0.498398)
B: cycle: 474
average reward: 0.504219 (stdev 0.499444)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 475, 0, 1, 1, True, 1.000000, 222, 0.467368 (stdev 0.498334), 0:00:00, 1425
B: 475, 0, 0, 1, True, 1.000000, 239, 0.503158 (stdev 0.499456), 0:00:00, 0
A: cycle: 475
average reward: 0.467368 (stdev 0.498334)
B: cycle: 475
average reward: 0.503158 (stdev 0.499456)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 476, 1, 1, 1, True, 1.000000, 223, 0.468487 (stdev 0.498410), 0:00:00, 1428
B: 476, 1, 1, 0, True, 1.000000, 240, 0.504202 (stdev 0.499465), 0:00:00, 0
A: cycle: 476
average reward: 0.468487 (stdev 0.498410)
B: cycle: 476
average reward: 0.504202 (stdev 0.499465)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 477, 0, 0, 0, True, 1.000000, 223, 0.467505 (stdev 0.498483), 0:00:00, 1431
B: 477, 0, 1, 0, True, 1.000000, 241, 0.505241 (stdev 0.499458), 0:00:00, 0
A: cycle: 477
average reward: 0.467505 (stdev 0.498483)
B: cycle: 477
average reward: 0.505241 (stdev 0.499458)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 478, 1, 0, 1, True, 1.000000, 223, 0.466527 (stdev 0.498421), 0:00:00, 1434
B: 478, 1, 0, 0, True, 1.000000, 241, 0.504184 (stdev 0.499449), 0:00:00, 0
A: cycle: 478
average reward: 0.466527 (stdev 0.498421)
B: cycle: 478
average reward: 0.504184 (stdev 0.499449)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 479, 0, 0, 0, True, 1.000000, 223, 0.465553 (stdev 0.498357), 0:00:00, 1437
B: 479, 0, 1, 0, True, 1.000000, 242, 0.505219 (stdev 0.499460), 0:00:00, 0
A: cycle: 479
average reward: 0.465553 (stdev 0.498357)
B: cycle: 479
average reward: 0.505219 (stdev 0.499460)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 480, 1, 0, 0, True, 1.000000, 223, 0.464583 (stdev 0.498292), 0:00:00, 1440
B: 480, 1, 0, 1, True, 1.000000, 242, 0.504167 (stdev 0.499452), 0:00:00, 0
A: cycle: 480
average reward: 0.464583 (stdev 0.498292)
B: cycle: 480
average reward: 0.504167 (stdev 0.499452)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 481, 0, 1, 0, True, 1.000000, 224, 0.465696 (stdev 0.498225), 0:00:00, 1443
B: 481, 0, 0, 0, True, 1.000000, 242, 0.503119 (stdev 0.499463), 0:00:00, 0
A: cycle: 481
average reward: 0.465696 (stdev 0.498225)
B: cycle: 481
average reward: 0.503119 (stdev 0.499463)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 482, 1, 0, 0, True, 1.000000, 224, 0.464730 (stdev 0.498304), 0:00:00, 1446
B: 482, 1, 0, 1, True, 1.000000, 242, 0.502075 (stdev 0.499471), 0:00:00, 0
A: cycle: 482
average reward: 0.464730 (stdev 0.498304)
B: cycle: 482
average reward: 0.502075 (stdev 0.499471)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 483, 0, 1, 0, True, 1.000000, 225, 0.465839 (stdev 0.498238), 0:00:00, 1449
B: 483, 0, 0, 0, True, 1.000000, 242, 0.501035 (stdev 0.499478), 0:00:00, 0
A: cycle: 483
average reward: 0.465839 (stdev 0.498238)
B: cycle: 483
average reward: 0.501035 (stdev 0.499478)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 484, 1, 0, 0, True, 1.000000, 225, 0.464876 (stdev 0.498316), 0:00:00, 1452
B: 484, 1, 0, 1, True, 1.000000, 242, 0.500000 (stdev 0.499482), 0:00:00, 0
A: cycle: 484
average reward: 0.464876 (stdev 0.498316)
B: cycle: 484
average reward: 0.500000 (stdev 0.499482)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 485, 0, 1, 1, True, 1.000000, 226, 0.465979 (stdev 0.498250), 0:00:00, 1455
B: 485, 0, 0, 1, True, 1.000000, 242, 0.498969 (stdev 0.499484), 0:00:00, 0
A: cycle: 485
average reward: 0.465979 (stdev 0.498250)
B: cycle: 485
average reward: 0.498969 (stdev 0.499484)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 486, 1, 1, 1, True, 1.000000, 227, 0.467078 (stdev 0.498328), 0:00:00, 1458
B: 486, 1, 1, 0, True, 1.000000, 243, 0.500000 (stdev 0.499484), 0:00:00, 0
A: cycle: 486
average reward: 0.467078 (stdev 0.498328)
B: cycle: 486
average reward: 0.500000 (stdev 0.499484)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 487, 0, 0, 1, True, 1.000000, 227, 0.466119 (stdev 0.498402), 0:00:00, 1461
B: 487, 0, 1, 1, True, 1.000000, 244, 0.501027 (stdev 0.499486), 0:00:00, 0
A: cycle: 487
average reward: 0.466119 (stdev 0.498402)
B: cycle: 487
average reward: 0.501027 (stdev 0.499486)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 488, 1, 1, 1, True, 1.000000, 228, 0.467213 (stdev 0.498339), 0:00:00, 1464
B: 488, 1, 1, 1, True, 1.000000, 245, 0.502049 (stdev 0.499486), 0:00:00, 0
A: cycle: 488
average reward: 0.467213 (stdev 0.498339)
B: cycle: 488
average reward: 0.502049 (stdev 0.499486)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 489, 0, 0, 1, True, 1.000000, 228, 0.466258 (stdev 0.498413), 0:00:00, 1467
B: 489, 0, 0, 0, True, 1.000000, 245, 0.501022 (stdev 0.499484), 0:00:00, 0
A: cycle: 489
average reward: 0.466258 (stdev 0.498413)
B: cycle: 489
average reward: 0.501022 (stdev 0.499484)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 490, 1, 1, 0, True, 1.000000, 229, 0.467347 (stdev 0.498351), 0:00:00, 1470
B: 490, 1, 0, 0, True, 1.000000, 245, 0.500000 (stdev 0.499488), 0:00:00, 0
A: cycle: 490
average reward: 0.467347 (stdev 0.498351)
B: cycle: 490
average reward: 0.500000 (stdev 0.499488)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 491, 0, 1, 0, True, 1.000000, 230, 0.468432 (stdev 0.498424), 0:00:00, 1473
B: 491, 0, 1, 0, True, 1.000000, 246, 0.501018 (stdev 0.499491), 0:00:00, 0
A: cycle: 491
average reward: 0.468432 (stdev 0.498424)
B: cycle: 491
average reward: 0.501018 (stdev 0.499491)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 492, 1, 0, 1, True, 1.000000, 230, 0.467480 (stdev 0.498495), 0:00:00, 1476
B: 492, 1, 0, 1, True, 1.000000, 246, 0.500000 (stdev 0.499491), 0:00:00, 0
A: cycle: 492
average reward: 0.467480 (stdev 0.498495)
B: cycle: 492
average reward: 0.500000 (stdev 0.499491)
explore rate: 1.000000

A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 493, 0, 0, 0, True, 1.000000, 230, 0.466531 (stdev 0.498435), 0:00:00, 1479
B: 493, 0, 0, 1, True, 1.000000, 246, 0.498986 (stdev 0.499493), 0:00:00, 0
A: cycle: 493
average reward: 0.466531 (stdev 0.498435)
B: cycle: 493
average reward: 0.498986 (stdev 0.499493)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 494, 1, 0, 0, True, 1.000000, 230, 0.465587 (stdev 0.498373), 0:00:00, 1482
B: 494, 1, 1, 0, True, 1.000000, 247, 0.500000 (stdev 0.499493), 0:00:00, 0
A: cycle: 494
average reward: 0.465587 (stdev 0.498373)
B: cycle: 494
average reward: 0.500000 (stdev 0.499493)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying an action at random...
A: 495, 0, 1, 0, True, 1.000000, 231, 0.466667 (stdev 0.498310), 0:00:00, 1485
B: 495, 0, 1, 1, True, 1.000000, 248, 0.501010 (stdev 0.499495), 0:00:00, 0
A: cycle: 495
average reward: 0.466667 (stdev 0.498310)
B: cycle: 495
average reward: 0.501010 (stdev 0.499495)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying an action at random...
A: 496, 1, 0, 0, True, 1.000000, 231, 0.465726 (stdev 0.498384), 0:00:00, 1488
B: 496, 1, 1, 1, True, 1.000000, 249, 0.502016 (stdev 0.499495), 0:00:00, 0
A: cycle: 496
average reward: 0.465726 (stdev 0.498384)
B: cycle: 496
average reward: 0.502016 (stdev 0.499495)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 497, 0, 1, 0, True, 1.000000, 232, 0.466801 (stdev 0.498322), 0:00:00, 1491
B: 497, 0, 0, 0, True, 1.000000, 249, 0.501006 (stdev 0.499493), 0:00:00, 0
A: cycle: 497
average reward: 0.466801 (stdev 0.498322)
B: cycle: 497
average reward: 0.501006 (stdev 0.499493)
explore rate: 1.000000

A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 498, 1, 0, 0, True, 1.000000, 232, 0.465863 (stdev 0.498395), 0:00:00, 1494
B: 498, 1, 0, 1, True, 1.000000, 249, 0.500000 (stdev 0.499497), 0:00:00, 0
A: cycle: 498
average reward: 0.465863 (stdev 0.498395)
B: cycle: 498
average reward: 0.500000 (stdev 0.499497)
explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying an action at random...
A: 499, 0, 1, 1, True, 1.000000, 233, 0.466934 (stdev 0.498333), 0:00:00, 1497
B: 499, 0, 0, 0, True, 1.000000, 249, 0.498998 (stdev 0.499499), 0:00:00, 0
A: cycle: 499
average reward: 0.466934 (stdev 0.498333)
B: cycle: 499
average reward: 0.498998 (stdev 0.499499)
explore rate: 1.000000

A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying an action at random...
A: 500, 1, 1, 0, True, 1.000000, 234, 0.468000 (stdev 0.498406), 0:00:00, 1500
B: 500, 1, 0, 0, True, 1.000000, 249, 0.498000 (stdev 0.499499), 0:00:00, 0
A: cycle: 500
average reward: 0.468000 (stdev 0.498406)
B: cycle: 500
average reward: 0.498000 (stdev 0.499499)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0



explore rate: 1.000000

A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 501, 0, 1, 1, False, 1.000000, 235, 0.469062 (stdev 0.498477), 0:00:00.046875, 1503
B: 501, 0, 1, 1, False, 1.000000, 250, 0.499002 (stdev 0.499497), 0:00:00, 0
A: cycle: 501
average reward: 0.469062 (stdev 0.498477)
B: cycle: 501
average reward: 0.499002 (stdev 0.499497)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 502, 1, 1, 0, False, 1.000000, 236, 0.470120 (stdev 0.498545), 0:00:00.062499, 1506
B: 502, 1, 1, 0, False, 1.000000, 251, 0.500000 (stdev 0.499501), 0:00:00, 0
A: cycle: 502
average reward: 0.470120 (stdev 0.498545)
B: cycle: 502
average reward: 0.500000 (stdev 0.499501)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 503, 0, 1, 1, False, 1.000000, 237, 0.471173 (stdev 0.498610), 0:00:00.062500, 1509
B: 503, 0, 1, 1, False, 1.000000, 252, 0.500994 (stdev 0.499503), 0:00:00, 0
A: cycle: 503
average reward: 0.471173 (stdev 0.498610)
B: cycle: 503
average reward: 0.500994 (stdev 0.499503)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 504, 1, 1, 1, False, 1.000000, 238, 0.472222 (stdev 0.498673), 0:00:00.062500, 1512
B: 504, 1, 1, 0, False, 1.000000, 253, 0.501984 (stdev 0.499503), 0:00:00, 0
A: cycle: 504
average reward: 0.472222 (stdev 0.498673)
B: cycle: 504
average reward: 0.501984 (stdev 0.499503)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 505, 0, 0, 1, False, 1.000000, 238, 0.471287 (stdev 0.498733), 0:00:00.074331, 1515
B: 505, 0, 1, 1, False, 1.000000, 254, 0.502970 (stdev 0.499501), 0:00:00, 0
A: cycle: 505
average reward: 0.471287 (stdev 0.498733)
B: cycle: 505
average reward: 0.502970 (stdev 0.499501)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 506, 1, 1, 0, False, 1.000000, 239, 0.472332 (stdev 0.498681), 0:00:00.078126, 1518
B: 506, 1, 1, 1, False, 1.000000, 255, 0.503953 (stdev 0.499497), 0:00:00, 0
A: cycle: 506
average reward: 0.472332 (stdev 0.498681)
B: cycle: 506
average reward: 0.503953 (stdev 0.499497)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 507, 0, 1, 1, False, 1.000000, 240, 0.473373 (stdev 0.498741), 0:00:00.062498, 1521
B: 507, 0, 0, 1, False, 1.000000, 255, 0.502959 (stdev 0.499491), 0:00:00, 0
A: cycle: 507
average reward: 0.473373 (stdev 0.498741)
B: cycle: 507
average reward: 0.502959 (stdev 0.499491)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 508, 1, 1, 0, False, 1.000000, 241, 0.474409 (stdev 0.498799), 0:00:00.093750, 1524
B: 508, 1, 1, 0, False, 1.000000, 256, 0.503937 (stdev 0.499499), 0:00:00, 0
A: cycle: 508
average reward: 0.474409 (stdev 0.498799)
B: cycle: 508
average reward: 0.503937 (stdev 0.499499)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 509, 0, 1, 0, False, 1.000000, 242, 0.475442 (stdev 0.498854), 0:00:00.078125, 1527
B: 509, 0, 1, 0, False, 1.000000, 257, 0.504912 (stdev 0.499493), 0:00:00, 0
A: cycle: 509
average reward: 0.475442 (stdev 0.498854)
B: cycle: 509
average reward: 0.504912 (stdev 0.499493)
A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 510, 1, 0, 0, False, 1.000000, 242, 0.474510 (stdev 0.498907), 0:00:00.062500, 1530
B: 510, 1, 0, 0, False, 1.000000, 257, 0.503922 (stdev 0.499485), 0:00:00, 0
A: cycle: 510
average reward: 0.474510 (stdev 0.498907)
B: cycle: 510
average reward: 0.503922 (stdev 0.499485)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 511, 0, 1, 1, False, 1.000000, 243, 0.475538 (stdev 0.498861), 0:00:00.062499, 1533
B: 511, 0, 1, 1, False, 1.000000, 258, 0.504892 (stdev 0.499495), 0:00:00, 0
A: cycle: 511
average reward: 0.475538 (stdev 0.498861)
B: cycle: 511
average reward: 0.504892 (stdev 0.499495)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 512, 1, 1, 0, False, 1.000000, 244, 0.476562 (stdev 0.498913), 0:00:00.109375, 1536
B: 512, 1, 1, 0, False, 1.000000, 259, 0.505859 (stdev 0.499488), 0:00:00, 0
A: cycle: 512
average reward: 0.476562 (stdev 0.498913)
B: cycle: 512
average reward: 0.505859 (stdev 0.499488)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 513, 0, 1, 1, False, 1.000000, 245, 0.477583 (stdev 0.498963), 0:00:00.046875, 1539
B: 513, 0, 1, 0, False, 1.000000, 260, 0.506823 (stdev 0.499478), 0:00:00, 0
A: cycle: 513
average reward: 0.477583 (stdev 0.498963)
B: cycle: 513
average reward: 0.506823 (stdev 0.499478)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 514, 1, 1, 0, False, 1.000000, 246, 0.478599 (stdev 0.499011), 0:00:00.078124, 1542
B: 514, 1, 0, 0, False, 1.000000, 260, 0.505837 (stdev 0.499467), 0:00:00, 0
A: cycle: 514
average reward: 0.478599 (stdev 0.499011)
B: cycle: 514
average reward: 0.505837 (stdev 0.499467)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 515, 0, 1, 1, False, 1.000000, 247, 0.479612 (stdev 0.499057), 0:00:00.093751, 1545
B: 515, 0, 1, 1, False, 1.000000, 261, 0.506796 (stdev 0.499480), 0:00:00, 0
A: cycle: 515
average reward: 0.479612 (stdev 0.499057)
B: cycle: 515
average reward: 0.506796 (stdev 0.499480)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 516, 1, 1, 0, False, 1.000000, 248, 0.480620 (stdev 0.499100), 0:00:00.093749, 1548
B: 516, 1, 1, 1, False, 1.000000, 262, 0.507752 (stdev 0.499469), 0:00:00, 0
A: cycle: 516
average reward: 0.480620 (stdev 0.499100)
B: cycle: 516
average reward: 0.507752 (stdev 0.499469)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 517, 0, 1, 1, False, 1.000000, 249, 0.481625 (stdev 0.499141), 0:00:00.062500, 1551
B: 517, 0, 0, 0, False, 1.000000, 262, 0.506770 (stdev 0.499456), 0:00:00, 0
A: cycle: 517
average reward: 0.481625 (stdev 0.499141)
B: cycle: 517
average reward: 0.506770 (stdev 0.499456)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 518, 1, 1, 0, False, 1.000000, 250, 0.482625 (stdev 0.499180), 0:00:00.109374, 1554
B: 518, 1, 0, 1, False, 1.000000, 262, 0.505792 (stdev 0.499471), 0:00:00, 0
A: cycle: 518
average reward: 0.482625 (stdev 0.499180)
B: cycle: 518
average reward: 0.505792 (stdev 0.499471)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 519, 0, 1, 1, False, 1.000000, 251, 0.483622 (stdev 0.499216), 0:00:00.078126, 1557
B: 519, 0, 0, 0, False, 1.000000, 262, 0.504817 (stdev 0.499485), 0:00:00, 0
A: cycle: 519
average reward: 0.483622 (stdev 0.499216)
B: cycle: 519
average reward: 0.504817 (stdev 0.499485)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 520, 1, 1, 0, False, 1.000000, 252, 0.484615 (stdev 0.499251), 0:00:00.062498, 1560
B: 520, 1, 0, 0, False, 1.000000, 262, 0.503846 (stdev 0.499496), 0:00:00, 0
A: cycle: 520
average reward: 0.484615 (stdev 0.499251)
B: cycle: 520
average reward: 0.503846 (stdev 0.499496)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 521, 0, 1, 1, False, 1.000000, 253, 0.485605 (stdev 0.499283), 0:00:00.046874, 1563
B: 521, 0, 1, 1, False, 1.000000, 263, 0.504798 (stdev 0.499505), 0:00:00, 0
A: cycle: 521
average reward: 0.485605 (stdev 0.499283)
B: cycle: 521
average reward: 0.504798 (stdev 0.499505)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 522, 1, 1, 0, False, 1.000000, 254, 0.486590 (stdev 0.499314), 0:00:00.046887, 1566
B: 522, 1, 1, 0, False, 1.000000, 264, 0.505747 (stdev 0.499498), 0:00:00, 0
A: cycle: 522
average reward: 0.486590 (stdev 0.499314)
B: cycle: 522
average reward: 0.505747 (stdev 0.499498)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 523, 0, 1, 1, False, 1.000000, 255, 0.487572 (stdev 0.499342), 0:00:00.046875, 1569
B: 523, 0, 1, 0, False, 1.000000, 265, 0.506692 (stdev 0.499489), 0:00:00, 0
A: cycle: 523
average reward: 0.487572 (stdev 0.499342)
B: cycle: 523
average reward: 0.506692 (stdev 0.499489)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 524, 1, 1, 0, False, 1.000000, 256, 0.488550 (stdev 0.499368), 0:00:00.046879, 1572
B: 524, 1, 0, 0, False, 1.000000, 265, 0.505725 (stdev 0.499478), 0:00:00, 0
A: cycle: 524
average reward: 0.488550 (stdev 0.499368)
B: cycle: 524
average reward: 0.505725 (stdev 0.499478)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 525, 0, 1, 1, False, 1.000000, 257, 0.489524 (stdev 0.499393), 0:00:00.031234, 1575
B: 525, 0, 1, 0, False, 1.000000, 266, 0.506667 (stdev 0.499491), 0:00:00, 0
A: cycle: 525
average reward: 0.489524 (stdev 0.499393)
B: cycle: 525
average reward: 0.506667 (stdev 0.499491)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 526, 1, 1, 0, False, 1.000000, 258, 0.490494 (stdev 0.499415), 0:00:00.066786, 1578
B: 526, 1, 0, 0, False, 1.000000, 266, 0.505703 (stdev 0.499480), 0:00:00, 0
A: cycle: 526
average reward: 0.490494 (stdev 0.499415)
B: cycle: 526
average reward: 0.505703 (stdev 0.499480)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 527, 0, 1, 1, False, 1.000000, 259, 0.491461 (stdev 0.499435), 0:00:00.046876, 1581
B: 527, 0, 1, 1, False, 1.000000, 267, 0.506641 (stdev 0.499493), 0:00:00, 0
A: cycle: 527
average reward: 0.491461 (stdev 0.499435)
B: cycle: 527
average reward: 0.506641 (stdev 0.499493)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 528, 1, 1, 0, False, 1.000000, 260, 0.492424 (stdev 0.499453), 0:00:00.046875, 1584
B: 528, 1, 1, 0, False, 1.000000, 268, 0.507576 (stdev 0.499482), 0:00:00, 0
A: cycle: 528
average reward: 0.492424 (stdev 0.499453)
B: cycle: 528
average reward: 0.507576 (stdev 0.499482)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 529, 0, 1, 1, False, 1.000000, 261, 0.493384 (stdev 0.499470), 0:00:00.046874, 1587
B: 529, 0, 1, 1, False, 1.000000, 269, 0.508507 (stdev 0.499470), 0:00:00, 0
A: cycle: 529
average reward: 0.493384 (stdev 0.499470)
B: cycle: 529
average reward: 0.508507 (stdev 0.499470)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 530, 1, 1, 0, False, 1.000000, 262, 0.494340 (stdev 0.499484), 0:00:00.046887, 1590
B: 530, 1, 1, 0, False, 1.000000, 270, 0.509434 (stdev 0.499456), 0:00:00, 0
A: cycle: 530
average reward: 0.494340 (stdev 0.499484)
B: cycle: 530
average reward: 0.509434 (stdev 0.499456)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 531, 0, 1, 1, False, 1.000000, 263, 0.495292 (stdev 0.499497), 0:00:00.046879, 1593
B: 531, 0, 1, 0, False, 1.000000, 271, 0.510358 (stdev 0.499440), 0:00:00, 0
A: cycle: 531
average reward: 0.495292 (stdev 0.499497)
B: cycle: 531
average reward: 0.510358 (stdev 0.499440)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 532, 1, 1, 0, False, 1.000000, 264, 0.496241 (stdev 0.499508), 0:00:00.031250, 1596
B: 532, 1, 0, 1, False, 1.000000, 271, 0.509398 (stdev 0.499423), 0:00:00, 0
A: cycle: 532
average reward: 0.496241 (stdev 0.499508)
B: cycle: 532
average reward: 0.509398 (stdev 0.499423)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 533, 0, 1, 1, False, 1.000000, 265, 0.497186 (stdev 0.499517), 0:00:00.046871, 1599
B: 533, 0, 0, 1, False, 1.000000, 271, 0.508443 (stdev 0.499442), 0:00:00, 0
A: cycle: 533
average reward: 0.497186 (stdev 0.499517)
B: cycle: 533
average reward: 0.508443 (stdev 0.499442)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 534, 1, 1, 1, False, 1.000000, 266, 0.498127 (stdev 0.499524), 0:00:00.046862, 1602
B: 534, 1, 1, 0, False, 1.000000, 272, 0.509363 (stdev 0.499460), 0:00:00, 0
A: cycle: 534
average reward: 0.498127 (stdev 0.499524)
B: cycle: 534
average reward: 0.509363 (stdev 0.499460)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 535, 0, 0, 1, False, 1.000000, 266, 0.497196 (stdev 0.499529), 0:00:00.046895, 1605
B: 535, 0, 1, 1, False, 1.000000, 273, 0.510280 (stdev 0.499445), 0:00:00, 0
A: cycle: 535
average reward: 0.497196 (stdev 0.499529)
B: cycle: 535
average reward: 0.510280 (stdev 0.499445)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 536, 1, 1, 0, False, 1.000000, 267, 0.498134 (stdev 0.499526), 0:00:00.046866, 1608
B: 536, 1, 1, 1, False, 1.000000, 274, 0.511194 (stdev 0.499428), 0:00:00, 0
A: cycle: 536
average reward: 0.498134 (stdev 0.499526)
B: cycle: 536
average reward: 0.511194 (stdev 0.499428)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 537, 0, 1, 1, False, 1.000000, 268, 0.499069 (stdev 0.499531), 0:00:00.046875, 1611
B: 537, 0, 0, 0, False, 1.000000, 274, 0.510242 (stdev 0.499409), 0:00:00, 0
A: cycle: 537
average reward: 0.499069 (stdev 0.499531)
B: cycle: 537
average reward: 0.510242 (stdev 0.499409)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 538, 1, 1, 1, False, 1.000000, 269, 0.500000 (stdev 0.499534), 0:00:00.049032, 1614
B: 538, 1, 0, 0, False, 1.000000, 274, 0.509294 (stdev 0.499430), 0:00:00, 0
A: cycle: 538
average reward: 0.500000 (stdev 0.499534)
B: cycle: 538
average reward: 0.509294 (stdev 0.499430)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 539, 0, 0, 1, False, 1.000000, 269, 0.499072 (stdev 0.499536), 0:00:00.029762, 1617
B: 539, 0, 1, 0, False, 1.000000, 275, 0.510204 (stdev 0.499450), 0:00:00, 0
A: cycle: 539
average reward: 0.499072 (stdev 0.499536)
B: cycle: 539
average reward: 0.510204 (stdev 0.499450)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 540, 1, 1, 0, False, 1.000000, 270, 0.500000 (stdev 0.499536), 0:00:00.046870, 1620
B: 540, 1, 0, 0, False, 1.000000, 275, 0.509259 (stdev 0.499433), 0:00:00, 0
A: cycle: 540
average reward: 0.500000 (stdev 0.499536)
B: cycle: 540
average reward: 0.509259 (stdev 0.499433)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 541, 0, 1, 1, False, 1.000000, 271, 0.500924 (stdev 0.499538), 0:00:00.046863, 1623
B: 541, 0, 1, 0, False, 1.000000, 276, 0.510166 (stdev 0.499452), 0:00:00, 0
A: cycle: 541
average reward: 0.500924 (stdev 0.499538)
B: cycle: 541
average reward: 0.510166 (stdev 0.499452)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 542, 1, 1, 0, False, 1.000000, 272, 0.501845 (stdev 0.499538), 0:00:00.046875, 1626
B: 542, 1, 0, 0, False, 1.000000, 276, 0.509225 (stdev 0.499435), 0:00:00, 0
A: cycle: 542
average reward: 0.501845 (stdev 0.499538)
B: cycle: 542
average reward: 0.509225 (stdev 0.499435)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 543, 0, 1, 1, False, 1.000000, 273, 0.502762 (stdev 0.499536), 0:00:00.046876, 1629
B: 543, 0, 1, 1, False, 1.000000, 277, 0.510129 (stdev 0.499454), 0:00:00, 0
A: cycle: 543
average reward: 0.502762 (stdev 0.499536)
B: cycle: 543
average reward: 0.510129 (stdev 0.499454)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 544, 1, 1, 0, False, 1.000000, 274, 0.503676 (stdev 0.499533), 0:00:00.031249, 1632
B: 544, 1, 1, 0, False, 1.000000, 278, 0.511029 (stdev 0.499438), 0:00:00, 0
A: cycle: 544
average reward: 0.503676 (stdev 0.499533)
B: cycle: 544
average reward: 0.511029 (stdev 0.499438)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 545, 0, 1, 1, False, 1.000000, 275, 0.504587 (stdev 0.499528), 0:00:00.046875, 1635
B: 545, 0, 1, 0, False, 1.000000, 279, 0.511927 (stdev 0.499420), 0:00:00, 0
A: cycle: 545
average reward: 0.504587 (stdev 0.499528)
B: cycle: 545
average reward: 0.511927 (stdev 0.499420)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 546, 1, 1, 0, False, 1.000000, 276, 0.505495 (stdev 0.499521), 0:00:00.046874, 1638
B: 546, 1, 0, 0, False, 1.000000, 279, 0.510989 (stdev 0.499400), 0:00:00, 0
A: cycle: 546
average reward: 0.505495 (stdev 0.499521)
B: cycle: 546
average reward: 0.510989 (stdev 0.499400)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 547, 0, 1, 1, False, 1.000000, 277, 0.506399 (stdev 0.499513), 0:00:00.046875, 1641
B: 547, 0, 1, 1, False, 1.000000, 280, 0.511883 (stdev 0.499422), 0:00:00, 0
A: cycle: 547
average reward: 0.506399 (stdev 0.499513)
B: cycle: 547
average reward: 0.511883 (stdev 0.499422)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 548, 1, 1, 0, False, 1.000000, 278, 0.507299 (stdev 0.499503), 0:00:00.046875, 1644
B: 548, 1, 1, 0, False, 1.000000, 281, 0.512774 (stdev 0.499402), 0:00:00, 0
A: cycle: 548
average reward: 0.507299 (stdev 0.499503)
B: cycle: 548
average reward: 0.512774 (stdev 0.499402)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 549, 0, 1, 1, False, 1.000000, 279, 0.508197 (stdev 0.499491), 0:00:00.046887, 1647
B: 549, 0, 1, 1, False, 1.000000, 282, 0.513661 (stdev 0.499381), 0:00:00, 0
A: cycle: 549
average reward: 0.508197 (stdev 0.499491)
B: cycle: 549
average reward: 0.513661 (stdev 0.499381)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 550, 1, 1, 0, False, 1.000000, 280, 0.509091 (stdev 0.499478), 0:00:00.031238, 1650
B: 550, 1, 1, 1, False, 1.000000, 283, 0.514545 (stdev 0.499359), 0:00:00, 0
A: cycle: 550
average reward: 0.509091 (stdev 0.499478)
B: cycle: 550
average reward: 0.514545 (stdev 0.499359)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1



A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 551, 0, 1, 1, False, 1.000000, 281, 0.509982 (stdev 0.499463), 0:00:00.046885, 1653
B: 551, 0, 0, 1, False, 1.000000, 283, 0.513612 (stdev 0.499335), 0:00:00, 0
A: cycle: 551
average reward: 0.509982 (stdev 0.499463)
B: cycle: 551
average reward: 0.513612 (stdev 0.499335)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 552, 1, 1, 0, False, 1.000000, 282, 0.510870 (stdev 0.499447), 0:00:00.046877, 1656
B: 552, 1, 1, 0, False, 1.000000, 284, 0.514493 (stdev 0.499362), 0:00:00, 0
A: cycle: 552
average reward: 0.510870 (stdev 0.499447)
B: cycle: 552
average reward: 0.514493 (stdev 0.499362)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 553, 0, 1, 1, False, 1.000000, 283, 0.511754 (stdev 0.499430), 0:00:00.046877, 1659
B: 553, 0, 1, 1, False, 1.000000, 285, 0.515371 (stdev 0.499338), 0:00:00, 0
A: cycle: 553
average reward: 0.511754 (stdev 0.499430)
B: cycle: 553
average reward: 0.515371 (stdev 0.499338)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 554, 1, 1, 0, False, 1.000000, 284, 0.512635 (stdev 0.499410), 0:00:00.035839, 1662
B: 554, 1, 1, 0, False, 1.000000, 286, 0.516245 (stdev 0.499312), 0:00:00, 0
A: cycle: 554
average reward: 0.512635 (stdev 0.499410)
B: cycle: 554
average reward: 0.516245 (stdev 0.499312)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 555, 0, 1, 1, False, 1.000000, 285, 0.513514 (stdev 0.499390), 0:00:00.046875, 1665
B: 555, 0, 1, 0, False, 1.000000, 287, 0.517117 (stdev 0.499286), 0:00:00, 0
A: cycle: 555
average reward: 0.513514 (stdev 0.499390)
B: cycle: 555
average reward: 0.517117 (stdev 0.499286)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 556, 1, 1, 0, False, 1.000000, 286, 0.514388 (stdev 0.499368), 0:00:00.046892, 1668
B: 556, 1, 0, 0, False, 1.000000, 287, 0.516187 (stdev 0.499257), 0:00:00, 0
A: cycle: 556
average reward: 0.514388 (stdev 0.499368)
B: cycle: 556
average reward: 0.516187 (stdev 0.499257)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 557, 0, 1, 1, False, 1.000000, 287, 0.515260 (stdev 0.499344), 0:00:00.046875, 1671
B: 557, 0, 1, 0, False, 1.000000, 288, 0.517056 (stdev 0.499289), 0:00:00, 0
A: cycle: 557
average reward: 0.515260 (stdev 0.499344)
B: cycle: 557
average reward: 0.517056 (stdev 0.499289)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 558, 1, 1, 0, False, 1.000000, 288, 0.516129 (stdev 0.499319), 0:00:00.046874, 1674
B: 558, 1, 0, 1, False, 1.000000, 288, 0.516129 (stdev 0.499261), 0:00:00, 0
A: cycle: 558
average reward: 0.516129 (stdev 0.499319)
B: cycle: 558
average reward: 0.516129 (stdev 0.499261)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 559, 0, 1, 1, False, 1.000000, 289, 0.516995 (stdev 0.499293), 0:00:00.046877, 1677
B: 559, 0, 0, 0, False, 1.000000, 288, 0.515206 (stdev 0.499293), 0:00:00, 0
A: cycle: 559
average reward: 0.516995 (stdev 0.499293)
B: cycle: 559
average reward: 0.515206 (stdev 0.499293)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 560, 1, 1, 0, False, 1.000000, 290, 0.517857 (stdev 0.499265), 0:00:00.046873, 1680
B: 560, 1, 0, 0, False, 1.000000, 288, 0.514286 (stdev 0.499322), 0:00:00, 0
A: cycle: 560
average reward: 0.517857 (stdev 0.499265)
B: cycle: 560
average reward: 0.514286 (stdev 0.499322)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 561, 0, 1, 1, False, 1.000000, 291, 0.518717 (stdev 0.499235), 0:00:00.042900, 1683
B: 561, 0, 1, 1, False, 1.000000, 289, 0.515152 (stdev 0.499350), 0:00:00, 0
A: cycle: 561
average reward: 0.518717 (stdev 0.499235)
B: cycle: 561
average reward: 0.515152 (stdev 0.499350)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 562, 1, 1, 0, False, 1.000000, 292, 0.519573 (stdev 0.499205), 0:00:00.046875, 1686
B: 562, 1, 1, 1, False, 1.000000, 290, 0.516014 (stdev 0.499326), 0:00:00, 0
A: cycle: 562
average reward: 0.519573 (stdev 0.499205)
B: cycle: 562
average reward: 0.516014 (stdev 0.499326)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 563, 0, 1, 1, False, 1.000000, 293, 0.520426 (stdev 0.499173), 0:00:00.046891, 1689
B: 563, 0, 0, 1, False, 1.000000, 290, 0.515098 (stdev 0.499299), 0:00:00, 0
A: cycle: 563
average reward: 0.520426 (stdev 0.499173)
B: cycle: 563
average reward: 0.515098 (stdev 0.499299)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 564, 1, 1, 0, False, 1.000000, 294, 0.521277 (stdev 0.499140), 0:00:00.046875, 1692
B: 564, 1, 1, 0, False, 1.000000, 291, 0.515957 (stdev 0.499329), 0:00:00, 0
A: cycle: 564
average reward: 0.521277 (stdev 0.499140)
B: cycle: 564
average reward: 0.515957 (stdev 0.499329)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 565, 0, 1, 1, False, 1.000000, 295, 0.522124 (stdev 0.499105), 0:00:00.046870, 1695
B: 565, 0, 1, 0, False, 1.000000, 292, 0.516814 (stdev 0.499303), 0:00:00, 0
A: cycle: 565
average reward: 0.522124 (stdev 0.499105)
B: cycle: 565
average reward: 0.516814 (stdev 0.499303)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 566, 1, 1, 0, False, 1.000000, 296, 0.522968 (stdev 0.499069), 0:00:00.040151, 1698
B: 566, 1, 0, 1, False, 1.000000, 292, 0.515901 (stdev 0.499276), 0:00:00, 0
A: cycle: 566
average reward: 0.522968 (stdev 0.499069)
B: cycle: 566
average reward: 0.515901 (stdev 0.499276)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 567, 0, 1, 1, False, 1.000000, 297, 0.523810 (stdev 0.499032), 0:00:00.046875, 1701
B: 567, 0, 0, 1, False, 1.000000, 292, 0.514991 (stdev 0.499306), 0:00:00, 0
A: cycle: 567
average reward: 0.523810 (stdev 0.499032)
B: cycle: 567
average reward: 0.514991 (stdev 0.499306)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 568, 1, 1, 0, False, 1.000000, 298, 0.524648 (stdev 0.498993), 0:00:00.046887, 1704
B: 568, 1, 1, 1, False, 1.000000, 293, 0.515845 (stdev 0.499335), 0:00:00, 0
A: cycle: 568
average reward: 0.524648 (stdev 0.498993)
B: cycle: 568
average reward: 0.515845 (stdev 0.499335)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 569, 0, 1, 1, False, 1.000000, 299, 0.525483 (stdev 0.498953), 0:00:00.046874, 1707
B: 569, 0, 0, 0, False, 1.000000, 293, 0.514938 (stdev 0.499310), 0:00:00, 0
A: cycle: 569
average reward: 0.525483 (stdev 0.498953)
B: cycle: 569
average reward: 0.514938 (stdev 0.499310)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 570, 1, 1, 0, False, 1.000000, 300, 0.526316 (stdev 0.498912), 0:00:00.046874, 1710
B: 570, 1, 0, 1, False, 1.000000, 293, 0.514035 (stdev 0.499338), 0:00:00, 0
A: cycle: 570
average reward: 0.526316 (stdev 0.498912)
B: cycle: 570
average reward: 0.514035 (stdev 0.499338)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 571, 0, 1, 1, False, 1.000000, 301, 0.527145 (stdev 0.498870), 0:00:00.062490, 1713
B: 571, 0, 0, 0, False, 1.000000, 293, 0.513135 (stdev 0.499365), 0:00:00, 0
A: cycle: 571
average reward: 0.527145 (stdev 0.498870)
B: cycle: 571
average reward: 0.513135 (stdev 0.499365)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 572, 1, 1, 0, False, 1.000000, 302, 0.527972 (stdev 0.498826), 0:00:00.046892, 1716
B: 572, 1, 0, 0, False, 1.000000, 293, 0.512238 (stdev 0.499390), 0:00:00, 0
A: cycle: 572
average reward: 0.527972 (stdev 0.498826)
B: cycle: 572
average reward: 0.512238 (stdev 0.499390)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 573, 0, 1, 1, False, 1.000000, 303, 0.528796 (stdev 0.498781), 0:00:00.046857, 1719
B: 573, 0, 1, 1, False, 1.000000, 294, 0.513089 (stdev 0.499414), 0:00:00, 0
A: cycle: 573
average reward: 0.528796 (stdev 0.498781)
B: cycle: 573
average reward: 0.513089 (stdev 0.499414)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 574, 1, 1, 0, False, 1.000000, 304, 0.529617 (stdev 0.498735), 0:00:00.031249, 1722
B: 574, 1, 1, 1, False, 1.000000, 295, 0.513937 (stdev 0.499393), 0:00:00, 0
A: cycle: 574
average reward: 0.529617 (stdev 0.498735)
B: cycle: 574
average reward: 0.513937 (stdev 0.499393)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 575, 0, 1, 1, False, 1.000000, 305, 0.530435 (stdev 0.498688), 0:00:00.046875, 1725
B: 575, 0, 0, 1, False, 1.000000, 295, 0.513043 (stdev 0.499371), 0:00:00, 0
A: cycle: 575
average reward: 0.530435 (stdev 0.498688)
B: cycle: 575
average reward: 0.513043 (stdev 0.499371)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 576, 1, 1, 0, False, 1.000000, 306, 0.531250 (stdev 0.498639), 0:00:00.046875, 1728
B: 576, 1, 1, 1, False, 1.000000, 296, 0.513889 (stdev 0.499396), 0:00:00, 0
A: cycle: 576
average reward: 0.531250 (stdev 0.498639)
B: cycle: 576
average reward: 0.513889 (stdev 0.499396)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 577, 0, 1, 1, False, 1.000000, 307, 0.532062 (stdev 0.498590), 0:00:00.046875, 1731
B: 577, 0, 0, 0, False, 1.000000, 296, 0.512998 (stdev 0.499374), 0:00:00, 0
A: cycle: 577
average reward: 0.532062 (stdev 0.498590)
B: cycle: 577
average reward: 0.512998 (stdev 0.499374)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 578, 1, 1, 0, False, 1.000000, 308, 0.532872 (stdev 0.498539), 0:00:00.046875, 1734
B: 578, 1, 0, 0, False, 1.000000, 296, 0.512111 (stdev 0.499398), 0:00:00, 0
A: cycle: 578
average reward: 0.532872 (stdev 0.498539)
B: cycle: 578
average reward: 0.512111 (stdev 0.499398)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 579, 0, 1, 1, False, 1.000000, 309, 0.533679 (stdev 0.498487), 0:00:00.046886, 1737
B: 579, 0, 1, 1, False, 1.000000, 297, 0.512953 (stdev 0.499421), 0:00:00, 0
A: cycle: 579
average reward: 0.533679 (stdev 0.498487)
B: cycle: 579
average reward: 0.512953 (stdev 0.499421)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 580, 1, 1, 0, False, 1.000000, 310, 0.534483 (stdev 0.498434), 0:00:00.031250, 1740
B: 580, 1, 1, 0, False, 1.000000, 298, 0.513793 (stdev 0.499401), 0:00:00, 0
A: cycle: 580
average reward: 0.534483 (stdev 0.498434)
B: cycle: 580
average reward: 0.513793 (stdev 0.499401)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 581, 0, 1, 1, False, 1.000000, 311, 0.535284 (stdev 0.498380), 0:00:00.046874, 1743
B: 581, 0, 1, 0, False, 1.000000, 299, 0.514630 (stdev 0.499379), 0:00:00, 0
A: cycle: 581
average reward: 0.535284 (stdev 0.498380)
B: cycle: 581
average reward: 0.514630 (stdev 0.499379)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 582, 1, 1, 0, False, 1.000000, 312, 0.536082 (stdev 0.498325), 0:00:00.046876, 1746
B: 582, 1, 0, 1, False, 1.000000, 299, 0.513746 (stdev 0.499356), 0:00:00, 0
A: cycle: 582
average reward: 0.536082 (stdev 0.498325)
B: cycle: 582
average reward: 0.513746 (stdev 0.499356)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 583, 0, 1, 1, False, 1.000000, 313, 0.536878 (stdev 0.498268), 0:00:00.046879, 1749
B: 583, 0, 0, 0, False, 1.000000, 299, 0.512864 (stdev 0.499382), 0:00:00, 0
A: cycle: 583
average reward: 0.536878 (stdev 0.498268)
B: cycle: 583
average reward: 0.512864 (stdev 0.499382)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 584, 1, 1, 1, False, 1.000000, 314, 0.537671 (stdev 0.498211), 0:00:00.046858, 1752
B: 584, 1, 0, 0, False, 1.000000, 299, 0.511986 (stdev 0.499406), 0:00:00, 0
A: cycle: 584
average reward: 0.537671 (stdev 0.498211)
B: cycle: 584
average reward: 0.511986 (stdev 0.499406)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 585, 0, 0, 1, False, 1.000000, 314, 0.536752 (stdev 0.498153), 0:00:00.049344, 1755
B: 585, 0, 1, 1, False, 1.000000, 300, 0.512821 (stdev 0.499429), 0:00:00, 0
A: cycle: 585
average reward: 0.536752 (stdev 0.498153)
B: cycle: 585
average reward: 0.512821 (stdev 0.499429)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 586, 1, 1, 0, False, 1.000000, 315, 0.537543 (stdev 0.498222), 0:00:00.041342, 1758
B: 586, 1, 1, 1, False, 1.000000, 301, 0.513652 (stdev 0.499409), 0:00:00, 0
A: cycle: 586
average reward: 0.537543 (stdev 0.498222)
B: cycle: 586
average reward: 0.513652 (stdev 0.499409)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 587, 0, 1, 1, False, 1.000000, 316, 0.538330 (stdev 0.498164), 0:00:00.031250, 1761
B: 587, 0, 0, 1, False, 1.000000, 301, 0.512777 (stdev 0.499388), 0:00:00, 0
A: cycle: 587
average reward: 0.538330 (stdev 0.498164)
B: cycle: 587
average reward: 0.512777 (stdev 0.499388)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 588, 1, 1, 0, False, 1.000000, 317, 0.539116 (stdev 0.498105), 0:00:00.046875, 1764
B: 588, 1, 1, 0, False, 1.000000, 302, 0.513605 (stdev 0.499412), 0:00:00, 0
A: cycle: 588
average reward: 0.539116 (stdev 0.498105)
B: cycle: 588
average reward: 0.513605 (stdev 0.499412)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 589, 0, 1, 1, False, 1.000000, 318, 0.539898 (stdev 0.498044), 0:00:00.046875, 1767
B: 589, 0, 1, 0, False, 1.000000, 303, 0.514431 (stdev 0.499390), 0:00:00, 0
A: cycle: 589
average reward: 0.539898 (stdev 0.498044)
B: cycle: 589
average reward: 0.514431 (stdev 0.499390)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 590, 1, 1, 0, False, 1.000000, 319, 0.540678 (stdev 0.497983), 0:00:00.046875, 1770
B: 590, 1, 0, 1, False, 1.000000, 303, 0.513559 (stdev 0.499368), 0:00:00, 0
A: cycle: 590
average reward: 0.540678 (stdev 0.497983)
B: cycle: 590
average reward: 0.513559 (stdev 0.499368)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 591, 0, 1, 1, False, 1.000000, 320, 0.541455 (stdev 0.497921), 0:00:00.046886, 1773
B: 591, 0, 0, 1, False, 1.000000, 303, 0.512690 (stdev 0.499393), 0:00:00, 0
A: cycle: 591
average reward: 0.541455 (stdev 0.497921)
B: cycle: 591
average reward: 0.512690 (stdev 0.499393)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 592, 1, 1, 0, False, 1.000000, 321, 0.542230 (stdev 0.497857), 0:00:00.046875, 1776
B: 592, 1, 1, 0, False, 1.000000, 304, 0.513514 (stdev 0.499417), 0:00:00, 0
A: cycle: 592
average reward: 0.542230 (stdev 0.497857)
B: cycle: 592
average reward: 0.513514 (stdev 0.499417)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 593, 0, 1, 1, False, 1.000000, 322, 0.543002 (stdev 0.497793), 0:00:00.046875, 1779
B: 593, 0, 1, 1, False, 1.000000, 305, 0.514334 (stdev 0.499396), 0:00:00, 0
A: cycle: 593
average reward: 0.543002 (stdev 0.497793)
B: cycle: 593
average reward: 0.514334 (stdev 0.499396)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 594, 1, 1, 0, False, 1.000000, 323, 0.543771 (stdev 0.497728), 0:00:00.031255, 1782
B: 594, 1, 1, 1, False, 1.000000, 306, 0.515152 (stdev 0.499374), 0:00:00, 0
A: cycle: 594
average reward: 0.543771 (stdev 0.497728)
B: cycle: 594
average reward: 0.515152 (stdev 0.499374)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 595, 0, 1, 1, False, 1.000000, 324, 0.544538 (stdev 0.497662), 0:00:00.046869, 1785
B: 595, 0, 0, 1, False, 1.000000, 306, 0.514286 (stdev 0.499350), 0:00:00, 0
A: cycle: 595
average reward: 0.544538 (stdev 0.497662)
B: cycle: 595
average reward: 0.514286 (stdev 0.499350)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 596, 1, 1, 0, False, 1.000000, 325, 0.545302 (stdev 0.497594), 0:00:00.046880, 1788
B: 596, 1, 1, 0, False, 1.000000, 307, 0.515101 (stdev 0.499376), 0:00:00, 0
A: cycle: 596
average reward: 0.545302 (stdev 0.497594)
B: cycle: 596
average reward: 0.515101 (stdev 0.499376)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 597, 0, 1, 1, False, 1.000000, 326, 0.546064 (stdev 0.497526), 0:00:00.046870, 1791
B: 597, 0, 1, 1, False, 1.000000, 308, 0.515913 (stdev 0.499353), 0:00:00, 0
A: cycle: 597
average reward: 0.546064 (stdev 0.497526)
B: cycle: 597
average reward: 0.515913 (stdev 0.499353)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 598, 1, 1, 0, False, 1.000000, 327, 0.546823 (stdev 0.497457), 0:00:00.046880, 1794
B: 598, 1, 1, 0, False, 1.000000, 309, 0.516722 (stdev 0.499329), 0:00:00, 0
A: cycle: 598
average reward: 0.546823 (stdev 0.497457)
B: cycle: 598
average reward: 0.516722 (stdev 0.499329)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 599, 0, 1, 1, False, 1.000000, 328, 0.547579 (stdev 0.497387), 0:00:00.031244, 1797
B: 599, 0, 1, 0, False, 1.000000, 310, 0.517529 (stdev 0.499303), 0:00:00, 0
A: cycle: 599
average reward: 0.547579 (stdev 0.497387)
B: cycle: 599
average reward: 0.517529 (stdev 0.499303)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 600, 1, 1, 0, False, 1.000000, 329, 0.548333 (stdev 0.497316), 0:00:00.046880, 1800
B: 600, 1, 0, 0, False, 1.000000, 310, 0.516667 (stdev 0.499276), 0:00:00, 0
A: cycle: 600
average reward: 0.548333 (stdev 0.497316)
B: cycle: 600
average reward: 0.516667 (stdev 0.499276)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0



A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 601, 0, 1, 1, False, 1.000000, 330, 0.549085 (stdev 0.497244), 0:00:00.046859, 1803
B: 601, 0, 1, 1, False, 1.000000, 311, 0.517471 (stdev 0.499306), 0:00:00, 0
A: cycle: 601
average reward: 0.549085 (stdev 0.497244)
B: cycle: 601
average reward: 0.517471 (stdev 0.499306)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 602, 1, 1, 0, False, 1.000000, 331, 0.549834 (stdev 0.497171), 0:00:00.046875, 1806
B: 602, 1, 1, 0, False, 1.000000, 312, 0.518272 (stdev 0.499279), 0:00:00, 0
A: cycle: 602
average reward: 0.549834 (stdev 0.497171)
B: cycle: 602
average reward: 0.518272 (stdev 0.499279)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 603, 0, 1, 1, False, 1.000000, 332, 0.550580 (stdev 0.497098), 0:00:00.046875, 1809
B: 603, 0, 1, 1, False, 1.000000, 313, 0.519071 (stdev 0.499252), 0:00:00, 0
A: cycle: 603
average reward: 0.550580 (stdev 0.497098)
B: cycle: 603
average reward: 0.519071 (stdev 0.499252)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 604, 1, 1, 0, False, 1.000000, 333, 0.551325 (stdev 0.497023), 0:00:00.046875, 1812
B: 604, 1, 1, 1, False, 1.000000, 314, 0.519868 (stdev 0.499222), 0:00:00, 0
A: cycle: 604
average reward: 0.551325 (stdev 0.497023)
B: cycle: 604
average reward: 0.519868 (stdev 0.499222)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 605, 0, 1, 1, False, 1.000000, 334, 0.552066 (stdev 0.496948), 0:00:00.046875, 1815
B: 605, 0, 0, 1, False, 1.000000, 314, 0.519008 (stdev 0.499192), 0:00:00, 0
A: cycle: 605
average reward: 0.552066 (stdev 0.496948)
B: cycle: 605
average reward: 0.519008 (stdev 0.499192)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 606, 1, 1, 0, False, 1.000000, 335, 0.552805 (stdev 0.496871), 0:00:00.046874, 1818
B: 606, 1, 1, 0, False, 1.000000, 315, 0.519802 (stdev 0.499226), 0:00:00, 0
A: cycle: 606
average reward: 0.552805 (stdev 0.496871)
B: cycle: 606
average reward: 0.519802 (stdev 0.499226)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 607, 0, 1, 1, False, 1.000000, 336, 0.553542 (stdev 0.496794), 0:00:00.046876, 1821
B: 607, 0, 1, 0, False, 1.000000, 316, 0.520593 (stdev 0.499196), 0:00:00, 0
A: cycle: 607
average reward: 0.553542 (stdev 0.496794)
B: cycle: 607
average reward: 0.520593 (stdev 0.499196)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 608, 1, 1, 0, False, 1.000000, 337, 0.554276 (stdev 0.496716), 0:00:00.046874, 1824
B: 608, 1, 0, 1, False, 1.000000, 316, 0.519737 (stdev 0.499165), 0:00:00, 0
A: cycle: 608
average reward: 0.554276 (stdev 0.496716)
B: cycle: 608
average reward: 0.519737 (stdev 0.499165)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 609, 0, 1, 1, False, 1.000000, 338, 0.555008 (stdev 0.496637), 0:00:00.046875, 1827
B: 609, 0, 0, 1, False, 1.000000, 316, 0.518883 (stdev 0.499200), 0:00:00, 0
A: cycle: 609
average reward: 0.555008 (stdev 0.496637)
B: cycle: 609
average reward: 0.518883 (stdev 0.499200)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 610, 1, 1, 0, False, 1.000000, 339, 0.555738 (stdev 0.496557), 0:00:00.046875, 1830
B: 610, 1, 1, 1, False, 1.000000, 317, 0.519672 (stdev 0.499234), 0:00:00, 0
A: cycle: 610
average reward: 0.555738 (stdev 0.496557)
B: cycle: 610
average reward: 0.519672 (stdev 0.499234)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 611, 0, 1, 1, False, 1.000000, 340, 0.556465 (stdev 0.496477), 0:00:00.046874, 1833
B: 611, 0, 0, 1, False, 1.000000, 317, 0.518822 (stdev 0.499204), 0:00:00, 0
A: cycle: 611
average reward: 0.556465 (stdev 0.496477)
B: cycle: 611
average reward: 0.518822 (stdev 0.499204)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 612, 1, 1, 0, False, 1.000000, 341, 0.557190 (stdev 0.496395), 0:00:00.031251, 1836
B: 612, 1, 1, 0, False, 1.000000, 318, 0.519608 (stdev 0.499237), 0:00:00, 0
A: cycle: 612
average reward: 0.557190 (stdev 0.496395)
B: cycle: 612
average reward: 0.519608 (stdev 0.499237)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 613, 0, 1, 1, False, 1.000000, 342, 0.557912 (stdev 0.496313), 0:00:00.046874, 1839
B: 613, 0, 1, 1, False, 1.000000, 319, 0.520392 (stdev 0.499208), 0:00:00, 0
A: cycle: 613
average reward: 0.557912 (stdev 0.496313)
B: cycle: 613
average reward: 0.520392 (stdev 0.499208)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 614, 1, 1, 0, False, 1.000000, 343, 0.558632 (stdev 0.496230), 0:00:00.046874, 1842
B: 614, 1, 1, 0, False, 1.000000, 320, 0.521173 (stdev 0.499177), 0:00:00, 0
A: cycle: 614
average reward: 0.558632 (stdev 0.496230)
B: cycle: 614
average reward: 0.521173 (stdev 0.499177)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 615, 0, 1, 1, False, 1.000000, 344, 0.559350 (stdev 0.496147), 0:00:00.062517, 1845
B: 615, 0, 1, 0, False, 1.000000, 321, 0.521951 (stdev 0.499145), 0:00:00, 0
A: cycle: 615
average reward: 0.559350 (stdev 0.496147)
B: cycle: 615
average reward: 0.521951 (stdev 0.499145)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 616, 1, 1, 0, False, 1.000000, 345, 0.560065 (stdev 0.496062), 0:00:00.046858, 1848
B: 616, 1, 0, 1, False, 1.000000, 321, 0.521104 (stdev 0.499112), 0:00:00, 0
A: cycle: 616
average reward: 0.560065 (stdev 0.496062)
B: cycle: 616
average reward: 0.521104 (stdev 0.499112)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 617, 0, 1, 1, False, 1.000000, 346, 0.560778 (stdev 0.495977), 0:00:00.031250, 1851
B: 617, 0, 0, 1, False, 1.000000, 321, 0.520259 (stdev 0.499149), 0:00:00, 0
A: cycle: 617
average reward: 0.560778 (stdev 0.495977)
B: cycle: 617
average reward: 0.520259 (stdev 0.499149)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 618, 1, 1, 0, False, 1.000000, 347, 0.561489 (stdev 0.495891), 0:00:00.046875, 1854
B: 618, 1, 1, 0, False, 1.000000, 322, 0.521036 (stdev 0.499185), 0:00:00, 0
A: cycle: 618
average reward: 0.561489 (stdev 0.495891)
B: cycle: 618
average reward: 0.521036 (stdev 0.499185)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 619, 0, 1, 1, False, 1.000000, 348, 0.562197 (stdev 0.495804), 0:00:00.046874, 1857
B: 619, 0, 1, 0, False, 1.000000, 323, 0.521809 (stdev 0.499154), 0:00:00, 0
A: cycle: 619
average reward: 0.562197 (stdev 0.495804)
B: cycle: 619
average reward: 0.521809 (stdev 0.499154)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 620, 1, 1, 0, False, 1.000000, 349, 0.562903 (stdev 0.495716), 0:00:00.046887, 1860
B: 620, 1, 0, 1, False, 1.000000, 323, 0.520968 (stdev 0.499121), 0:00:00, 0
A: cycle: 620
average reward: 0.562903 (stdev 0.495716)
B: cycle: 620
average reward: 0.520968 (stdev 0.499121)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 621, 0, 1, 1, False, 1.000000, 350, 0.563607 (stdev 0.495628), 0:00:00.046875, 1863
B: 621, 0, 0, 1, False, 1.000000, 323, 0.520129 (stdev 0.499158), 0:00:00, 0
A: cycle: 621
average reward: 0.563607 (stdev 0.495628)
B: cycle: 621
average reward: 0.520129 (stdev 0.499158)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 622, 1, 1, 0, False, 1.000000, 351, 0.564309 (stdev 0.495539), 0:00:00.046875, 1866
B: 622, 1, 1, 1, False, 1.000000, 324, 0.520900 (stdev 0.499193), 0:00:00, 0
A: cycle: 622
average reward: 0.564309 (stdev 0.495539)
B: cycle: 622
average reward: 0.520900 (stdev 0.499193)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 623, 0, 1, 1, False, 1.000000, 352, 0.565008 (stdev 0.495449), 0:00:00.046879, 1869
B: 623, 0, 0, 1, False, 1.000000, 324, 0.520064 (stdev 0.499162), 0:00:00, 0
A: cycle: 623
average reward: 0.565008 (stdev 0.495449)
B: cycle: 623
average reward: 0.520064 (stdev 0.499162)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 624, 1, 1, 0, False, 1.000000, 353, 0.565705 (stdev 0.495359), 0:00:00.031245, 1872
B: 624, 1, 1, 1, False, 1.000000, 325, 0.520833 (stdev 0.499197), 0:00:00, 0
A: cycle: 624
average reward: 0.565705 (stdev 0.495359)
B: cycle: 624
average reward: 0.520833 (stdev 0.499197)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 625, 0, 1, 1, False, 1.000000, 354, 0.566400 (stdev 0.495267), 0:00:00.046863, 1875
B: 625, 0, 0, 1, False, 1.000000, 325, 0.520000 (stdev 0.499166), 0:00:00, 0
A: cycle: 625
average reward: 0.566400 (stdev 0.495267)
B: cycle: 625
average reward: 0.520000 (stdev 0.499166)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 626, 1, 1, 0, False, 1.000000, 355, 0.567093 (stdev 0.495175), 0:00:00.046875, 1878
B: 626, 1, 1, 1, False, 1.000000, 326, 0.520767 (stdev 0.499201), 0:00:00, 0
A: cycle: 626
average reward: 0.567093 (stdev 0.495175)
B: cycle: 626
average reward: 0.520767 (stdev 0.499201)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 627, 0, 1, 1, False, 1.000000, 356, 0.567783 (stdev 0.495083), 0:00:00.046875, 1881
B: 627, 0, 0, 0, False, 1.000000, 326, 0.519936 (stdev 0.499170), 0:00:00, 0
A: cycle: 627
average reward: 0.567783 (stdev 0.495083)
B: cycle: 627
average reward: 0.519936 (stdev 0.499170)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 628, 1, 1, 0, False, 1.000000, 357, 0.568471 (stdev 0.494990), 0:00:00.046874, 1884
B: 628, 1, 0, 1, False, 1.000000, 326, 0.519108 (stdev 0.499204), 0:00:00, 0
A: cycle: 628
average reward: 0.568471 (stdev 0.494990)
B: cycle: 628
average reward: 0.519108 (stdev 0.499204)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 629, 0, 1, 1, False, 1.000000, 358, 0.569157 (stdev 0.494896), 0:00:00.046875, 1887
B: 629, 0, 0, 0, False, 1.000000, 326, 0.518283 (stdev 0.499237), 0:00:00, 0
A: cycle: 629
average reward: 0.569157 (stdev 0.494896)
B: cycle: 629
average reward: 0.518283 (stdev 0.499237)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 630, 1, 1, 0, False, 1.000000, 359, 0.569841 (stdev 0.494801), 0:00:00.046887, 1890
B: 630, 1, 0, 1, False, 1.000000, 326, 0.517460 (stdev 0.499269), 0:00:00, 0
A: cycle: 630
average reward: 0.569841 (stdev 0.494801)
B: cycle: 630
average reward: 0.517460 (stdev 0.499269)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 631, 0, 1, 1, False, 1.000000, 360, 0.570523 (stdev 0.494706), 0:00:00.031238, 1893
B: 631, 0, 0, 1, False, 1.000000, 326, 0.516640 (stdev 0.499299), 0:00:00, 0
A: cycle: 631
average reward: 0.570523 (stdev 0.494706)
B: cycle: 631
average reward: 0.516640 (stdev 0.499299)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 632, 1, 1, 0, False, 1.000000, 361, 0.571203 (stdev 0.494610), 0:00:00.046887, 1896
B: 632, 1, 1, 1, False, 1.000000, 327, 0.517405 (stdev 0.499328), 0:00:00, 0
A: cycle: 632
average reward: 0.571203 (stdev 0.494610)
B: cycle: 632
average reward: 0.517405 (stdev 0.499328)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 633, 0, 1, 1, False, 1.000000, 362, 0.571880 (stdev 0.494513), 0:00:00.046875, 1899
B: 633, 0, 0, 0, False, 1.000000, 327, 0.516588 (stdev 0.499302), 0:00:00, 0
A: cycle: 633
average reward: 0.571880 (stdev 0.494513)
B: cycle: 633
average reward: 0.516588 (stdev 0.499302)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 634, 1, 1, 0, False, 1.000000, 363, 0.572555 (stdev 0.494416), 0:00:00.046862, 1902
B: 634, 1, 0, 0, False, 1.000000, 327, 0.515773 (stdev 0.499331), 0:00:00, 0
A: cycle: 634
average reward: 0.572555 (stdev 0.494416)
B: cycle: 634
average reward: 0.515773 (stdev 0.499331)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 635, 0, 1, 1, False, 1.000000, 364, 0.573228 (stdev 0.494318), 0:00:00.046875, 1905
B: 635, 0, 1, 1, False, 1.000000, 328, 0.516535 (stdev 0.499357), 0:00:00, 0
A: cycle: 635
average reward: 0.573228 (stdev 0.494318)
B: cycle: 635
average reward: 0.516535 (stdev 0.499357)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 636, 1, 1, 0, False, 1.000000, 365, 0.573899 (stdev 0.494220), 0:00:00.046875, 1908
B: 636, 1, 1, 1, False, 1.000000, 329, 0.517296 (stdev 0.499333), 0:00:00, 0
A: cycle: 636
average reward: 0.573899 (stdev 0.494220)
B: cycle: 636
average reward: 0.517296 (stdev 0.499333)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 637, 0, 1, 1, False, 1.000000, 366, 0.574568 (stdev 0.494120), 0:00:00.046887, 1911
B: 637, 0, 0, 0, False, 1.000000, 329, 0.516484 (stdev 0.499308), 0:00:00, 0
A: cycle: 637
average reward: 0.574568 (stdev 0.494120)
B: cycle: 637
average reward: 0.516484 (stdev 0.499308)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 638, 1, 1, 0, False, 1.000000, 367, 0.575235 (stdev 0.494021), 0:00:00.046875, 1914
B: 638, 1, 0, 0, False, 1.000000, 329, 0.515674 (stdev 0.499336), 0:00:00, 0
A: cycle: 638
average reward: 0.575235 (stdev 0.494021)
B: cycle: 638
average reward: 0.515674 (stdev 0.499336)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 639, 0, 1, 1, False, 1.000000, 368, 0.575900 (stdev 0.493920), 0:00:00.031249, 1917
B: 639, 0, 1, 1, False, 1.000000, 330, 0.516432 (stdev 0.499363), 0:00:00, 0
A: cycle: 639
average reward: 0.575900 (stdev 0.493920)
B: cycle: 639
average reward: 0.516432 (stdev 0.499363)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 640, 1, 1, 0, False, 1.000000, 369, 0.576562 (stdev 0.493819), 0:00:00.046876, 1920
B: 640, 1, 1, 0, False, 1.000000, 331, 0.517188 (stdev 0.499339), 0:00:00, 0
A: cycle: 640
average reward: 0.576562 (stdev 0.493819)
B: cycle: 640
average reward: 0.517188 (stdev 0.499339)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 641, 0, 1, 1, False, 1.000000, 370, 0.577223 (stdev 0.493718), 0:00:00.046862, 1923
B: 641, 0, 1, 1, False, 1.000000, 332, 0.517941 (stdev 0.499315), 0:00:00, 0
A: cycle: 641
average reward: 0.577223 (stdev 0.493718)
B: cycle: 641
average reward: 0.517941 (stdev 0.499315)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 642, 1, 1, 0, False, 1.000000, 371, 0.577882 (stdev 0.493616), 0:00:00.046887, 1926
B: 642, 1, 1, 0, False, 1.000000, 333, 0.518692 (stdev 0.499289), 0:00:00, 0
A: cycle: 642
average reward: 0.577882 (stdev 0.493616)
B: cycle: 642
average reward: 0.518692 (stdev 0.499289)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 643, 0, 1, 1, False, 1.000000, 372, 0.578538 (stdev 0.493513), 0:00:00.046875, 1929
B: 643, 0, 1, 1, False, 1.000000, 334, 0.519440 (stdev 0.499262), 0:00:00, 0
A: cycle: 643
average reward: 0.578538 (stdev 0.493513)
B: cycle: 643
average reward: 0.519440 (stdev 0.499262)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 644, 1, 1, 0, False, 1.000000, 373, 0.579193 (stdev 0.493410), 0:00:00.046875, 1932
B: 644, 1, 1, 1, False, 1.000000, 335, 0.520186 (stdev 0.499234), 0:00:00, 0
A: cycle: 644
average reward: 0.579193 (stdev 0.493410)
B: cycle: 644
average reward: 0.520186 (stdev 0.499234)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 645, 0, 1, 1, False, 1.000000, 374, 0.579845 (stdev 0.493306), 0:00:00.031250, 1935
B: 645, 0, 0, 0, False, 1.000000, 335, 0.519380 (stdev 0.499205), 0:00:00, 0
A: cycle: 645
average reward: 0.579845 (stdev 0.493306)
B: cycle: 645
average reward: 0.519380 (stdev 0.499205)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 646, 1, 1, 0, False, 1.000000, 375, 0.580495 (stdev 0.493201), 0:00:00.046879, 1938
B: 646, 1, 0, 1, False, 1.000000, 335, 0.518576 (stdev 0.499237), 0:00:00, 0
A: cycle: 646
average reward: 0.580495 (stdev 0.493201)
B: cycle: 646
average reward: 0.518576 (stdev 0.499237)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 647, 0, 1, 1, False, 1.000000, 376, 0.581144 (stdev 0.493096), 0:00:00.046870, 1941
B: 647, 0, 0, 0, False, 1.000000, 335, 0.517774 (stdev 0.499269), 0:00:00, 0
A: cycle: 647
average reward: 0.581144 (stdev 0.493096)
B: cycle: 647
average reward: 0.517774 (stdev 0.499269)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 648, 1, 1, 0, False, 1.000000, 377, 0.581790 (stdev 0.492991), 0:00:00.046875, 1944
B: 648, 1, 0, 1, False, 1.000000, 335, 0.516975 (stdev 0.499298), 0:00:00, 0
A: cycle: 648
average reward: 0.581790 (stdev 0.492991)
B: cycle: 648
average reward: 0.516975 (stdev 0.499298)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 649, 0, 1, 1, False, 1.000000, 378, 0.582435 (stdev 0.492885), 0:00:00.046875, 1947
B: 649, 0, 0, 1, False, 1.000000, 335, 0.516179 (stdev 0.499327), 0:00:00, 0
A: cycle: 649
average reward: 0.582435 (stdev 0.492885)
B: cycle: 649
average reward: 0.516179 (stdev 0.499327)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 650, 1, 1, 0, False, 1.000000, 379, 0.583077 (stdev 0.492778), 0:00:00.046880, 1950
B: 650, 1, 1, 1, False, 1.000000, 336, 0.516923 (stdev 0.499354), 0:00:00, 0
A: cycle: 650
average reward: 0.583077 (stdev 0.492778)
B: cycle: 650
average reward: 0.516923 (stdev 0.499354)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1



A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 651, 0, 1, 1, False, 1.000000, 380, 0.583717 (stdev 0.492671), 0:00:00.046858, 1953
B: 651, 0, 0, 1, False, 1.000000, 336, 0.516129 (stdev 0.499330), 0:00:00, 0
A: cycle: 651
average reward: 0.583717 (stdev 0.492671)
B: cycle: 651
average reward: 0.516129 (stdev 0.499330)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 652, 1, 1, 0, False, 1.000000, 381, 0.584356 (stdev 0.492563), 0:00:00.046891, 1956
B: 652, 1, 1, 0, False, 1.000000, 337, 0.516871 (stdev 0.499356), 0:00:00, 0
A: cycle: 652
average reward: 0.584356 (stdev 0.492563)
B: cycle: 652
average reward: 0.516871 (stdev 0.499356)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 653, 0, 1, 1, False, 1.000000, 382, 0.584992 (stdev 0.492455), 0:00:00.046858, 1959
B: 653, 0, 1, 1, False, 1.000000, 338, 0.517611 (stdev 0.499333), 0:00:00, 0
A: cycle: 653
average reward: 0.584992 (stdev 0.492455)
B: cycle: 653
average reward: 0.517611 (stdev 0.499333)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 654, 1, 1, 0, False, 1.000000, 383, 0.585627 (stdev 0.492347), 0:00:00.046887, 1962
B: 654, 1, 1, 0, False, 1.000000, 339, 0.518349 (stdev 0.499308), 0:00:00, 0
A: cycle: 654
average reward: 0.585627 (stdev 0.492347)
B: cycle: 654
average reward: 0.518349 (stdev 0.499308)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 655, 0, 1, 1, False, 1.000000, 384, 0.586260 (stdev 0.492237), 0:00:00.046864, 1965
B: 655, 0, 1, 0, False, 1.000000, 340, 0.519084 (stdev 0.499282), 0:00:00, 0
A: cycle: 655
average reward: 0.586260 (stdev 0.492237)
B: cycle: 655
average reward: 0.519084 (stdev 0.499282)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 656, 1, 1, 0, False, 1.000000, 385, 0.586890 (stdev 0.492128), 0:00:00.046890, 1968
B: 656, 1, 0, 0, False, 1.000000, 340, 0.518293 (stdev 0.499255), 0:00:00, 0
A: cycle: 656
average reward: 0.586890 (stdev 0.492128)
B: cycle: 656
average reward: 0.518293 (stdev 0.499255)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 657, 0, 1, 1, False, 1.000000, 386, 0.587519 (stdev 0.492017), 0:00:00.046875, 1971
B: 657, 0, 1, 0, False, 1.000000, 341, 0.519026 (stdev 0.499285), 0:00:00, 0
A: cycle: 657
average reward: 0.587519 (stdev 0.492017)
B: cycle: 657
average reward: 0.519026 (stdev 0.499285)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 658, 1, 1, 0, False, 1.000000, 387, 0.588146 (stdev 0.491907), 0:00:00.046877, 1974
B: 658, 1, 0, 1, False, 1.000000, 341, 0.518237 (stdev 0.499258), 0:00:00, 0
A: cycle: 658
average reward: 0.588146 (stdev 0.491907)
B: cycle: 658
average reward: 0.518237 (stdev 0.499258)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 659, 0, 1, 1, False, 1.000000, 388, 0.588771 (stdev 0.491795), 0:00:00.062498, 1977
B: 659, 0, 0, 1, False, 1.000000, 341, 0.517451 (stdev 0.499288), 0:00:00, 0
A: cycle: 659
average reward: 0.588771 (stdev 0.491795)
B: cycle: 659
average reward: 0.517451 (stdev 0.499288)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 660, 1, 1, 0, False, 1.000000, 389, 0.589394 (stdev 0.491684), 0:00:00.046858, 1980
B: 660, 1, 1, 1, False, 1.000000, 342, 0.518182 (stdev 0.499317), 0:00:00, 0
A: cycle: 660
average reward: 0.589394 (stdev 0.491684)
B: cycle: 660
average reward: 0.518182 (stdev 0.499317)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 661, 0, 1, 1, False, 1.000000, 390, 0.590015 (stdev 0.491572), 0:00:00.046875, 1983
B: 661, 0, 0, 1, False, 1.000000, 342, 0.517398 (stdev 0.499291), 0:00:00, 0
A: cycle: 661
average reward: 0.590015 (stdev 0.491572)
B: cycle: 661
average reward: 0.517398 (stdev 0.499291)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 662, 1, 1, 0, False, 1.000000, 391, 0.590634 (stdev 0.491459), 0:00:00.031266, 1986
B: 662, 1, 1, 0, False, 1.000000, 343, 0.518127 (stdev 0.499320), 0:00:00, 0
A: cycle: 662
average reward: 0.590634 (stdev 0.491459)
B: cycle: 662
average reward: 0.518127 (stdev 0.499320)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 663, 0, 1, 0, False, 1.000000, 392, 0.591252 (stdev 0.491346), 0:00:00.046875, 1989
B: 663, 0, 1, 0, False, 1.000000, 344, 0.518854 (stdev 0.499294), 0:00:00, 0
A: cycle: 663
average reward: 0.591252 (stdev 0.491346)
B: cycle: 663
average reward: 0.518854 (stdev 0.499294)
A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 664, 1, 0, 0, False, 1.000000, 392, 0.590361 (stdev 0.491232), 0:00:00.046875, 1992
B: 664, 1, 0, 1, False, 1.000000, 344, 0.518072 (stdev 0.499268), 0:00:00, 0
A: cycle: 664
average reward: 0.590361 (stdev 0.491232)
B: cycle: 664
average reward: 0.518072 (stdev 0.499268)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 665, 0, 1, 1, False, 1.000000, 393, 0.590977 (stdev 0.491397), 0:00:00.046870, 1995
B: 665, 0, 0, 1, False, 1.000000, 344, 0.517293 (stdev 0.499297), 0:00:00, 0
A: cycle: 665
average reward: 0.590977 (stdev 0.491397)
B: cycle: 665
average reward: 0.517293 (stdev 0.499297)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 666, 1, 1, 0, False, 1.000000, 394, 0.591592 (stdev 0.491284), 0:00:00.046875, 1998
B: 666, 1, 1, 1, False, 1.000000, 345, 0.518018 (stdev 0.499326), 0:00:00, 0
A: cycle: 666
average reward: 0.591592 (stdev 0.491284)
B: cycle: 666
average reward: 0.518018 (stdev 0.499326)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 667, 0, 1, 1, False, 1.000000, 395, 0.592204 (stdev 0.491171), 0:00:00.046879, 2001
B: 667, 0, 0, 0, False, 1.000000, 345, 0.517241 (stdev 0.499301), 0:00:00, 0
A: cycle: 667
average reward: 0.592204 (stdev 0.491171)
B: cycle: 667
average reward: 0.517241 (stdev 0.499301)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 668, 1, 1, 1, False, 1.000000, 396, 0.592814 (stdev 0.491057), 0:00:00.031250, 2004
B: 668, 1, 0, 0, False, 1.000000, 345, 0.516467 (stdev 0.499328), 0:00:00, 0
A: cycle: 668
average reward: 0.592814 (stdev 0.491057)
B: cycle: 668
average reward: 0.516467 (stdev 0.499328)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 669, 0, 0, 1, False, 1.000000, 396, 0.591928 (stdev 0.490943), 0:00:00.046870, 2007
B: 669, 0, 1, 1, False, 1.000000, 346, 0.517190 (stdev 0.499355), 0:00:00, 0
A: cycle: 669
average reward: 0.591928 (stdev 0.490943)
B: cycle: 669
average reward: 0.517190 (stdev 0.499355)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 670, 1, 1, 1, False, 1.000000, 397, 0.592537 (stdev 0.491110), 0:00:00.046875, 2010
B: 670, 1, 1, 1, False, 1.000000, 347, 0.517910 (stdev 0.499331), 0:00:00, 0
A: cycle: 670
average reward: 0.592537 (stdev 0.491110)
B: cycle: 670
average reward: 0.517910 (stdev 0.499331)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 671, 0, 0, 1, False, 1.000000, 397, 0.591654 (stdev 0.490996), 0:00:00.046863, 2013
B: 671, 0, 0, 0, False, 1.000000, 347, 0.517139 (stdev 0.499307), 0:00:00, 0
A: cycle: 671
average reward: 0.591654 (stdev 0.490996)
B: cycle: 671
average reward: 0.517139 (stdev 0.499307)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 672, 1, 1, 0, False, 1.000000, 398, 0.592262 (stdev 0.491162), 0:00:00.046887, 2016
B: 672, 1, 0, 0, False, 1.000000, 347, 0.516369 (stdev 0.499334), 0:00:00, 0
A: cycle: 672
average reward: 0.592262 (stdev 0.491162)
B: cycle: 672
average reward: 0.516369 (stdev 0.499334)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 673, 0, 1, 1, False, 1.000000, 399, 0.592868 (stdev 0.491049), 0:00:00.046879, 2019
B: 673, 0, 1, 1, False, 1.000000, 348, 0.517088 (stdev 0.499361), 0:00:00, 0
A: cycle: 673
average reward: 0.592868 (stdev 0.491049)
B: cycle: 673
average reward: 0.517088 (stdev 0.499361)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 674, 1, 1, 0, False, 1.000000, 400, 0.593472 (stdev 0.490935), 0:00:00.046870, 2022
B: 674, 1, 1, 1, False, 1.000000, 349, 0.517804 (stdev 0.499337), 0:00:00, 0
A: cycle: 674
average reward: 0.593472 (stdev 0.490935)
B: cycle: 674
average reward: 0.517804 (stdev 0.499337)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 675, 0, 1, 1, False, 1.000000, 401, 0.594074 (stdev 0.490821), 0:00:00.031251, 2025
B: 675, 0, 0, 1, False, 1.000000, 349, 0.517037 (stdev 0.499313), 0:00:00, 0
A: cycle: 675
average reward: 0.594074 (stdev 0.490821)
B: cycle: 675
average reward: 0.517037 (stdev 0.499313)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 676, 1, 1, 0, False, 1.000000, 402, 0.594675 (stdev 0.490707), 0:00:00.046862, 2028
B: 676, 1, 1, 0, False, 1.000000, 350, 0.517751 (stdev 0.499340), 0:00:00, 0
A: cycle: 676
average reward: 0.594675 (stdev 0.490707)
B: cycle: 676
average reward: 0.517751 (stdev 0.499340)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 677, 0, 1, 1, False, 1.000000, 403, 0.595273 (stdev 0.490592), 0:00:00.046875, 2031
B: 677, 0, 1, 1, False, 1.000000, 351, 0.518464 (stdev 0.499316), 0:00:00, 0
A: cycle: 677
average reward: 0.595273 (stdev 0.490592)
B: cycle: 677
average reward: 0.518464 (stdev 0.499316)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 678, 1, 1, 0, False, 1.000000, 404, 0.595870 (stdev 0.490477), 0:00:00.046874, 2034
B: 678, 1, 1, 1, False, 1.000000, 352, 0.519174 (stdev 0.499290), 0:00:00, 0
A: cycle: 678
average reward: 0.595870 (stdev 0.490477)
B: cycle: 678
average reward: 0.519174 (stdev 0.499290)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 679, 0, 1, 1, False, 1.000000, 405, 0.596465 (stdev 0.490361), 0:00:00.046875, 2037
B: 679, 0, 0, 1, False, 1.000000, 352, 0.518409 (stdev 0.499264), 0:00:00, 0
A: cycle: 679
average reward: 0.596465 (stdev 0.490361)
B: cycle: 679
average reward: 0.518409 (stdev 0.499264)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 680, 1, 1, 0, False, 1.000000, 406, 0.597059 (stdev 0.490245), 0:00:00.046893, 2040
B: 680, 1, 1, 0, False, 1.000000, 353, 0.519118 (stdev 0.499293), 0:00:00, 0
A: cycle: 680
average reward: 0.597059 (stdev 0.490245)
B: cycle: 680
average reward: 0.519118 (stdev 0.499293)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 681, 0, 1, 1, False, 1.000000, 407, 0.597651 (stdev 0.490129), 0:00:00.031244, 2043
B: 681, 0, 1, 1, False, 1.000000, 354, 0.519824 (stdev 0.499267), 0:00:00, 0
A: cycle: 681
average reward: 0.597651 (stdev 0.490129)
B: cycle: 681
average reward: 0.519824 (stdev 0.499267)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 682, 1, 1, 0, False, 1.000000, 408, 0.598240 (stdev 0.490012), 0:00:00.046874, 2046
B: 682, 1, 1, 1, False, 1.000000, 355, 0.520528 (stdev 0.499240), 0:00:00, 0
A: cycle: 682
average reward: 0.598240 (stdev 0.490012)
B: cycle: 682
average reward: 0.520528 (stdev 0.499240)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 683, 0, 1, 1, False, 1.000000, 409, 0.598829 (stdev 0.489895), 0:00:00.046864, 2049
B: 683, 0, 0, 0, False, 1.000000, 355, 0.519766 (stdev 0.499213), 0:00:00, 0
A: cycle: 683
average reward: 0.598829 (stdev 0.489895)
B: cycle: 683
average reward: 0.519766 (stdev 0.499213)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 684, 1, 1, 0, False, 1.000000, 410, 0.599415 (stdev 0.489777), 0:00:00.046891, 2052
B: 684, 1, 0, 0, False, 1.000000, 355, 0.519006 (stdev 0.499244), 0:00:00, 0
A: cycle: 684
average reward: 0.599415 (stdev 0.489777)
B: cycle: 684
average reward: 0.519006 (stdev 0.499244)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 685, 0, 1, 1, False, 1.000000, 411, 0.600000 (stdev 0.489659), 0:00:00.046871, 2055
B: 685, 0, 1, 0, False, 1.000000, 356, 0.519708 (stdev 0.499274), 0:00:00, 0
A: cycle: 685
average reward: 0.600000 (stdev 0.489659)
B: cycle: 685
average reward: 0.519708 (stdev 0.499274)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 686, 1, 1, 0, False, 1.000000, 412, 0.600583 (stdev 0.489541), 0:00:00.046874, 2058
B: 686, 1, 0, 1, False, 1.000000, 356, 0.518950 (stdev 0.499247), 0:00:00, 0
A: cycle: 686
average reward: 0.600583 (stdev 0.489541)
B: cycle: 686
average reward: 0.518950 (stdev 0.499247)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 687, 0, 1, 1, False, 1.000000, 413, 0.601164 (stdev 0.489422), 0:00:00.046863, 2061
B: 687, 0, 0, 0, False, 1.000000, 356, 0.518195 (stdev 0.499277), 0:00:00, 0
A: cycle: 687
average reward: 0.601164 (stdev 0.489422)
B: cycle: 687
average reward: 0.518195 (stdev 0.499277)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 688, 1, 1, 0, False, 1.000000, 414, 0.601744 (stdev 0.489303), 0:00:00.031250, 2064
B: 688, 1, 0, 1, False, 1.000000, 356, 0.517442 (stdev 0.499306), 0:00:00, 0
A: cycle: 688
average reward: 0.601744 (stdev 0.489303)
B: cycle: 688
average reward: 0.517442 (stdev 0.499306)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 689, 0, 1, 1, False, 1.000000, 415, 0.602322 (stdev 0.489183), 0:00:00.046888, 2067
B: 689, 0, 0, 1, False, 1.000000, 356, 0.516691 (stdev 0.499333), 0:00:00, 0
A: cycle: 689
average reward: 0.602322 (stdev 0.489183)
B: cycle: 689
average reward: 0.516691 (stdev 0.499333)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 690, 1, 1, 0, False, 1.000000, 416, 0.602899 (stdev 0.489063), 0:00:00.046873, 2070
B: 690, 1, 1, 0, False, 1.000000, 357, 0.517391 (stdev 0.499359), 0:00:00, 0
A: cycle: 690
average reward: 0.602899 (stdev 0.489063)
B: cycle: 690
average reward: 0.517391 (stdev 0.499359)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 691, 0, 1, 1, False, 1.000000, 417, 0.603473 (stdev 0.488943), 0:00:00.046875, 2073
B: 691, 0, 1, 1, False, 1.000000, 358, 0.518090 (stdev 0.499336), 0:00:00, 0
A: cycle: 691
average reward: 0.603473 (stdev 0.488943)
B: cycle: 691
average reward: 0.518090 (stdev 0.499336)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 692, 1, 1, 0, False, 1.000000, 418, 0.604046 (stdev 0.488823), 0:00:00.046863, 2076
B: 692, 1, 1, 1, False, 1.000000, 359, 0.518786 (stdev 0.499311), 0:00:00, 0
A: cycle: 692
average reward: 0.604046 (stdev 0.488823)
B: cycle: 692
average reward: 0.518786 (stdev 0.499311)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 693, 0, 1, 1, False, 1.000000, 419, 0.604618 (stdev 0.488702), 0:00:00.046892, 2079
B: 693, 0, 0, 0, False, 1.000000, 359, 0.518038 (stdev 0.499286), 0:00:00, 0
A: cycle: 693
average reward: 0.604618 (stdev 0.488702)
B: cycle: 693
average reward: 0.518038 (stdev 0.499286)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 694, 1, 1, 0, False, 1.000000, 420, 0.605187 (stdev 0.488580), 0:00:00.046332, 2082
B: 694, 1, 0, 1, False, 1.000000, 359, 0.517291 (stdev 0.499314), 0:00:00, 0
A: cycle: 694
average reward: 0.605187 (stdev 0.488580)
B: cycle: 694
average reward: 0.517291 (stdev 0.499314)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 695, 0, 1, 1, False, 1.000000, 421, 0.605755 (stdev 0.488459), 0:00:00.044912, 2085
B: 695, 0, 0, 1, False, 1.000000, 359, 0.516547 (stdev 0.499341), 0:00:00, 0
A: cycle: 695
average reward: 0.605755 (stdev 0.488459)
B: cycle: 695
average reward: 0.516547 (stdev 0.499341)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 696, 1, 1, 0, False, 1.000000, 422, 0.606322 (stdev 0.488337), 0:00:00.033564, 2088
B: 696, 1, 1, 1, False, 1.000000, 360, 0.517241 (stdev 0.499367), 0:00:00, 0
A: cycle: 696
average reward: 0.606322 (stdev 0.488337)
B: cycle: 696
average reward: 0.517241 (stdev 0.499367)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 697, 0, 1, 1, False, 1.000000, 423, 0.606887 (stdev 0.488214), 0:00:00.046870, 2091
B: 697, 0, 0, 0, False, 1.000000, 360, 0.516499 (stdev 0.499344), 0:00:00, 0
A: cycle: 697
average reward: 0.606887 (stdev 0.488214)
B: cycle: 697
average reward: 0.516499 (stdev 0.499344)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 698, 1, 1, 0, False, 1.000000, 424, 0.607450 (stdev 0.488092), 0:00:00.046875, 2094
B: 698, 1, 0, 1, False, 1.000000, 360, 0.515759 (stdev 0.499370), 0:00:00, 0
A: cycle: 698
average reward: 0.607450 (stdev 0.488092)
B: cycle: 698
average reward: 0.515759 (stdev 0.499370)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 699, 0, 1, 1, False, 1.000000, 425, 0.608011 (stdev 0.487969), 0:00:00.046863, 2097
B: 699, 0, 0, 0, False, 1.000000, 360, 0.515021 (stdev 0.499394), 0:00:00, 0
A: cycle: 699
average reward: 0.608011 (stdev 0.487969)
B: cycle: 699
average reward: 0.515021 (stdev 0.499394)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 700, 1, 1, 0, False, 1.000000, 426, 0.608571 (stdev 0.487845), 0:00:00.031267, 2100
B: 700, 1, 0, 0, False, 1.000000, 360, 0.514286 (stdev 0.499417), 0:00:00, 0
A: cycle: 700
average reward: 0.608571 (stdev 0.487845)
B: cycle: 700
average reward: 0.514286 (stdev 0.499417)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0



A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 701, 0, 1, 1, False, 1.000000, 427, 0.609130 (stdev 0.487722), 0:00:00.046874, 2103
B: 701, 0, 1, 0, False, 1.000000, 361, 0.514979 (stdev 0.499439), 0:00:00, 0
A: cycle: 701
average reward: 0.609130 (stdev 0.487722)
B: cycle: 701
average reward: 0.514979 (stdev 0.499439)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 702, 1, 1, 0, False, 1.000000, 428, 0.609687 (stdev 0.487598), 0:00:00.046876, 2106
B: 702, 1, 0, 1, False, 1.000000, 361, 0.514245 (stdev 0.499419), 0:00:00, 0
A: cycle: 702
average reward: 0.609687 (stdev 0.487598)
B: cycle: 702
average reward: 0.514245 (stdev 0.499419)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 703, 0, 1, 1, False, 1.000000, 429, 0.610242 (stdev 0.487473), 0:00:00.046874, 2109
B: 703, 0, 0, 1, False, 1.000000, 361, 0.513514 (stdev 0.499441), 0:00:00, 0
A: cycle: 703
average reward: 0.610242 (stdev 0.487473)
B: cycle: 703
average reward: 0.513514 (stdev 0.499441)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 704, 1, 1, 0, False, 1.000000, 430, 0.610795 (stdev 0.487349), 0:00:00.046875, 2112
B: 704, 1, 1, 0, False, 1.000000, 362, 0.514205 (stdev 0.499462), 0:00:00, 0
A: cycle: 704
average reward: 0.610795 (stdev 0.487349)
B: cycle: 704
average reward: 0.514205 (stdev 0.499462)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 705, 0, 1, 1, False, 1.000000, 431, 0.611348 (stdev 0.487224), 0:00:00.062500, 2115
B: 705, 0, 1, 1, False, 1.000000, 363, 0.514894 (stdev 0.499444), 0:00:00, 0
A: cycle: 705
average reward: 0.611348 (stdev 0.487224)
B: cycle: 705
average reward: 0.514894 (stdev 0.499444)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 706, 1, 1, 0, False, 1.000000, 432, 0.611898 (stdev 0.487099), 0:00:00.031266, 2118
B: 706, 1, 1, 0, False, 1.000000, 364, 0.515581 (stdev 0.499424), 0:00:00, 0
A: cycle: 706
average reward: 0.611898 (stdev 0.487099)
B: cycle: 706
average reward: 0.515581 (stdev 0.499424)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 707, 0, 1, 1, False, 1.000000, 433, 0.612447 (stdev 0.486973), 0:00:00.046876, 2121
B: 707, 0, 1, 0, False, 1.000000, 365, 0.516266 (stdev 0.499404), 0:00:00, 0
A: cycle: 707
average reward: 0.612447 (stdev 0.486973)
B: cycle: 707
average reward: 0.516266 (stdev 0.499404)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 708, 1, 1, 0, False, 1.000000, 434, 0.612994 (stdev 0.486847), 0:00:00.059066, 2124
B: 708, 1, 0, 1, False, 1.000000, 365, 0.515537 (stdev 0.499382), 0:00:00, 0
A: cycle: 708
average reward: 0.612994 (stdev 0.486847)
B: cycle: 708
average reward: 0.515537 (stdev 0.499382)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 709, 0, 1, 1, False, 1.000000, 435, 0.613540 (stdev 0.486721), 0:00:00.031716, 2127
B: 709, 0, 0, 1, False, 1.000000, 365, 0.514810 (stdev 0.499406), 0:00:00, 0
A: cycle: 709
average reward: 0.613540 (stdev 0.486721)
B: cycle: 709
average reward: 0.514810 (stdev 0.499406)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 710, 1, 1, 0, False, 1.000000, 436, 0.614085 (stdev 0.486595), 0:00:00.046874, 2130
B: 710, 1, 1, 1, False, 1.000000, 366, 0.515493 (stdev 0.499429), 0:00:00, 0
A: cycle: 710
average reward: 0.614085 (stdev 0.486595)
B: cycle: 710
average reward: 0.515493 (stdev 0.499429)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 711, 0, 1, 1, False, 1.000000, 437, 0.614627 (stdev 0.486468), 0:00:00.046874, 2133
B: 711, 0, 0, 0, False, 1.000000, 366, 0.514768 (stdev 0.499408), 0:00:00, 0
A: cycle: 711
average reward: 0.614627 (stdev 0.486468)
B: cycle: 711
average reward: 0.514768 (stdev 0.499408)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 712, 1, 1, 0, False, 1.000000, 438, 0.615169 (stdev 0.486341), 0:00:00.046875, 2136
B: 712, 1, 0, 1, False, 1.000000, 366, 0.514045 (stdev 0.499431), 0:00:00, 0
A: cycle: 712
average reward: 0.615169 (stdev 0.486341)
B: cycle: 712
average reward: 0.514045 (stdev 0.499431)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 713, 0, 1, 1, False, 1.000000, 439, 0.615708 (stdev 0.486214), 0:00:00.046858, 2139
B: 713, 0, 0, 0, False, 1.000000, 366, 0.513324 (stdev 0.499452), 0:00:00, 0
A: cycle: 713
average reward: 0.615708 (stdev 0.486214)
B: cycle: 713
average reward: 0.513324 (stdev 0.499452)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 714, 1, 1, 0, False, 1.000000, 440, 0.616246 (stdev 0.486087), 0:00:00.046875, 2142
B: 714, 1, 0, 0, False, 1.000000, 366, 0.512605 (stdev 0.499472), 0:00:00, 0
A: cycle: 714
average reward: 0.616246 (stdev 0.486087)
B: cycle: 714
average reward: 0.512605 (stdev 0.499472)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 715, 0, 1, 1, False, 1.000000, 441, 0.616783 (stdev 0.485959), 0:00:00.046888, 2145
B: 715, 0, 1, 0, False, 1.000000, 367, 0.513287 (stdev 0.499491), 0:00:00, 0
A: cycle: 715
average reward: 0.616783 (stdev 0.485959)
B: cycle: 715
average reward: 0.513287 (stdev 0.499491)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 716, 1, 1, 0, False, 1.000000, 442, 0.617318 (stdev 0.485831), 0:00:00.046861, 2148
B: 716, 1, 0, 1, False, 1.000000, 367, 0.512570 (stdev 0.499474), 0:00:00, 0
A: cycle: 716
average reward: 0.617318 (stdev 0.485831)
B: cycle: 716
average reward: 0.512570 (stdev 0.499474)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 717, 0, 1, 1, False, 1.000000, 443, 0.617852 (stdev 0.485702), 0:00:00.046875, 2151
B: 717, 0, 0, 0, False, 1.000000, 367, 0.511855 (stdev 0.499493), 0:00:00, 0
A: cycle: 717
average reward: 0.617852 (stdev 0.485702)
B: cycle: 717
average reward: 0.511855 (stdev 0.499493)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 718, 1, 1, 0, False, 1.000000, 444, 0.618384 (stdev 0.485574), 0:00:00.046892, 2154
B: 718, 1, 0, 1, False, 1.000000, 367, 0.511142 (stdev 0.499511), 0:00:00, 0
A: cycle: 718
average reward: 0.618384 (stdev 0.485574)
B: cycle: 718
average reward: 0.511142 (stdev 0.499511)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 719, 0, 1, 1, False, 1.000000, 445, 0.618915 (stdev 0.485445), 0:00:00.031249, 2157
B: 719, 0, 0, 1, False, 1.000000, 367, 0.510431 (stdev 0.499528), 0:00:00, 0
A: cycle: 719
average reward: 0.618915 (stdev 0.485445)
B: cycle: 719
average reward: 0.510431 (stdev 0.499528)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 720, 1, 1, 0, False, 1.000000, 446, 0.619444 (stdev 0.485316), 0:00:00.046875, 2160
B: 720, 1, 1, 1, False, 1.000000, 368, 0.511111 (stdev 0.499544), 0:00:00, 0
A: cycle: 720
average reward: 0.619444 (stdev 0.485316)
B: cycle: 720
average reward: 0.511111 (stdev 0.499544)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 721, 0, 1, 1, False, 1.000000, 447, 0.619972 (stdev 0.485187), 0:00:00.046870, 2163
B: 721, 0, 0, 0, False, 1.000000, 368, 0.510402 (stdev 0.499530), 0:00:00, 0
A: cycle: 721
average reward: 0.619972 (stdev 0.485187)
B: cycle: 721
average reward: 0.510402 (stdev 0.499530)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 722, 1, 1, 0, False, 1.000000, 448, 0.620499 (stdev 0.485057), 0:00:00.046876, 2166
B: 722, 1, 0, 0, False, 1.000000, 368, 0.509695 (stdev 0.499545), 0:00:00, 0
A: cycle: 722
average reward: 0.620499 (stdev 0.485057)
B: cycle: 722
average reward: 0.509695 (stdev 0.499545)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 723, 0, 1, 1, False, 1.000000, 449, 0.621024 (stdev 0.484927), 0:00:00.046874, 2169
B: 723, 0, 1, 0, False, 1.000000, 369, 0.510373 (stdev 0.499560), 0:00:00, 0
A: cycle: 723
average reward: 0.621024 (stdev 0.484927)
B: cycle: 723
average reward: 0.510373 (stdev 0.499560)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 724, 1, 1, 0, False, 1.000000, 450, 0.621547 (stdev 0.484797), 0:00:00.046863, 2172
B: 724, 1, 0, 1, False, 1.000000, 369, 0.509669 (stdev 0.499547), 0:00:00, 0
A: cycle: 724
average reward: 0.621547 (stdev 0.484797)
B: cycle: 724
average reward: 0.509669 (stdev 0.499547)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 725, 0, 1, 1, False, 1.000000, 451, 0.622069 (stdev 0.484667), 0:00:00.031250, 2175
B: 725, 0, 0, 0, False, 1.000000, 369, 0.508966 (stdev 0.499562), 0:00:00, 0
A: cycle: 725
average reward: 0.622069 (stdev 0.484667)
B: cycle: 725
average reward: 0.508966 (stdev 0.499562)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 726, 1, 1, 0, False, 1.000000, 452, 0.622590 (stdev 0.484536), 0:00:00.046875, 2178
B: 726, 1, 0, 0, False, 1.000000, 369, 0.508264 (stdev 0.499575), 0:00:00, 0
A: cycle: 726
average reward: 0.622590 (stdev 0.484536)
B: cycle: 726
average reward: 0.508264 (stdev 0.499575)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 727, 0, 1, 0, False, 1.000000, 453, 0.623109 (stdev 0.484405), 0:00:00.046874, 2181
B: 727, 0, 1, 1, False, 1.000000, 370, 0.508941 (stdev 0.499588), 0:00:00, 0
A: cycle: 727
average reward: 0.623109 (stdev 0.484405)
B: cycle: 727
average reward: 0.508941 (stdev 0.499588)
A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 728, 1, 0, 0, False, 1.000000, 453, 0.622253 (stdev 0.484274), 0:00:00.046887, 2184
B: 728, 1, 1, 1, False, 1.000000, 371, 0.509615 (stdev 0.499577), 0:00:00, 0
A: cycle: 728
average reward: 0.622253 (stdev 0.484274)
B: cycle: 728
average reward: 0.509615 (stdev 0.499577)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 729, 0, 1, 1, False, 1.000000, 454, 0.622771 (stdev 0.484491), 0:00:00.046876, 2187
B: 729, 0, 0, 0, False, 1.000000, 371, 0.508916 (stdev 0.499565), 0:00:00, 0
A: cycle: 729
average reward: 0.622771 (stdev 0.484491)
B: cycle: 729
average reward: 0.508916 (stdev 0.499565)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 730, 1, 1, 0, False, 1.000000, 455, 0.623288 (stdev 0.484361), 0:00:00.046873, 2190
B: 730, 1, 0, 1, False, 1.000000, 371, 0.508219 (stdev 0.499578), 0:00:00, 0
A: cycle: 730
average reward: 0.623288 (stdev 0.484361)
B: cycle: 730
average reward: 0.508219 (stdev 0.499578)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 731, 0, 1, 1, False, 1.000000, 456, 0.623803 (stdev 0.484230), 0:00:00.046880, 2193
B: 731, 0, 0, 0, False, 1.000000, 371, 0.507524 (stdev 0.499590), 0:00:00, 0
A: cycle: 731
average reward: 0.623803 (stdev 0.484230)
B: cycle: 731
average reward: 0.507524 (stdev 0.499590)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 732, 1, 1, 0, False, 1.000000, 457, 0.624317 (stdev 0.484099), 0:00:00.031246, 2196
B: 732, 1, 0, 1, False, 1.000000, 371, 0.506831 (stdev 0.499602), 0:00:00, 0
A: cycle: 732
average reward: 0.624317 (stdev 0.484099)
B: cycle: 732
average reward: 0.506831 (stdev 0.499602)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 733, 0, 1, 1, False, 1.000000, 458, 0.624829 (stdev 0.483968), 0:00:00.046875, 2199
B: 733, 0, 0, 0, False, 1.000000, 371, 0.506139 (stdev 0.499612), 0:00:00, 0
A: cycle: 733
average reward: 0.624829 (stdev 0.483968)
B: cycle: 733
average reward: 0.506139 (stdev 0.499612)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 734, 1, 1, 0, False, 1.000000, 459, 0.625341 (stdev 0.483837), 0:00:00.046862, 2202
B: 734, 1, 0, 1, False, 1.000000, 371, 0.505450 (stdev 0.499622), 0:00:00, 0
A: cycle: 734
average reward: 0.625341 (stdev 0.483837)
B: cycle: 734
average reward: 0.505450 (stdev 0.499622)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 735, 0, 1, 1, False, 1.000000, 460, 0.625850 (stdev 0.483705), 0:00:00.046887, 2205
B: 735, 0, 0, 0, False, 1.000000, 371, 0.504762 (stdev 0.499630), 0:00:00, 0
A: cycle: 735
average reward: 0.625850 (stdev 0.483705)
B: cycle: 735
average reward: 0.504762 (stdev 0.499630)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 736, 1, 1, 0, False, 1.000000, 461, 0.626359 (stdev 0.483574), 0:00:00.046863, 2208
B: 736, 1, 0, 0, False, 1.000000, 371, 0.504076 (stdev 0.499638), 0:00:00, 0
A: cycle: 736
average reward: 0.626359 (stdev 0.483574)
B: cycle: 736
average reward: 0.504076 (stdev 0.499638)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 737, 0, 1, 1, False, 1.000000, 462, 0.626866 (stdev 0.483442), 0:00:00.046874, 2211
B: 737, 0, 1, 0, False, 1.000000, 372, 0.504749 (stdev 0.499644), 0:00:00, 0
A: cycle: 737
average reward: 0.626866 (stdev 0.483442)
B: cycle: 737
average reward: 0.504749 (stdev 0.499644)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 738, 1, 1, 0, False, 1.000000, 463, 0.627371 (stdev 0.483310), 0:00:00.046875, 2214
B: 738, 1, 0, 0, False, 1.000000, 372, 0.504065 (stdev 0.499639), 0:00:00, 0
A: cycle: 738
average reward: 0.627371 (stdev 0.483310)
B: cycle: 738
average reward: 0.504065 (stdev 0.499639)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 739, 0, 1, 1, False, 1.000000, 464, 0.627876 (stdev 0.483177), 0:00:00.046887, 2217
B: 739, 0, 1, 1, False, 1.000000, 373, 0.504736 (stdev 0.499645), 0:00:00, 0
A: cycle: 739
average reward: 0.627876 (stdev 0.483177)
B: cycle: 739
average reward: 0.504736 (stdev 0.499645)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 740, 1, 1, 0, False, 1.000000, 465, 0.628378 (stdev 0.483045), 0:00:00.031250, 2220
B: 740, 1, 1, 0, False, 1.000000, 374, 0.505405 (stdev 0.499640), 0:00:00, 0
A: cycle: 740
average reward: 0.628378 (stdev 0.483045)
B: cycle: 740
average reward: 0.505405 (stdev 0.499640)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 741, 0, 1, 0, False, 1.000000, 466, 0.628880 (stdev 0.482912), 0:00:00.046863, 2223
B: 741, 0, 1, 1, False, 1.000000, 375, 0.506073 (stdev 0.499633), 0:00:00, 0
A: cycle: 741
average reward: 0.628880 (stdev 0.482912)
B: cycle: 741
average reward: 0.506073 (stdev 0.499633)
A: action = low, observation = high, reward = wrong (0)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 742, 1, 0, 0, False, 1.000000, 466, 0.628032 (stdev 0.482779), 0:00:00.046875, 2226
B: 742, 1, 1, 1, False, 1.000000, 376, 0.506739 (stdev 0.499626), 0:00:00, 0
A: cycle: 742
average reward: 0.628032 (stdev 0.482779)
B: cycle: 742
average reward: 0.506739 (stdev 0.499626)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 743, 0, 1, 1, False, 1.000000, 467, 0.628533 (stdev 0.483004), 0:00:00.046874, 2229
B: 743, 0, 0, 0, False, 1.000000, 376, 0.506057 (stdev 0.499618), 0:00:00, 0
A: cycle: 743
average reward: 0.628533 (stdev 0.483004)
B: cycle: 743
average reward: 0.506057 (stdev 0.499618)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 744, 1, 1, 0, False, 1.000000, 468, 0.629032 (stdev 0.482872), 0:00:00.046875, 2232
B: 744, 1, 0, 0, False, 1.000000, 376, 0.505376 (stdev 0.499627), 0:00:00, 0
A: cycle: 744
average reward: 0.629032 (stdev 0.482872)
B: cycle: 744
average reward: 0.505376 (stdev 0.499627)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 745, 0, 1, 1, False, 1.000000, 469, 0.629530 (stdev 0.482740), 0:00:00.046875, 2235
B: 745, 0, 1, 1, False, 1.000000, 377, 0.506040 (stdev 0.499635), 0:00:00, 0
A: cycle: 745
average reward: 0.629530 (stdev 0.482740)
B: cycle: 745
average reward: 0.506040 (stdev 0.499635)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 746, 1, 1, 0, False, 1.000000, 470, 0.630027 (stdev 0.482607), 0:00:00.046875, 2238
B: 746, 1, 1, 0, False, 1.000000, 378, 0.506702 (stdev 0.499628), 0:00:00, 0
A: cycle: 746
average reward: 0.630027 (stdev 0.482607)
B: cycle: 746
average reward: 0.506702 (stdev 0.499628)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 747, 0, 1, 1, False, 1.000000, 471, 0.630522 (stdev 0.482474), 0:00:00.031250, 2241
B: 747, 0, 1, 0, False, 1.000000, 379, 0.507363 (stdev 0.499620), 0:00:00, 0
A: cycle: 747
average reward: 0.630522 (stdev 0.482474)
B: cycle: 747
average reward: 0.507363 (stdev 0.499620)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 748, 1, 1, 0, False, 1.000000, 472, 0.631016 (stdev 0.482341), 0:00:00.062516, 2244
B: 748, 1, 0, 0, False, 1.000000, 379, 0.506684 (stdev 0.499611), 0:00:00, 0
A: cycle: 748
average reward: 0.631016 (stdev 0.482341)
B: cycle: 748
average reward: 0.506684 (stdev 0.499611)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 749, 0, 1, 1, False, 1.000000, 473, 0.631509 (stdev 0.482207), 0:00:00.046858, 2247
B: 749, 0, 1, 1, False, 1.000000, 380, 0.507343 (stdev 0.499621), 0:00:00, 0
A: cycle: 749
average reward: 0.631509 (stdev 0.482207)
B: cycle: 749
average reward: 0.507343 (stdev 0.499621)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 750, 1, 1, 0, False, 1.000000, 474, 0.632000 (stdev 0.482074), 0:00:00.046887, 2250
B: 750, 1, 1, 0, False, 1.000000, 381, 0.508000 (stdev 0.499613), 0:00:00, 0
A: cycle: 750
average reward: 0.632000 (stdev 0.482074)
B: cycle: 750
average reward: 0.508000 (stdev 0.499613)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1



A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 751, 0, 1, 1, False, 1.000000, 475, 0.632490 (stdev 0.481940), 0:00:00.046863, 2253
B: 751, 0, 1, 0, False, 1.000000, 382, 0.508655 (stdev 0.499603), 0:00:00, 0
A: cycle: 751
average reward: 0.632490 (stdev 0.481940)
B: cycle: 751
average reward: 0.508655 (stdev 0.499603)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 752, 1, 1, 0, False, 1.000000, 476, 0.632979 (stdev 0.481806), 0:00:00.046875, 2256
B: 752, 1, 0, 0, False, 1.000000, 382, 0.507979 (stdev 0.499593), 0:00:00, 0
A: cycle: 752
average reward: 0.632979 (stdev 0.481806)
B: cycle: 752
average reward: 0.507979 (stdev 0.499593)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 753, 0, 1, 1, False, 1.000000, 477, 0.633466 (stdev 0.481672), 0:00:00.046893, 2259
B: 753, 0, 1, 1, False, 1.000000, 383, 0.508632 (stdev 0.499604), 0:00:00, 0
A: cycle: 753
average reward: 0.633466 (stdev 0.481672)
B: cycle: 753
average reward: 0.508632 (stdev 0.499604)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 754, 1, 1, 0, False, 1.000000, 478, 0.633952 (stdev 0.481538), 0:00:00.046857, 2262
B: 754, 1, 1, 1, False, 1.000000, 384, 0.509284 (stdev 0.499594), 0:00:00, 0
A: cycle: 754
average reward: 0.633952 (stdev 0.481538)
B: cycle: 754
average reward: 0.509284 (stdev 0.499594)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 755, 0, 1, 1, False, 1.000000, 479, 0.634437 (stdev 0.481404), 0:00:00.046874, 2265
B: 755, 0, 0, 0, False, 1.000000, 384, 0.508609 (stdev 0.499583), 0:00:00, 0
A: cycle: 755
average reward: 0.634437 (stdev 0.481404)
B: cycle: 755
average reward: 0.508609 (stdev 0.499583)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 756, 1, 1, 0, False, 1.000000, 480, 0.634921 (stdev 0.481269), 0:00:00.046876, 2268
B: 756, 1, 0, 0, False, 1.000000, 384, 0.507937 (stdev 0.499595), 0:00:00, 0
A: cycle: 756
average reward: 0.634921 (stdev 0.481269)
B: cycle: 756
average reward: 0.507937 (stdev 0.499595)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 757, 0, 1, 1, False, 1.000000, 481, 0.635403 (stdev 0.481134), 0:00:00.031266, 2271
B: 757, 0, 1, 1, False, 1.000000, 385, 0.508587 (stdev 0.499607), 0:00:00, 0
A: cycle: 757
average reward: 0.635403 (stdev 0.481134)
B: cycle: 757
average reward: 0.508587 (stdev 0.499607)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 758, 1, 1, 0, False, 1.000000, 482, 0.635884 (stdev 0.480999), 0:00:00.046875, 2274
B: 758, 1, 1, 0, False, 1.000000, 386, 0.509235 (stdev 0.499596), 0:00:00, 0
A: cycle: 758
average reward: 0.635884 (stdev 0.480999)
B: cycle: 758
average reward: 0.509235 (stdev 0.499596)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 759, 0, 1, 1, False, 1.000000, 483, 0.636364 (stdev 0.480864), 0:00:00.063147, 2277
B: 759, 0, 1, 1, False, 1.000000, 387, 0.509881 (stdev 0.499585), 0:00:00, 0
A: cycle: 759
average reward: 0.636364 (stdev 0.480864)
B: cycle: 759
average reward: 0.509881 (stdev 0.499585)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 760, 1, 1, 0, False, 1.000000, 484, 0.636842 (stdev 0.480729), 0:00:00.034320, 2280
B: 760, 1, 1, 1, False, 1.000000, 388, 0.510526 (stdev 0.499573), 0:00:00, 0
A: cycle: 760
average reward: 0.636842 (stdev 0.480729)
B: cycle: 760
average reward: 0.510526 (stdev 0.499573)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 761, 0, 1, 1, False, 1.000000, 485, 0.637319 (stdev 0.480594), 0:00:00.046874, 2283
B: 761, 0, 0, 0, False, 1.000000, 388, 0.509855 (stdev 0.499561), 0:00:00, 0
A: cycle: 761
average reward: 0.637319 (stdev 0.480594)
B: cycle: 761
average reward: 0.509855 (stdev 0.499561)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 762, 1, 1, 0, False, 1.000000, 486, 0.637795 (stdev 0.480458), 0:00:00.046875, 2286
B: 762, 1, 0, 1, False, 1.000000, 388, 0.509186 (stdev 0.499575), 0:00:00, 0
A: cycle: 762
average reward: 0.637795 (stdev 0.480458)
B: cycle: 762
average reward: 0.509186 (stdev 0.499575)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 763, 0, 1, 1, False, 1.000000, 487, 0.638270 (stdev 0.480322), 0:00:00.046874, 2289
B: 763, 0, 0, 1, False, 1.000000, 388, 0.508519 (stdev 0.499588), 0:00:00, 0
A: cycle: 763
average reward: 0.638270 (stdev 0.480322)
B: cycle: 763
average reward: 0.508519 (stdev 0.499588)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 764, 1, 1, 0, False, 1.000000, 488, 0.638743 (stdev 0.480187), 0:00:00.046887, 2292
B: 764, 1, 1, 1, False, 1.000000, 389, 0.509162 (stdev 0.499600), 0:00:00, 0
A: cycle: 764
average reward: 0.638743 (stdev 0.480187)
B: cycle: 764
average reward: 0.509162 (stdev 0.499600)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 765, 0, 1, 1, False, 1.000000, 489, 0.639216 (stdev 0.480051), 0:00:00.046875, 2295
B: 765, 0, 0, 1, False, 1.000000, 389, 0.508497 (stdev 0.499589), 0:00:00, 0
A: cycle: 765
average reward: 0.639216 (stdev 0.480051)
B: cycle: 765
average reward: 0.508497 (stdev 0.499589)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 766, 1, 1, 0, False, 1.000000, 490, 0.639687 (stdev 0.479914), 0:00:00.046863, 2298
B: 766, 1, 1, 1, False, 1.000000, 390, 0.509138 (stdev 0.499601), 0:00:00, 0
A: cycle: 766
average reward: 0.639687 (stdev 0.479914)
B: cycle: 766
average reward: 0.509138 (stdev 0.499601)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 767, 0, 1, 1, False, 1.000000, 491, 0.640156 (stdev 0.479778), 0:00:00.046887, 2301
B: 767, 0, 0, 1, False, 1.000000, 390, 0.508475 (stdev 0.499590), 0:00:00, 0
A: cycle: 767
average reward: 0.640156 (stdev 0.479778)
B: cycle: 767
average reward: 0.508475 (stdev 0.499590)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 768, 1, 1, 0, False, 1.000000, 492, 0.640625 (stdev 0.479642), 0:00:00.031249, 2304
B: 768, 1, 1, 0, False, 1.000000, 391, 0.509115 (stdev 0.499603), 0:00:00, 0
A: cycle: 768
average reward: 0.640625 (stdev 0.479642)
B: cycle: 768
average reward: 0.509115 (stdev 0.499603)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 769, 0, 1, 1, False, 1.000000, 493, 0.641092 (stdev 0.479505), 0:00:00.046875, 2307
B: 769, 0, 1, 1, False, 1.000000, 392, 0.509753 (stdev 0.499592), 0:00:00, 0
A: cycle: 769
average reward: 0.641092 (stdev 0.479505)
B: cycle: 769
average reward: 0.509753 (stdev 0.499592)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 770, 1, 1, 0, False, 1.000000, 494, 0.641558 (stdev 0.479368), 0:00:00.046863, 2310
B: 770, 1, 1, 0, False, 1.000000, 393, 0.510390 (stdev 0.499580), 0:00:00, 0
A: cycle: 770
average reward: 0.641558 (stdev 0.479368)
B: cycle: 770
average reward: 0.510390 (stdev 0.499580)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 771, 0, 1, 1, False, 1.000000, 495, 0.642023 (stdev 0.479232), 0:00:00.046886, 2313
B: 771, 0, 1, 0, False, 1.000000, 394, 0.511025 (stdev 0.499568), 0:00:00, 0
A: cycle: 771
average reward: 0.642023 (stdev 0.479232)
B: cycle: 771
average reward: 0.511025 (stdev 0.499568)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 772, 1, 1, 0, False, 1.000000, 496, 0.642487 (stdev 0.479095), 0:00:00.046876, 2316
B: 772, 1, 0, 1, False, 1.000000, 394, 0.510363 (stdev 0.499555), 0:00:00, 0
A: cycle: 772
average reward: 0.642487 (stdev 0.479095)
B: cycle: 772
average reward: 0.510363 (stdev 0.499555)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 773, 0, 1, 1, False, 1.000000, 497, 0.642950 (stdev 0.478958), 0:00:00.046864, 2319
B: 773, 0, 0, 1, False, 1.000000, 394, 0.509702 (stdev 0.499569), 0:00:00, 0
A: cycle: 773
average reward: 0.642950 (stdev 0.478958)
B: cycle: 773
average reward: 0.509702 (stdev 0.499569)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 774, 1, 1, 0, False, 1.000000, 498, 0.643411 (stdev 0.478820), 0:00:00.046885, 2322
B: 774, 1, 1, 1, False, 1.000000, 395, 0.510336 (stdev 0.499583), 0:00:00, 0
A: cycle: 774
average reward: 0.643411 (stdev 0.478820)
B: cycle: 774
average reward: 0.510336 (stdev 0.499583)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 775, 0, 1, 1, False, 1.000000, 499, 0.643871 (stdev 0.478683), 0:00:00.031250, 2325
B: 775, 0, 0, 0, False, 1.000000, 395, 0.509677 (stdev 0.499571), 0:00:00, 0
A: cycle: 775
average reward: 0.643871 (stdev 0.478683)
B: cycle: 775
average reward: 0.509677 (stdev 0.499571)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 776, 1, 1, 0, False, 1.000000, 500, 0.644330 (stdev 0.478545), 0:00:00.046874, 2328
B: 776, 1, 0, 1, False, 1.000000, 395, 0.509021 (stdev 0.499584), 0:00:00, 0
A: cycle: 776
average reward: 0.644330 (stdev 0.478545)
B: cycle: 776
average reward: 0.509021 (stdev 0.499584)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 777, 0, 1, 1, False, 1.000000, 501, 0.644788 (stdev 0.478408), 0:00:00.046865, 2331
B: 777, 0, 0, 0, False, 1.000000, 395, 0.508366 (stdev 0.499597), 0:00:00, 0
A: cycle: 777
average reward: 0.644788 (stdev 0.478408)
B: cycle: 777
average reward: 0.508366 (stdev 0.499597)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 778, 1, 1, 0, False, 1.000000, 502, 0.645244 (stdev 0.478270), 0:00:00.046874, 2334
B: 778, 1, 0, 1, False, 1.000000, 395, 0.507712 (stdev 0.499609), 0:00:00, 0
A: cycle: 778
average reward: 0.645244 (stdev 0.478270)
B: cycle: 778
average reward: 0.507712 (stdev 0.499609)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 779, 0, 1, 1, False, 1.000000, 503, 0.645700 (stdev 0.478132), 0:00:00.046886, 2337
B: 779, 0, 0, 0, False, 1.000000, 395, 0.507060 (stdev 0.499620), 0:00:00, 0
A: cycle: 779
average reward: 0.645700 (stdev 0.478132)
B: cycle: 779
average reward: 0.507060 (stdev 0.499620)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 780, 1, 1, 0, False, 1.000000, 504, 0.646154 (stdev 0.477994), 0:00:00.046863, 2340
B: 780, 1, 0, 1, False, 1.000000, 395, 0.506410 (stdev 0.499630), 0:00:00, 0
A: cycle: 780
average reward: 0.646154 (stdev 0.477994)
B: cycle: 780
average reward: 0.506410 (stdev 0.499630)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 781, 0, 1, 1, False, 1.000000, 505, 0.646607 (stdev 0.477856), 0:00:00.046887, 2343
B: 781, 0, 0, 0, False, 1.000000, 395, 0.505762 (stdev 0.499639), 0:00:00, 0
A: cycle: 781
average reward: 0.646607 (stdev 0.477856)
B: cycle: 781
average reward: 0.505762 (stdev 0.499639)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 782, 1, 1, 0, False, 1.000000, 506, 0.647059 (stdev 0.477718), 0:00:00.031250, 2346
B: 782, 1, 0, 1, False, 1.000000, 395, 0.505115 (stdev 0.499647), 0:00:00, 0
A: cycle: 782
average reward: 0.647059 (stdev 0.477718)
B: cycle: 782
average reward: 0.505115 (stdev 0.499647)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 783, 0, 1, 1, False, 1.000000, 507, 0.647510 (stdev 0.477579), 0:00:00.046863, 2349
B: 783, 0, 0, 1, False, 1.000000, 395, 0.504470 (stdev 0.499654), 0:00:00, 0
A: cycle: 783
average reward: 0.647510 (stdev 0.477579)
B: cycle: 783
average reward: 0.504470 (stdev 0.499654)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 784, 1, 1, 0, False, 1.000000, 508, 0.647959 (stdev 0.477441), 0:00:00.046887, 2352
B: 784, 1, 1, 0, False, 1.000000, 396, 0.505102 (stdev 0.499661), 0:00:00, 0
A: cycle: 784
average reward: 0.647959 (stdev 0.477441)
B: cycle: 784
average reward: 0.505102 (stdev 0.499661)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 785, 0, 1, 1, False, 1.000000, 509, 0.648408 (stdev 0.477302), 0:00:00.046875, 2355
B: 785, 0, 1, 1, False, 1.000000, 397, 0.505732 (stdev 0.499655), 0:00:00, 0
A: cycle: 785
average reward: 0.648408 (stdev 0.477302)
B: cycle: 785
average reward: 0.505732 (stdev 0.499655)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 786, 1, 1, 0, False, 1.000000, 510, 0.648855 (stdev 0.477164), 0:00:00.046874, 2358
B: 786, 1, 1, 0, False, 1.000000, 398, 0.506361 (stdev 0.499649), 0:00:00, 0
A: cycle: 786
average reward: 0.648855 (stdev 0.477164)
B: cycle: 786
average reward: 0.506361 (stdev 0.499649)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 787, 0, 1, 1, False, 1.000000, 511, 0.649301 (stdev 0.477025), 0:00:00.046863, 2361
B: 787, 0, 1, 1, False, 1.000000, 399, 0.506989 (stdev 0.499642), 0:00:00, 0
A: cycle: 787
average reward: 0.649301 (stdev 0.477025)
B: cycle: 787
average reward: 0.506989 (stdev 0.499642)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 788, 1, 1, 0, False, 1.000000, 512, 0.649746 (stdev 0.476886), 0:00:00.046892, 2364
B: 788, 1, 1, 1, False, 1.000000, 400, 0.507614 (stdev 0.499634), 0:00:00, 0
A: cycle: 788
average reward: 0.649746 (stdev 0.476886)
B: cycle: 788
average reward: 0.507614 (stdev 0.499634)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 789, 0, 1, 1, False, 1.000000, 513, 0.650190 (stdev 0.476747), 0:00:00.031233, 2367
B: 789, 0, 0, 1, False, 1.000000, 400, 0.506971 (stdev 0.499625), 0:00:00, 0
A: cycle: 789
average reward: 0.650190 (stdev 0.476747)
B: cycle: 789
average reward: 0.506971 (stdev 0.499625)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 790, 1, 1, 0, False, 1.000000, 514, 0.650633 (stdev 0.476608), 0:00:00.046887, 2370
B: 790, 1, 1, 1, False, 1.000000, 401, 0.507595 (stdev 0.499635), 0:00:00, 0
A: cycle: 790
average reward: 0.650633 (stdev 0.476608)
B: cycle: 790
average reward: 0.507595 (stdev 0.499635)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 791, 0, 1, 1, False, 1.000000, 515, 0.651075 (stdev 0.476469), 0:00:00.046874, 2373
B: 791, 0, 0, 1, False, 1.000000, 401, 0.506953 (stdev 0.499626), 0:00:00, 0
A: cycle: 791
average reward: 0.651075 (stdev 0.476469)
B: cycle: 791
average reward: 0.506953 (stdev 0.499626)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 792, 1, 1, 0, False, 1.000000, 516, 0.651515 (stdev 0.476329), 0:00:00.062489, 2376
B: 792, 1, 1, 0, False, 1.000000, 402, 0.507576 (stdev 0.499636), 0:00:00, 0
A: cycle: 792
average reward: 0.651515 (stdev 0.476329)
B: cycle: 792
average reward: 0.507576 (stdev 0.499636)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 793, 0, 1, 1, False, 1.000000, 517, 0.651955 (stdev 0.476190), 0:00:00.046875, 2379
B: 793, 0, 1, 0, False, 1.000000, 403, 0.508197 (stdev 0.499627), 0:00:00, 0
A: cycle: 793
average reward: 0.651955 (stdev 0.476190)
B: cycle: 793
average reward: 0.508197 (stdev 0.499627)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 794, 1, 1, 0, False, 1.000000, 518, 0.652393 (stdev 0.476050), 0:00:00.031249, 2382
B: 794, 1, 0, 0, False, 1.000000, 403, 0.507557 (stdev 0.499618), 0:00:00, 0
A: cycle: 794
average reward: 0.652393 (stdev 0.476050)
B: cycle: 794
average reward: 0.507557 (stdev 0.499618)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 795, 0, 1, 1, False, 1.000000, 519, 0.652830 (stdev 0.475911), 0:00:00.046887, 2385
B: 795, 0, 1, 1, False, 1.000000, 404, 0.508176 (stdev 0.499628), 0:00:00, 0
A: cycle: 795
average reward: 0.652830 (stdev 0.475911)
B: cycle: 795
average reward: 0.508176 (stdev 0.499628)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 796, 1, 1, 1, False, 1.000000, 520, 0.653266 (stdev 0.475771), 0:00:00.046862, 2388
B: 796, 1, 1, 0, False, 1.000000, 405, 0.508794 (stdev 0.499619), 0:00:00, 0
A: cycle: 796
average reward: 0.653266 (stdev 0.475771)
B: cycle: 796
average reward: 0.508794 (stdev 0.499619)
A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 797, 0, 0, 1, False, 1.000000, 520, 0.652447 (stdev 0.475631), 0:00:00.046887, 2391
B: 797, 0, 1, 1, False, 1.000000, 406, 0.509410 (stdev 0.499609), 0:00:00, 0
A: cycle: 797
average reward: 0.652447 (stdev 0.475631)
B: cycle: 797
average reward: 0.509410 (stdev 0.499609)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 798, 1, 1, 0, False, 1.000000, 521, 0.652882 (stdev 0.475895), 0:00:00.046863, 2394
B: 798, 1, 1, 1, False, 1.000000, 407, 0.510025 (stdev 0.499598), 0:00:00, 0
A: cycle: 798
average reward: 0.652882 (stdev 0.475895)
B: cycle: 798
average reward: 0.510025 (stdev 0.499598)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 799, 0, 1, 1, False, 1.000000, 522, 0.653317 (stdev 0.475756), 0:00:00.046887, 2397
B: 799, 0, 0, 1, False, 1.000000, 407, 0.509387 (stdev 0.499587), 0:00:00, 0
A: cycle: 799
average reward: 0.653317 (stdev 0.475756)
B: cycle: 799
average reward: 0.509387 (stdev 0.499587)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 800, 1, 1, 0, False, 1.000000, 523, 0.653750 (stdev 0.475616), 0:00:00.046863, 2400
B: 800, 1, 1, 0, False, 1.000000, 408, 0.510000 (stdev 0.499599), 0:00:00, 0
A: cycle: 800
average reward: 0.653750 (stdev 0.475616)
B: cycle: 800
average reward: 0.510000 (stdev 0.499599)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1



A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 801, 0, 1, 1, False, 1.000000, 524, 0.654182 (stdev 0.475477), 0:00:00.042118, 2403
B: 801, 0, 1, 0, False, 1.000000, 409, 0.510612 (stdev 0.499588), 0:00:00, 0
A: cycle: 801
average reward: 0.654182 (stdev 0.475477)
B: cycle: 801
average reward: 0.510612 (stdev 0.499588)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 802, 1, 1, 0, False, 1.000000, 525, 0.654613 (stdev 0.475338), 0:00:00.046876, 2406
B: 802, 1, 0, 0, False, 1.000000, 409, 0.509975 (stdev 0.499576), 0:00:00, 0
A: cycle: 802
average reward: 0.654613 (stdev 0.475338)
B: cycle: 802
average reward: 0.509975 (stdev 0.499576)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 803, 0, 1, 1, False, 1.000000, 526, 0.655044 (stdev 0.475198), 0:00:00.046874, 2409
B: 803, 0, 1, 0, False, 1.000000, 410, 0.510585 (stdev 0.499589), 0:00:00, 0
A: cycle: 803
average reward: 0.655044 (stdev 0.475198)
B: cycle: 803
average reward: 0.510585 (stdev 0.499589)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 804, 1, 1, 0, False, 1.000000, 527, 0.655473 (stdev 0.475058), 0:00:00.046875, 2412
B: 804, 1, 0, 1, False, 1.000000, 410, 0.509950 (stdev 0.499577), 0:00:00, 0
A: cycle: 804
average reward: 0.655473 (stdev 0.475058)
B: cycle: 804
average reward: 0.509950 (stdev 0.499577)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 805, 0, 1, 1, False, 1.000000, 528, 0.655901 (stdev 0.474919), 0:00:00.046875, 2415
B: 805, 0, 0, 0, False, 1.000000, 410, 0.509317 (stdev 0.499590), 0:00:00, 0
A: cycle: 805
average reward: 0.655901 (stdev 0.474919)
B: cycle: 805
average reward: 0.509317 (stdev 0.499590)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 806, 1, 1, 0, False, 1.000000, 529, 0.656328 (stdev 0.474779), 0:00:00.046875, 2418
B: 806, 1, 0, 1, False, 1.000000, 410, 0.508685 (stdev 0.499603), 0:00:00, 0
A: cycle: 806
average reward: 0.656328 (stdev 0.474779)
B: cycle: 806
average reward: 0.508685 (stdev 0.499603)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 807, 0, 1, 1, False, 1.000000, 530, 0.656753 (stdev 0.474639), 0:00:00.046875, 2421
B: 807, 0, 0, 0, False, 1.000000, 410, 0.508055 (stdev 0.499615), 0:00:00, 0
A: cycle: 807
average reward: 0.656753 (stdev 0.474639)
B: cycle: 807
average reward: 0.508055 (stdev 0.499615)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 808, 1, 1, 1, False, 1.000000, 531, 0.657178 (stdev 0.474499), 0:00:00.046874, 2424
B: 808, 1, 0, 1, False, 1.000000, 410, 0.507426 (stdev 0.499626), 0:00:00, 0
A: cycle: 808
average reward: 0.657178 (stdev 0.474499)
B: cycle: 808
average reward: 0.507426 (stdev 0.499626)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 809, 0, 0, 1, False, 1.000000, 531, 0.656366 (stdev 0.474359), 0:00:00.046876, 2427
B: 809, 0, 0, 1, False, 1.000000, 410, 0.506799 (stdev 0.499636), 0:00:00, 0
A: cycle: 809
average reward: 0.656366 (stdev 0.474359)
B: cycle: 809
average reward: 0.506799 (stdev 0.499636)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 810, 1, 1, 0, False, 1.000000, 532, 0.656790 (stdev 0.474627), 0:00:00.046874, 2430
B: 810, 1, 1, 1, False, 1.000000, 411, 0.507407 (stdev 0.499645), 0:00:00, 0
A: cycle: 810
average reward: 0.656790 (stdev 0.474627)
B: cycle: 810
average reward: 0.507407 (stdev 0.499645)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 811, 0, 1, 1, False, 1.000000, 533, 0.657213 (stdev 0.474488), 0:00:00.046875, 2433
B: 811, 0, 0, 1, False, 1.000000, 411, 0.506782 (stdev 0.499637), 0:00:00, 0
A: cycle: 811
average reward: 0.657213 (stdev 0.474488)
B: cycle: 811
average reward: 0.506782 (stdev 0.499637)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 812, 1, 1, 0, False, 1.000000, 534, 0.657635 (stdev 0.474349), 0:00:00.046875, 2436
B: 812, 1, 1, 0, False, 1.000000, 412, 0.507389 (stdev 0.499646), 0:00:00, 0
A: cycle: 812
average reward: 0.657635 (stdev 0.474349)
B: cycle: 812
average reward: 0.507389 (stdev 0.499646)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 813, 0, 1, 1, False, 1.000000, 535, 0.658057 (stdev 0.474209), 0:00:00.031265, 2439
B: 813, 0, 1, 0, False, 1.000000, 413, 0.507995 (stdev 0.499638), 0:00:00, 0
A: cycle: 813
average reward: 0.658057 (stdev 0.474209)
B: cycle: 813
average reward: 0.507995 (stdev 0.499638)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 814, 1, 1, 0, False, 1.000000, 536, 0.658477 (stdev 0.474069), 0:00:00.055111, 2442
B: 814, 1, 0, 1, False, 1.000000, 413, 0.507371 (stdev 0.499629), 0:00:00, 0
A: cycle: 814
average reward: 0.658477 (stdev 0.474069)
B: cycle: 814
average reward: 0.507371 (stdev 0.499629)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 815, 0, 1, 1, False, 1.000000, 537, 0.658896 (stdev 0.473930), 0:00:00.046859, 2445
B: 815, 0, 0, 1, False, 1.000000, 413, 0.506748 (stdev 0.499639), 0:00:00, 0
A: cycle: 815
average reward: 0.658896 (stdev 0.473930)
B: cycle: 815
average reward: 0.506748 (stdev 0.499639)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 816, 1, 1, 1, False, 1.000000, 538, 0.659314 (stdev 0.473790), 0:00:00.031266, 2448
B: 816, 1, 1, 1, False, 1.000000, 414, 0.507353 (stdev 0.499648), 0:00:00, 0
A: cycle: 816
average reward: 0.659314 (stdev 0.473790)
B: cycle: 816
average reward: 0.507353 (stdev 0.499648)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 817, 0, 0, 1, False, 1.000000, 538, 0.658507 (stdev 0.473650), 0:00:00.046874, 2451
B: 817, 0, 0, 0, False, 1.000000, 414, 0.506732 (stdev 0.499640), 0:00:00, 0
A: cycle: 817
average reward: 0.658507 (stdev 0.473650)
B: cycle: 817
average reward: 0.506732 (stdev 0.499640)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 818, 1, 1, 0, False, 1.000000, 539, 0.658924 (stdev 0.473921), 0:00:00.140620, 2454
B: 818, 1, 0, 0, False, 1.000000, 414, 0.506112 (stdev 0.499649), 0:00:00, 0
A: cycle: 818
average reward: 0.658924 (stdev 0.473921)
B: cycle: 818
average reward: 0.506112 (stdev 0.499649)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 819, 0, 1, 1, False, 1.000000, 540, 0.659341 (stdev 0.473781), 0:00:00.046863, 2457
B: 819, 0, 1, 1, False, 1.000000, 415, 0.506716 (stdev 0.499657), 0:00:00, 0
A: cycle: 819
average reward: 0.659341 (stdev 0.473781)
B: cycle: 819
average reward: 0.506716 (stdev 0.499657)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 820, 1, 1, 0, False, 1.000000, 541, 0.659756 (stdev 0.473642), 0:00:00.046887, 2460
B: 820, 1, 1, 0, False, 1.000000, 416, 0.507317 (stdev 0.499650), 0:00:00, 0
A: cycle: 820
average reward: 0.659756 (stdev 0.473642)
B: cycle: 820
average reward: 0.507317 (stdev 0.499650)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 821, 0, 1, 1, False, 1.000000, 542, 0.660171 (stdev 0.473502), 0:00:00.046875, 2463
B: 821, 0, 1, 0, False, 1.000000, 417, 0.507917 (stdev 0.499642), 0:00:00, 0
A: cycle: 821
average reward: 0.660171 (stdev 0.473502)
B: cycle: 821
average reward: 0.507917 (stdev 0.499642)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 822, 1, 1, 0, False, 1.000000, 543, 0.660584 (stdev 0.473363), 0:00:00.046874, 2466
B: 822, 1, 0, 1, False, 1.000000, 417, 0.507299 (stdev 0.499633), 0:00:00, 0
A: cycle: 822
average reward: 0.660584 (stdev 0.473363)
B: cycle: 822
average reward: 0.507299 (stdev 0.499633)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 823, 0, 1, 1, False, 1.000000, 544, 0.660996 (stdev 0.473223), 0:00:00.031250, 2469
B: 823, 0, 0, 1, False, 1.000000, 417, 0.506683 (stdev 0.499643), 0:00:00, 0
A: cycle: 823
average reward: 0.660996 (stdev 0.473223)
B: cycle: 823
average reward: 0.506683 (stdev 0.499643)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 824, 1, 1, 0, False, 1.000000, 545, 0.661408 (stdev 0.473084), 0:00:00.046863, 2472
B: 824, 1, 1, 1, False, 1.000000, 418, 0.507282 (stdev 0.499652), 0:00:00, 0
A: cycle: 824
average reward: 0.661408 (stdev 0.473084)
B: cycle: 824
average reward: 0.507282 (stdev 0.499652)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 825, 0, 1, 1, False, 1.000000, 546, 0.661818 (stdev 0.472944), 0:00:00.046876, 2475
B: 825, 0, 0, 0, False, 1.000000, 418, 0.506667 (stdev 0.499644), 0:00:00, 0
A: cycle: 825
average reward: 0.661818 (stdev 0.472944)
B: cycle: 825
average reward: 0.506667 (stdev 0.499644)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 826, 1, 1, 0, False, 1.000000, 547, 0.662228 (stdev 0.472804), 0:00:00.046886, 2478
B: 826, 1, 0, 0, False, 1.000000, 418, 0.506053 (stdev 0.499653), 0:00:00, 0
A: cycle: 826
average reward: 0.662228 (stdev 0.472804)
B: cycle: 826
average reward: 0.506053 (stdev 0.499653)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 827, 0, 1, 1, False, 1.000000, 548, 0.662636 (stdev 0.472665), 0:00:00.046863, 2481
B: 827, 0, 1, 1, False, 1.000000, 419, 0.506651 (stdev 0.499661), 0:00:00, 0
A: cycle: 827
average reward: 0.662636 (stdev 0.472665)
B: cycle: 827
average reward: 0.506651 (stdev 0.499661)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 828, 1, 1, 0, False, 1.000000, 549, 0.663043 (stdev 0.472525), 0:00:00.046886, 2484
B: 828, 1, 1, 0, False, 1.000000, 420, 0.507246 (stdev 0.499654), 0:00:00, 0
A: cycle: 828
average reward: 0.663043 (stdev 0.472525)
B: cycle: 828
average reward: 0.507246 (stdev 0.499654)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 829, 0, 1, 1, False, 1.000000, 550, 0.663450 (stdev 0.472385), 0:00:00.046875, 2487
B: 829, 0, 1, 0, False, 1.000000, 421, 0.507841 (stdev 0.499646), 0:00:00, 0
A: cycle: 829
average reward: 0.663450 (stdev 0.472385)
B: cycle: 829
average reward: 0.507841 (stdev 0.499646)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 830, 1, 1, 0, False, 1.000000, 551, 0.663855 (stdev 0.472245), 0:00:00.031255, 2490
B: 830, 1, 0, 0, False, 1.000000, 421, 0.507229 (stdev 0.499637), 0:00:00, 0
A: cycle: 830
average reward: 0.663855 (stdev 0.472245)
B: cycle: 830
average reward: 0.507229 (stdev 0.499637)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 831, 0, 1, 1, False, 1.000000, 552, 0.664260 (stdev 0.472105), 0:00:00.046870, 2493
B: 831, 0, 1, 0, False, 1.000000, 422, 0.507822 (stdev 0.499647), 0:00:00, 0
A: cycle: 831
average reward: 0.664260 (stdev 0.472105)
B: cycle: 831
average reward: 0.507822 (stdev 0.499647)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 832, 1, 1, 0, False, 1.000000, 553, 0.664663 (stdev 0.471965), 0:00:00.046880, 2496
B: 832, 1, 0, 1, False, 1.000000, 422, 0.507212 (stdev 0.499638), 0:00:00, 0
A: cycle: 832
average reward: 0.664663 (stdev 0.471965)
B: cycle: 832
average reward: 0.507212 (stdev 0.499638)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 833, 0, 1, 1, False, 1.000000, 554, 0.665066 (stdev 0.471825), 0:00:00.046874, 2499
B: 833, 0, 0, 1, False, 1.000000, 422, 0.506603 (stdev 0.499648), 0:00:00, 0
A: cycle: 833
average reward: 0.665066 (stdev 0.471825)
B: cycle: 833
average reward: 0.506603 (stdev 0.499648)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 834, 1, 1, 0, False, 1.000000, 555, 0.665468 (stdev 0.471684), 0:00:00.046874, 2502
B: 834, 1, 1, 0, False, 1.000000, 423, 0.507194 (stdev 0.499657), 0:00:00, 0
A: cycle: 834
average reward: 0.665468 (stdev 0.471684)
B: cycle: 834
average reward: 0.507194 (stdev 0.499657)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 835, 0, 1, 1, False, 1.000000, 556, 0.665868 (stdev 0.471544), 0:00:00.046860, 2505
B: 835, 0, 1, 1, False, 1.000000, 424, 0.507784 (stdev 0.499649), 0:00:00, 0
A: cycle: 835
average reward: 0.665868 (stdev 0.471544)
B: cycle: 835
average reward: 0.507784 (stdev 0.499649)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 836, 1, 1, 0, False, 1.000000, 557, 0.666268 (stdev 0.471404), 0:00:00.046874, 2508
B: 836, 1, 1, 0, False, 1.000000, 425, 0.508373 (stdev 0.499640), 0:00:00, 0
A: cycle: 836
average reward: 0.666268 (stdev 0.471404)
B: cycle: 836
average reward: 0.508373 (stdev 0.499640)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 837, 0, 1, 1, False, 1.000000, 558, 0.666667 (stdev 0.471264), 0:00:00.046875, 2511
B: 837, 0, 1, 1, False, 1.000000, 426, 0.508961 (stdev 0.499631), 0:00:00, 0
A: cycle: 837
average reward: 0.666667 (stdev 0.471264)
B: cycle: 837
average reward: 0.508961 (stdev 0.499631)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 838, 1, 1, 0, False, 1.000000, 559, 0.667064 (stdev 0.471123), 0:00:00.046875, 2514
B: 838, 1, 1, 0, False, 1.000000, 427, 0.509547 (stdev 0.499621), 0:00:00, 0
A: cycle: 838
average reward: 0.667064 (stdev 0.471123)
B: cycle: 838
average reward: 0.509547 (stdev 0.499621)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 839, 0, 1, 1, False, 1.000000, 560, 0.667461 (stdev 0.470983), 0:00:00.046875, 2517
B: 839, 0, 1, 0, False, 1.000000, 428, 0.510131 (stdev 0.499611), 0:00:00, 0
A: cycle: 839
average reward: 0.667461 (stdev 0.470983)
B: cycle: 839
average reward: 0.510131 (stdev 0.499611)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 840, 1, 1, 0, False, 1.000000, 561, 0.667857 (stdev 0.470842), 0:00:00.046875, 2520
B: 840, 1, 0, 1, False, 1.000000, 428, 0.509524 (stdev 0.499600), 0:00:00, 0
A: cycle: 840
average reward: 0.667857 (stdev 0.470842)
B: cycle: 840
average reward: 0.509524 (stdev 0.499600)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 841, 0, 1, 1, False, 1.000000, 562, 0.668252 (stdev 0.470702), 0:00:00.046875, 2523
B: 841, 0, 0, 1, False, 1.000000, 428, 0.508918 (stdev 0.499612), 0:00:00, 0
A: cycle: 841
average reward: 0.668252 (stdev 0.470702)
B: cycle: 841
average reward: 0.508918 (stdev 0.499612)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 842, 1, 1, 0, False, 1.000000, 563, 0.668646 (stdev 0.470561), 0:00:00.046874, 2526
B: 842, 1, 1, 0, False, 1.000000, 429, 0.509501 (stdev 0.499624), 0:00:00, 0
A: cycle: 842
average reward: 0.668646 (stdev 0.470561)
B: cycle: 842
average reward: 0.509501 (stdev 0.499624)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 843, 0, 1, 1, False, 1.000000, 564, 0.669039 (stdev 0.470421), 0:00:00.046892, 2529
B: 843, 0, 1, 1, False, 1.000000, 430, 0.510083 (stdev 0.499613), 0:00:00, 0
A: cycle: 843
average reward: 0.669039 (stdev 0.470421)
B: cycle: 843
average reward: 0.510083 (stdev 0.499613)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 844, 1, 1, 1, False, 1.000000, 565, 0.669431 (stdev 0.470280), 0:00:00.046869, 2532
B: 844, 1, 1, 1, False, 1.000000, 431, 0.510664 (stdev 0.499602), 0:00:00, 0
A: cycle: 844
average reward: 0.669431 (stdev 0.470280)
B: cycle: 844
average reward: 0.510664 (stdev 0.499602)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 845, 0, 0, 1, False, 1.000000, 565, 0.668639 (stdev 0.470140), 0:00:00.046864, 2535
B: 845, 0, 0, 1, False, 1.000000, 431, 0.510059 (stdev 0.499590), 0:00:00, 0
A: cycle: 845
average reward: 0.668639 (stdev 0.470140)
B: cycle: 845
average reward: 0.510059 (stdev 0.499590)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 846, 1, 1, 0, False, 1.000000, 566, 0.669031 (stdev 0.470424), 0:00:00.046886, 2538
B: 846, 1, 1, 1, False, 1.000000, 432, 0.510638 (stdev 0.499603), 0:00:00, 0
A: cycle: 846
average reward: 0.669031 (stdev 0.470424)
B: cycle: 846
average reward: 0.510638 (stdev 0.499603)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 847, 0, 1, 1, False, 1.000000, 567, 0.669421 (stdev 0.470284), 0:00:00.031238, 2541
B: 847, 0, 0, 0, False, 1.000000, 432, 0.510035 (stdev 0.499592), 0:00:00, 0
A: cycle: 847
average reward: 0.669421 (stdev 0.470284)
B: cycle: 847
average reward: 0.510035 (stdev 0.499592)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 848, 1, 1, 0, False, 1.000000, 568, 0.669811 (stdev 0.470144), 0:00:00.046875, 2544
B: 848, 1, 0, 1, False, 1.000000, 432, 0.509434 (stdev 0.499604), 0:00:00, 0
A: cycle: 848
average reward: 0.669811 (stdev 0.470144)
B: cycle: 848
average reward: 0.509434 (stdev 0.499604)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 849, 0, 1, 1, False, 1.000000, 569, 0.670200 (stdev 0.470004), 0:00:00.046887, 2547
B: 849, 0, 0, 0, False, 1.000000, 432, 0.508834 (stdev 0.499616), 0:00:00, 0
A: cycle: 849
average reward: 0.670200 (stdev 0.470004)
B: cycle: 849
average reward: 0.508834 (stdev 0.499616)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 850, 1, 1, 0, False, 1.000000, 570, 0.670588 (stdev 0.469864), 0:00:00.046874, 2550
B: 850, 1, 0, 1, False, 1.000000, 432, 0.508235 (stdev 0.499628), 0:00:00, 0
A: cycle: 850
average reward: 0.670588 (stdev 0.469864)
B: cycle: 850
average reward: 0.508235 (stdev 0.499628)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1
1
0
1
0
0
0
0
0
0
1
0
1
1
0
0
1
0
0
1
1
1
0
0
1
0
0
1
1
1
0
1
0
0
1
1
1
1
1
1
0
0
1
1
1
0
1
0
0
0
0



A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 851, 0, 1, 1, False, 1.000000, 571, 0.670975 (stdev 0.469723), 0:00:00.046864, 2553
B: 851, 0, 0, 0, False, 1.000000, 432, 0.507638 (stdev 0.499638), 0:00:00, 0
A: cycle: 851
average reward: 0.670975 (stdev 0.469723)
B: cycle: 851
average reward: 0.507638 (stdev 0.499638)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 852, 1, 1, 0, False, 1.000000, 572, 0.671362 (stdev 0.469583), 0:00:00.046875, 2556
B: 852, 1, 0, 1, False, 1.000000, 432, 0.507042 (stdev 0.499648), 0:00:00, 0
A: cycle: 852
average reward: 0.671362 (stdev 0.469583)
B: cycle: 852
average reward: 0.507042 (stdev 0.499648)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 853, 0, 1, 1, False, 1.000000, 573, 0.671747 (stdev 0.469443), 0:00:00.046875, 2559
B: 853, 0, 0, 0, False, 1.000000, 432, 0.506448 (stdev 0.499657), 0:00:00, 0
A: cycle: 853
average reward: 0.671747 (stdev 0.469443)
B: cycle: 853
average reward: 0.506448 (stdev 0.499657)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 854, 1, 1, 0, False, 1.000000, 574, 0.672131 (stdev 0.469303), 0:00:00.046875, 2562
B: 854, 1, 0, 1, False, 1.000000, 432, 0.505855 (stdev 0.499666), 0:00:00, 0
A: cycle: 854
average reward: 0.672131 (stdev 0.469303)
B: cycle: 854
average reward: 0.505855 (stdev 0.499666)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 855, 0, 1, 1, False, 1.000000, 575, 0.672515 (stdev 0.469162), 0:00:00.046891, 2565
B: 855, 0, 0, 0, False, 1.000000, 432, 0.505263 (stdev 0.499673), 0:00:00, 0
A: cycle: 855
average reward: 0.672515 (stdev 0.469162)
B: cycle: 855
average reward: 0.505263 (stdev 0.499673)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 856, 1, 1, 0, False, 1.000000, 576, 0.672897 (stdev 0.469022), 0:00:00.046858, 2568
B: 856, 1, 0, 0, False, 1.000000, 432, 0.504673 (stdev 0.499680), 0:00:00, 0
A: cycle: 856
average reward: 0.672897 (stdev 0.469022)
B: cycle: 856
average reward: 0.504673 (stdev 0.499680)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 857, 0, 1, 1, False, 1.000000, 577, 0.673279 (stdev 0.468881), 0:00:00.046892, 2571
B: 857, 0, 1, 0, False, 1.000000, 433, 0.505251 (stdev 0.499686), 0:00:00, 0
A: cycle: 857
average reward: 0.673279 (stdev 0.468881)
B: cycle: 857
average reward: 0.505251 (stdev 0.499686)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 858, 1, 1, 0, False, 1.000000, 578, 0.673660 (stdev 0.468741), 0:00:00.046874, 2574
B: 858, 1, 0, 1, False, 1.000000, 433, 0.504662 (stdev 0.499681), 0:00:00, 0
A: cycle: 858
average reward: 0.673660 (stdev 0.468741)
B: cycle: 858
average reward: 0.504662 (stdev 0.499681)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 859, 0, 1, 1, False, 1.000000, 579, 0.674040 (stdev 0.468600), 0:00:00.046876, 2577
B: 859, 0, 0, 1, False, 1.000000, 433, 0.504075 (stdev 0.499687), 0:00:00, 0
A: cycle: 859
average reward: 0.674040 (stdev 0.468600)
B: cycle: 859
average reward: 0.504075 (stdev 0.499687)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 860, 1, 1, 0, False, 1.000000, 580, 0.674419 (stdev 0.468460), 0:00:00.046874, 2580
B: 860, 1, 1, 1, False, 1.000000, 434, 0.504651 (stdev 0.499693), 0:00:00, 0
A: cycle: 860
average reward: 0.674419 (stdev 0.468460)
B: cycle: 860
average reward: 0.504651 (stdev 0.499693)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 861, 0, 1, 1, False, 1.000000, 581, 0.674797 (stdev 0.468319), 0:00:00.046858, 2583
B: 861, 0, 0, 1, False, 1.000000, 434, 0.504065 (stdev 0.499688), 0:00:00, 0
A: cycle: 861
average reward: 0.674797 (stdev 0.468319)
B: cycle: 861
average reward: 0.504065 (stdev 0.499688)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 862, 1, 1, 0, False, 1.000000, 582, 0.675174 (stdev 0.468179), 0:00:00.046874, 2586
B: 862, 1, 1, 0, False, 1.000000, 435, 0.504640 (stdev 0.499693), 0:00:00, 0
A: cycle: 862
average reward: 0.675174 (stdev 0.468179)
B: cycle: 862
average reward: 0.504640 (stdev 0.499693)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 863, 0, 1, 1, False, 1.000000, 583, 0.675550 (stdev 0.468038), 0:00:00.046892, 2589
B: 863, 0, 1, 1, False, 1.000000, 436, 0.505214 (stdev 0.499689), 0:00:00, 0
A: cycle: 863
average reward: 0.675550 (stdev 0.468038)
B: cycle: 863
average reward: 0.505214 (stdev 0.499689)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 864, 1, 1, 0, False, 1.000000, 584, 0.675926 (stdev 0.467898), 0:00:00.046858, 2592
B: 864, 1, 1, 0, False, 1.000000, 437, 0.505787 (stdev 0.499683), 0:00:00, 0
A: cycle: 864
average reward: 0.675926 (stdev 0.467898)
B: cycle: 864
average reward: 0.505787 (stdev 0.499683)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 865, 0, 1, 1, False, 1.000000, 585, 0.676301 (stdev 0.467757), 0:00:00.031250, 2595
B: 865, 0, 1, 0, False, 1.000000, 438, 0.506358 (stdev 0.499677), 0:00:00, 0
A: cycle: 865
average reward: 0.676301 (stdev 0.467757)
B: cycle: 865
average reward: 0.506358 (stdev 0.499677)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 866, 1, 1, 0, False, 1.000000, 586, 0.676674 (stdev 0.467617), 0:00:00.046886, 2598
B: 866, 1, 0, 1, False, 1.000000, 438, 0.505774 (stdev 0.499671), 0:00:00, 0
A: cycle: 866
average reward: 0.676674 (stdev 0.467617)
B: cycle: 866
average reward: 0.505774 (stdev 0.499671)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 867, 0, 1, 1, False, 1.000000, 587, 0.677047 (stdev 0.467476), 0:00:00.046875, 2601
B: 867, 0, 0, 1, False, 1.000000, 438, 0.505190 (stdev 0.499678), 0:00:00, 0
A: cycle: 867
average reward: 0.677047 (stdev 0.467476)
B: cycle: 867
average reward: 0.505190 (stdev 0.499678)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 868, 1, 1, 0, False, 1.000000, 588, 0.677419 (stdev 0.467335), 0:00:00.046864, 2604
B: 868, 1, 1, 0, False, 1.000000, 439, 0.505760 (stdev 0.499685), 0:00:00, 0
A: cycle: 868
average reward: 0.677419 (stdev 0.467335)
B: cycle: 868
average reward: 0.505760 (stdev 0.499685)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 869, 0, 1, 1, False, 1.000000, 589, 0.677791 (stdev 0.467195), 0:00:00.046886, 2607
B: 869, 0, 1, 0, False, 1.000000, 440, 0.506329 (stdev 0.499679), 0:00:00, 0
A: cycle: 869
average reward: 0.677791 (stdev 0.467195)
B: cycle: 869
average reward: 0.506329 (stdev 0.499679)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 870, 1, 1, 0, False, 1.000000, 590, 0.678161 (stdev 0.467054), 0:00:00.046875, 2610
B: 870, 1, 0, 1, False, 1.000000, 440, 0.505747 (stdev 0.499673), 0:00:00, 0
A: cycle: 870
average reward: 0.678161 (stdev 0.467054)
B: cycle: 870
average reward: 0.505747 (stdev 0.499673)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 871, 0, 1, 1, False, 1.000000, 591, 0.678530 (stdev 0.466913), 0:00:00.046874, 2613
B: 871, 0, 0, 1, False, 1.000000, 440, 0.505166 (stdev 0.499680), 0:00:00, 0
A: cycle: 871
average reward: 0.678530 (stdev 0.466913)
B: cycle: 871
average reward: 0.505166 (stdev 0.499680)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 872, 1, 1, 0, False, 1.000000, 592, 0.678899 (stdev 0.466773), 0:00:00.046875, 2616
B: 872, 1, 1, 1, False, 1.000000, 441, 0.505734 (stdev 0.499687), 0:00:00, 0
A: cycle: 872
average reward: 0.678899 (stdev 0.466773)
B: cycle: 872
average reward: 0.505734 (stdev 0.499687)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 873, 0, 1, 1, False, 1.000000, 593, 0.679267 (stdev 0.466632), 0:00:00.031250, 2619
B: 873, 0, 0, 1, False, 1.000000, 441, 0.505155 (stdev 0.499681), 0:00:00, 0
A: cycle: 873
average reward: 0.679267 (stdev 0.466632)
B: cycle: 873
average reward: 0.505155 (stdev 0.499681)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 874, 1, 1, 0, False, 1.000000, 594, 0.679634 (stdev 0.466491), 0:00:00.046875, 2622
B: 874, 1, 1, 1, False, 1.000000, 442, 0.505721 (stdev 0.499687), 0:00:00, 0
A: cycle: 874
average reward: 0.679634 (stdev 0.466491)
B: cycle: 874
average reward: 0.505721 (stdev 0.499687)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 875, 0, 1, 1, False, 1.000000, 595, 0.680000 (stdev 0.466351), 0:00:00.046863, 2625
B: 875, 0, 0, 1, False, 1.000000, 442, 0.505143 (stdev 0.499681), 0:00:00, 0
A: cycle: 875
average reward: 0.680000 (stdev 0.466351)
B: cycle: 875
average reward: 0.505143 (stdev 0.499681)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 876, 1, 1, 0, False, 1.000000, 596, 0.680365 (stdev 0.466210), 0:00:00.046887, 2628
B: 876, 1, 1, 1, False, 1.000000, 443, 0.505708 (stdev 0.499688), 0:00:00, 0
A: cycle: 876
average reward: 0.680365 (stdev 0.466210)
B: cycle: 876
average reward: 0.505708 (stdev 0.499688)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 877, 0, 1, 1, False, 1.000000, 597, 0.680730 (stdev 0.466069), 0:00:00.046874, 2631
B: 877, 0, 0, 0, False, 1.000000, 443, 0.505131 (stdev 0.499682), 0:00:00, 0
A: cycle: 877
average reward: 0.680730 (stdev 0.466069)
B: cycle: 877
average reward: 0.505131 (stdev 0.499682)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 878, 1, 1, 0, False, 1.000000, 598, 0.681093 (stdev 0.465928), 0:00:00.046865, 2634
B: 878, 1, 0, 1, False, 1.000000, 443, 0.504556 (stdev 0.499689), 0:00:00, 0
A: cycle: 878
average reward: 0.681093 (stdev 0.465928)
B: cycle: 878
average reward: 0.504556 (stdev 0.499689)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 879, 0, 1, 1, False, 1.000000, 599, 0.681456 (stdev 0.465788), 0:00:00.046873, 2637
B: 879, 0, 0, 0, False, 1.000000, 443, 0.503982 (stdev 0.499695), 0:00:00, 0
A: cycle: 879
average reward: 0.681456 (stdev 0.465788)
B: cycle: 879
average reward: 0.503982 (stdev 0.499695)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 880, 1, 1, 0, False, 1.000000, 600, 0.681818 (stdev 0.465647), 0:00:00.046875, 2640
B: 880, 1, 0, 0, False, 1.000000, 443, 0.503409 (stdev 0.499700), 0:00:00, 0
A: cycle: 880
average reward: 0.681818 (stdev 0.465647)
B: cycle: 880
average reward: 0.503409 (stdev 0.499700)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 881, 0, 1, 1, False, 1.000000, 601, 0.682179 (stdev 0.465506), 0:00:00.046891, 2643
B: 881, 0, 1, 1, False, 1.000000, 444, 0.503973 (stdev 0.499705), 0:00:00, 0
A: cycle: 881
average reward: 0.682179 (stdev 0.465506)
B: cycle: 881
average reward: 0.503973 (stdev 0.499705)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 882, 1, 1, 0, False, 1.000000, 602, 0.682540 (stdev 0.465365), 0:00:00.046859, 2646
B: 882, 1, 1, 1, False, 1.000000, 445, 0.504535 (stdev 0.499701), 0:00:00, 0
A: cycle: 882
average reward: 0.682540 (stdev 0.465365)
B: cycle: 882
average reward: 0.504535 (stdev 0.499701)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 883, 0, 1, 1, False, 1.000000, 603, 0.682899 (stdev 0.465225), 0:00:00.046891, 2649
B: 883, 0, 0, 0, False, 1.000000, 445, 0.503964 (stdev 0.499696), 0:00:00, 0
A: cycle: 883
average reward: 0.682899 (stdev 0.465225)
B: cycle: 883
average reward: 0.503964 (stdev 0.499696)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 884, 1, 1, 0, False, 1.000000, 604, 0.683258 (stdev 0.465084), 0:00:00.031245, 2652
B: 884, 1, 0, 1, False, 1.000000, 445, 0.503394 (stdev 0.499701), 0:00:00, 0
A: cycle: 884
average reward: 0.683258 (stdev 0.465084)
B: cycle: 884
average reward: 0.503394 (stdev 0.499701)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 885, 0, 1, 1, False, 1.000000, 605, 0.683616 (stdev 0.464943), 0:00:00.046875, 2655
B: 885, 0, 0, 0, False, 1.000000, 445, 0.502825 (stdev 0.499706), 0:00:00, 0
A: cycle: 885
average reward: 0.683616 (stdev 0.464943)
B: cycle: 885
average reward: 0.502825 (stdev 0.499706)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 886, 1, 1, 0, False, 1.000000, 606, 0.683973 (stdev 0.464802), 0:00:00.046880, 2658
B: 886, 1, 0, 1, False, 1.000000, 445, 0.502257 (stdev 0.499710), 0:00:00, 0
A: cycle: 886
average reward: 0.683973 (stdev 0.464802)
B: cycle: 886
average reward: 0.502257 (stdev 0.499710)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 887, 0, 1, 1, False, 1.000000, 607, 0.684329 (stdev 0.464661), 0:00:00.046870, 2661
B: 887, 0, 0, 0, False, 1.000000, 445, 0.501691 (stdev 0.499713), 0:00:00, 0
A: cycle: 887
average reward: 0.684329 (stdev 0.464661)
B: cycle: 887
average reward: 0.501691 (stdev 0.499713)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 888, 1, 1, 0, False, 1.000000, 608, 0.684685 (stdev 0.464521), 0:00:00.046879, 2664
B: 888, 1, 0, 1, False, 1.000000, 445, 0.501126 (stdev 0.499716), 0:00:00, 0
A: cycle: 888
average reward: 0.684685 (stdev 0.464521)
B: cycle: 888
average reward: 0.501126 (stdev 0.499716)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 889, 0, 1, 1, False, 1.000000, 609, 0.685039 (stdev 0.464380), 0:00:00.046875, 2667
B: 889, 0, 0, 1, False, 1.000000, 445, 0.500562 (stdev 0.499717), 0:00:00, 0
A: cycle: 889
average reward: 0.685039 (stdev 0.464380)
B: cycle: 889
average reward: 0.500562 (stdev 0.499717)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 890, 1, 1, 0, False, 1.000000, 610, 0.685393 (stdev 0.464239), 0:00:00.046875, 2670
B: 890, 1, 1, 0, False, 1.000000, 446, 0.501124 (stdev 0.499719), 0:00:00, 0
A: cycle: 890
average reward: 0.685393 (stdev 0.464239)
B: cycle: 890
average reward: 0.501124 (stdev 0.499719)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 891, 0, 1, 1, False, 1.000000, 611, 0.685746 (stdev 0.464098), 0:00:00.031245, 2673
B: 891, 0, 1, 0, False, 1.000000, 447, 0.501684 (stdev 0.499718), 0:00:00, 0
A: cycle: 891
average reward: 0.685746 (stdev 0.464098)
B: cycle: 891
average reward: 0.501684 (stdev 0.499718)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 892, 1, 1, 0, False, 1.000000, 612, 0.686099 (stdev 0.463958), 0:00:00.046879, 2676
B: 892, 1, 0, 0, False, 1.000000, 447, 0.501121 (stdev 0.499717), 0:00:00, 0
A: cycle: 892
average reward: 0.686099 (stdev 0.463958)
B: cycle: 892
average reward: 0.501121 (stdev 0.499717)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 893, 0, 1, 1, False, 1.000000, 613, 0.686450 (stdev 0.463817), 0:00:00.046870, 2679
B: 893, 0, 1, 0, False, 1.000000, 448, 0.501680 (stdev 0.499719), 0:00:00, 0
A: cycle: 893
average reward: 0.686450 (stdev 0.463817)
B: cycle: 893
average reward: 0.501680 (stdev 0.499719)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 894, 1, 1, 0, False, 1.000000, 614, 0.686801 (stdev 0.463676), 0:00:00.049420, 2682
B: 894, 1, 0, 1, False, 1.000000, 448, 0.501119 (stdev 0.499717), 0:00:00, 0
A: cycle: 894
average reward: 0.686801 (stdev 0.463676)
B: cycle: 894
average reward: 0.501119 (stdev 0.499717)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 895, 0, 1, 1, False, 1.000000, 615, 0.687151 (stdev 0.463535), 0:00:00.046875, 2685
B: 895, 0, 0, 1, False, 1.000000, 448, 0.500559 (stdev 0.499719), 0:00:00, 0
A: cycle: 895
average reward: 0.687151 (stdev 0.463535)
B: cycle: 895
average reward: 0.500559 (stdev 0.499719)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 896, 1, 1, 0, False, 1.000000, 616, 0.687500 (stdev 0.463395), 0:00:00.046887, 2688
B: 896, 1, 1, 1, False, 1.000000, 449, 0.501116 (stdev 0.499721), 0:00:00, 0
A: cycle: 896
average reward: 0.687500 (stdev 0.463395)
B: cycle: 896
average reward: 0.501116 (stdev 0.499721)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 897, 0, 1, 1, False, 1.000000, 617, 0.687848 (stdev 0.463254), 0:00:00.031255, 2691
B: 897, 0, 0, 1, False, 1.000000, 449, 0.500557 (stdev 0.499720), 0:00:00, 0
A: cycle: 897
average reward: 0.687848 (stdev 0.463254)
B: cycle: 897
average reward: 0.500557 (stdev 0.499720)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 898, 1, 1, 0, False, 1.000000, 618, 0.688196 (stdev 0.463113), 0:00:00.046875, 2694
B: 898, 1, 1, 0, False, 1.000000, 450, 0.501114 (stdev 0.499721), 0:00:00, 0
A: cycle: 898
average reward: 0.688196 (stdev 0.463113)
B: cycle: 898
average reward: 0.501114 (stdev 0.499721)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 899, 0, 1, 1, False, 1.000000, 619, 0.688543 (stdev 0.462973), 0:00:00.046875, 2697
B: 899, 0, 1, 0, False, 1.000000, 451, 0.501669 (stdev 0.499721), 0:00:00, 0
A: cycle: 899
average reward: 0.688543 (stdev 0.462973)
B: cycle: 899
average reward: 0.501669 (stdev 0.499721)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 900, 1, 1, 1, False, 1.000000, 620, 0.688889 (stdev 0.462832), 0:00:00.046874, 2700
B: 900, 1, 0, 0, False, 1.000000, 451, 0.501111 (stdev 0.499719), 0:00:00, 0
A: cycle: 900
average reward: 0.688889 (stdev 0.462832)
B: cycle: 900
average reward: 0.501111 (stdev 0.499719)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1
1
0
1
0
0
0
0
0
0
1
0
1
1
0
0
1
0
0
1
1
1
0
0
1
0
0
1
1
1
0
1
0
0
1
1
1
1
1
1
0
0
1
1
1
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
0
1
0
0
1
0
1
1
0



A: action = high, observation = low, reward = wrong (0)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 901, 0, 0, 1, False, 1.000000, 620, 0.688124 (stdev 0.462691), 0:00:00.046859, 2703
B: 901, 0, 1, 0, False, 1.000000, 452, 0.501665 (stdev 0.499721), 0:00:00, 0
A: cycle: 901
average reward: 0.688124 (stdev 0.462691)
B: cycle: 901
average reward: 0.501665 (stdev 0.499721)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 902, 1, 1, 0, False, 1.000000, 621, 0.688470 (stdev 0.463003), 0:00:00.046875, 2706
B: 902, 1, 0, 0, False, 1.000000, 452, 0.501109 (stdev 0.499720), 0:00:00, 0
A: cycle: 902
average reward: 0.688470 (stdev 0.463003)
B: cycle: 902
average reward: 0.501109 (stdev 0.499720)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 903, 0, 1, 1, False, 1.000000, 622, 0.688815 (stdev 0.462862), 0:00:00.046892, 2709
B: 903, 0, 1, 0, False, 1.000000, 453, 0.501661 (stdev 0.499722), 0:00:00, 0
A: cycle: 903
average reward: 0.688815 (stdev 0.462862)
B: cycle: 903
average reward: 0.501661 (stdev 0.499722)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 904, 1, 1, 0, False, 1.000000, 623, 0.689159 (stdev 0.462722), 0:00:00.046858, 2712
B: 904, 1, 0, 0, False, 1.000000, 453, 0.501106 (stdev 0.499721), 0:00:00, 0
A: cycle: 904
average reward: 0.689159 (stdev 0.462722)
B: cycle: 904
average reward: 0.501106 (stdev 0.499721)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 905, 0, 1, 1, False, 1.000000, 624, 0.689503 (stdev 0.462582), 0:00:00.046875, 2715
B: 905, 0, 1, 1, False, 1.000000, 454, 0.501657 (stdev 0.499722), 0:00:00, 0
A: cycle: 905
average reward: 0.689503 (stdev 0.462582)
B: cycle: 905
average reward: 0.501657 (stdev 0.499722)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 906, 1, 1, 0, False, 1.000000, 625, 0.689845 (stdev 0.462442), 0:00:00.046875, 2718
B: 906, 1, 1, 0, False, 1.000000, 455, 0.502208 (stdev 0.499721), 0:00:00, 0
A: cycle: 906
average reward: 0.689845 (stdev 0.462442)
B: cycle: 906
average reward: 0.502208 (stdev 0.499721)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 907, 0, 1, 1, False, 1.000000, 626, 0.690187 (stdev 0.462302), 0:00:00.046891, 2721
B: 907, 0, 1, 0, False, 1.000000, 456, 0.502756 (stdev 0.499719), 0:00:00, 0
A: cycle: 907
average reward: 0.690187 (stdev 0.462302)
B: cycle: 907
average reward: 0.502756 (stdev 0.499719)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 908, 1, 1, 0, False, 1.000000, 627, 0.690529 (stdev 0.462161), 0:00:00.046875, 2724
B: 908, 1, 0, 0, False, 1.000000, 456, 0.502203 (stdev 0.499717), 0:00:00, 0
A: cycle: 908
average reward: 0.690529 (stdev 0.462161)
B: cycle: 908
average reward: 0.502203 (stdev 0.499717)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 909, 0, 1, 1, False, 1.000000, 628, 0.690869 (stdev 0.462021), 0:00:00.046875, 2727
B: 909, 0, 1, 0, False, 1.000000, 457, 0.502750 (stdev 0.499720), 0:00:00, 0
A: cycle: 909
average reward: 0.690869 (stdev 0.462021)
B: cycle: 909
average reward: 0.502750 (stdev 0.499720)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 910, 1, 1, 0, False, 1.000000, 629, 0.691209 (stdev 0.461881), 0:00:00.046875, 2730
B: 910, 1, 0, 0, False, 1.000000, 457, 0.502198 (stdev 0.499718), 0:00:00, 0
A: cycle: 910
average reward: 0.691209 (stdev 0.461881)
B: cycle: 910
average reward: 0.502198 (stdev 0.499718)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 911, 0, 1, 1, False, 1.000000, 630, 0.691548 (stdev 0.461741), 0:00:00.046873, 2733
B: 911, 0, 1, 1, False, 1.000000, 458, 0.502744 (stdev 0.499721), 0:00:00, 0
A: cycle: 911
average reward: 0.691548 (stdev 0.461741)
B: cycle: 911
average reward: 0.502744 (stdev 0.499721)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 912, 1, 1, 0, False, 1.000000, 631, 0.691886 (stdev 0.461601), 0:00:00.046875, 2736
B: 912, 1, 1, 0, False, 1.000000, 459, 0.503289 (stdev 0.499718), 0:00:00, 0
A: cycle: 912
average reward: 0.691886 (stdev 0.461601)
B: cycle: 912
average reward: 0.503289 (stdev 0.499718)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 913, 0, 1, 1, False, 1.000000, 632, 0.692223 (stdev 0.461461), 0:00:00.046875, 2739
B: 913, 0, 1, 1, False, 1.000000, 460, 0.503834 (stdev 0.499715), 0:00:00, 0
A: cycle: 913
average reward: 0.692223 (stdev 0.461461)
B: cycle: 913
average reward: 0.503834 (stdev 0.499715)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 914, 1, 1, 0, False, 1.000000, 633, 0.692560 (stdev 0.461321), 0:00:00.046858, 2742
B: 914, 1, 1, 1, False, 1.000000, 461, 0.504376 (stdev 0.499712), 0:00:00, 0
A: cycle: 914
average reward: 0.692560 (stdev 0.461321)
B: cycle: 914
average reward: 0.504376 (stdev 0.499712)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 915, 0, 1, 1, False, 1.000000, 634, 0.692896 (stdev 0.461181), 0:00:00.031250, 2745
B: 915, 0, 0, 1, False, 1.000000, 461, 0.503825 (stdev 0.499708), 0:00:00, 0
A: cycle: 915
average reward: 0.692896 (stdev 0.461181)
B: cycle: 915
average reward: 0.503825 (stdev 0.499708)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 916, 1, 1, 0, False, 1.000000, 635, 0.693231 (stdev 0.461041), 0:00:00.046875, 2748
B: 916, 1, 1, 1, False, 1.000000, 462, 0.504367 (stdev 0.499712), 0:00:00, 0
A: cycle: 916
average reward: 0.693231 (stdev 0.461041)
B: cycle: 916
average reward: 0.504367 (stdev 0.499712)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 917, 0, 1, 1, False, 1.000000, 636, 0.693566 (stdev 0.460901), 0:00:00.046886, 2751
B: 917, 0, 0, 1, False, 1.000000, 462, 0.503817 (stdev 0.499708), 0:00:00, 0
A: cycle: 917
average reward: 0.693566 (stdev 0.460901)
B: cycle: 917
average reward: 0.503817 (stdev 0.499708)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 918, 1, 1, 0, False, 1.000000, 637, 0.693900 (stdev 0.460761), 0:00:00.046875, 2754
B: 918, 1, 1, 0, False, 1.000000, 463, 0.504357 (stdev 0.499713), 0:00:00, 0
A: cycle: 918
average reward: 0.693900 (stdev 0.460761)
B: cycle: 918
average reward: 0.504357 (stdev 0.499713)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 919, 0, 1, 1, False, 1.000000, 638, 0.694233 (stdev 0.460621), 0:00:00.046863, 2757
B: 919, 0, 1, 1, False, 1.000000, 464, 0.504897 (stdev 0.499709), 0:00:00, 0
A: cycle: 919
average reward: 0.694233 (stdev 0.460621)
B: cycle: 919
average reward: 0.504897 (stdev 0.499709)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 920, 1, 1, 0, False, 1.000000, 639, 0.694565 (stdev 0.460481), 0:00:00.046875, 2760
B: 920, 1, 1, 0, False, 1.000000, 465, 0.505435 (stdev 0.499704), 0:00:00, 0
A: cycle: 920
average reward: 0.694565 (stdev 0.460481)
B: cycle: 920
average reward: 0.505435 (stdev 0.499704)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 921, 0, 1, 1, False, 1.000000, 640, 0.694897 (stdev 0.460341), 0:00:00.046875, 2763
B: 921, 0, 1, 0, False, 1.000000, 466, 0.505972 (stdev 0.499699), 0:00:00, 0
A: cycle: 921
average reward: 0.694897 (stdev 0.460341)
B: cycle: 921
average reward: 0.505972 (stdev 0.499699)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 922, 1, 1, 0, False, 1.000000, 641, 0.695228 (stdev 0.460201), 0:00:00.046875, 2766
B: 922, 1, 0, 0, False, 1.000000, 466, 0.505423 (stdev 0.499693), 0:00:00, 0
A: cycle: 922
average reward: 0.695228 (stdev 0.460201)
B: cycle: 922
average reward: 0.505423 (stdev 0.499693)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 923, 0, 1, 1, False, 1.000000, 642, 0.695558 (stdev 0.460061), 0:00:00.046875, 2769
B: 923, 0, 1, 1, False, 1.000000, 467, 0.505959 (stdev 0.499700), 0:00:00, 0
A: cycle: 923
average reward: 0.695558 (stdev 0.460061)
B: cycle: 923
average reward: 0.505959 (stdev 0.499700)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 924, 1, 1, 0, False, 1.000000, 643, 0.695887 (stdev 0.459922), 0:00:00.046874, 2772
B: 924, 1, 1, 0, False, 1.000000, 468, 0.506494 (stdev 0.499694), 0:00:00, 0
A: cycle: 924
average reward: 0.695887 (stdev 0.459922)
B: cycle: 924
average reward: 0.506494 (stdev 0.499694)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 925, 0, 1, 1, False, 1.000000, 644, 0.696216 (stdev 0.459782), 0:00:00.046876, 2775
B: 925, 0, 1, 0, False, 1.000000, 469, 0.507027 (stdev 0.499688), 0:00:00, 0
A: cycle: 925
average reward: 0.696216 (stdev 0.459782)
B: cycle: 925
average reward: 0.507027 (stdev 0.499688)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 926, 1, 1, 0, False, 1.000000, 645, 0.696544 (stdev 0.459642), 0:00:00.031266, 2778
B: 926, 1, 0, 0, False, 1.000000, 469, 0.506479 (stdev 0.499681), 0:00:00, 0
A: cycle: 926
average reward: 0.696544 (stdev 0.459642)
B: cycle: 926
average reward: 0.506479 (stdev 0.499681)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 927, 0, 1, 1, False, 1.000000, 646, 0.696872 (stdev 0.459502), 0:00:00.046874, 2781
B: 927, 0, 1, 1, False, 1.000000, 470, 0.507012 (stdev 0.499688), 0:00:00, 0
A: cycle: 927
average reward: 0.696872 (stdev 0.459502)
B: cycle: 927
average reward: 0.507012 (stdev 0.499688)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 928, 1, 1, 0, False, 1.000000, 647, 0.697198 (stdev 0.459363), 0:00:00.046875, 2784
B: 928, 1, 1, 1, False, 1.000000, 471, 0.507543 (stdev 0.499681), 0:00:00, 0
A: cycle: 928
average reward: 0.697198 (stdev 0.459363)
B: cycle: 928
average reward: 0.507543 (stdev 0.499681)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 929, 0, 1, 1, False, 1.000000, 648, 0.697524 (stdev 0.459223), 0:00:00.046870, 2787
B: 929, 0, 0, 0, False, 1.000000, 471, 0.506997 (stdev 0.499674), 0:00:00, 0
A: cycle: 929
average reward: 0.697524 (stdev 0.459223)
B: cycle: 929
average reward: 0.506997 (stdev 0.499674)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 930, 1, 1, 0, False, 1.000000, 649, 0.697849 (stdev 0.459083), 0:00:00.046875, 2790
B: 930, 1, 0, 0, False, 1.000000, 471, 0.506452 (stdev 0.499682), 0:00:00, 0
A: cycle: 930
average reward: 0.697849 (stdev 0.459083)
B: cycle: 930
average reward: 0.506452 (stdev 0.499682)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 931, 0, 1, 0, False, 1.000000, 650, 0.698174 (stdev 0.458943), 0:00:00.046863, 2793
B: 931, 0, 1, 0, False, 1.000000, 472, 0.506982 (stdev 0.499690), 0:00:00, 0
A: cycle: 931
average reward: 0.698174 (stdev 0.458943)
B: cycle: 931
average reward: 0.506982 (stdev 0.499690)
A: action = low, observation = high, reward = wrong (0)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 932, 1, 0, 0, False, 1.000000, 650, 0.697425 (stdev 0.458804), 0:00:00.031267, 2796
B: 932, 1, 0, 1, False, 1.000000, 472, 0.506438 (stdev 0.499683), 0:00:00, 0
A: cycle: 932
average reward: 0.697425 (stdev 0.458804)
B: cycle: 932
average reward: 0.506438 (stdev 0.499683)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 933, 0, 1, 1, False, 1.000000, 651, 0.697749 (stdev 0.459127), 0:00:00.046874, 2799
B: 933, 0, 0, 0, False, 1.000000, 472, 0.505895 (stdev 0.499691), 0:00:00, 0
A: cycle: 933
average reward: 0.697749 (stdev 0.459127)
B: cycle: 933
average reward: 0.505895 (stdev 0.499691)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 934, 1, 1, 0, False, 1.000000, 652, 0.698073 (stdev 0.458987), 0:00:00.046858, 2802
B: 934, 1, 0, 1, False, 1.000000, 472, 0.505353 (stdev 0.499698), 0:00:00, 0
A: cycle: 934
average reward: 0.698073 (stdev 0.458987)
B: cycle: 934
average reward: 0.505353 (stdev 0.499698)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 935, 0, 1, 1, False, 1.000000, 653, 0.698396 (stdev 0.458848), 0:00:00.046876, 2805
B: 935, 0, 0, 0, False, 1.000000, 472, 0.504813 (stdev 0.499704), 0:00:00, 0
A: cycle: 935
average reward: 0.698396 (stdev 0.458848)
B: cycle: 935
average reward: 0.504813 (stdev 0.499704)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 936, 1, 1, 0, False, 1.000000, 654, 0.698718 (stdev 0.458709), 0:00:00.062509, 2808
B: 936, 1, 0, 0, False, 1.000000, 472, 0.504274 (stdev 0.499710), 0:00:00, 0
A: cycle: 936
average reward: 0.698718 (stdev 0.458709)
B: cycle: 936
average reward: 0.504274 (stdev 0.499710)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 937, 0, 1, 1, False, 1.000000, 655, 0.699039 (stdev 0.458570), 0:00:00.046863, 2811
B: 937, 0, 1, 0, False, 1.000000, 473, 0.504803 (stdev 0.499715), 0:00:00, 0
A: cycle: 937
average reward: 0.699039 (stdev 0.458570)
B: cycle: 937
average reward: 0.504803 (stdev 0.499715)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 938, 1, 1, 0, False, 1.000000, 656, 0.699360 (stdev 0.458431), 0:00:00.046874, 2814
B: 938, 1, 0, 0, False, 1.000000, 473, 0.504264 (stdev 0.499710), 0:00:00, 0
A: cycle: 938
average reward: 0.699360 (stdev 0.458431)
B: cycle: 938
average reward: 0.504264 (stdev 0.499710)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 939, 0, 1, 1, False, 1.000000, 657, 0.699681 (stdev 0.458292), 0:00:00.046875, 2817
B: 939, 0, 1, 0, False, 1.000000, 474, 0.504792 (stdev 0.499716), 0:00:00, 0
A: cycle: 939
average reward: 0.699681 (stdev 0.458292)
B: cycle: 939
average reward: 0.504792 (stdev 0.499716)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 940, 1, 1, 0, False, 1.000000, 658, 0.700000 (stdev 0.458153), 0:00:00.046887, 2820
B: 940, 1, 0, 1, False, 1.000000, 474, 0.504255 (stdev 0.499711), 0:00:00, 0
A: cycle: 940
average reward: 0.700000 (stdev 0.458153)
B: cycle: 940
average reward: 0.504255 (stdev 0.499711)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 941, 0, 1, 1, False, 1.000000, 659, 0.700319 (stdev 0.458014), 0:00:00.031250, 2823
B: 941, 0, 0, 0, False, 1.000000, 474, 0.503719 (stdev 0.499716), 0:00:00, 0
A: cycle: 941
average reward: 0.700319 (stdev 0.458014)
B: cycle: 941
average reward: 0.503719 (stdev 0.499716)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 942, 1, 1, 0, False, 1.000000, 660, 0.700637 (stdev 0.457875), 0:00:00.046875, 2826
B: 942, 1, 0, 1, False, 1.000000, 474, 0.503185 (stdev 0.499721), 0:00:00, 0
A: cycle: 942
average reward: 0.700637 (stdev 0.457875)
B: cycle: 942
average reward: 0.503185 (stdev 0.499721)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 943, 0, 1, 1, False, 1.000000, 661, 0.700954 (stdev 0.457736), 0:00:00.046874, 2829
B: 943, 0, 0, 1, False, 1.000000, 474, 0.502651 (stdev 0.499725), 0:00:00, 0
A: cycle: 943
average reward: 0.700954 (stdev 0.457736)
B: cycle: 943
average reward: 0.502651 (stdev 0.499725)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 944, 1, 1, 0, False, 1.000000, 662, 0.701271 (stdev 0.457597), 0:00:00.046875, 2832
B: 944, 1, 1, 1, False, 1.000000, 475, 0.503178 (stdev 0.499728), 0:00:00, 0
A: cycle: 944
average reward: 0.701271 (stdev 0.457597)
B: cycle: 944
average reward: 0.503178 (stdev 0.499728)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 945, 0, 1, 1, False, 1.000000, 663, 0.701587 (stdev 0.457458), 0:00:00.046863, 2835
B: 945, 0, 0, 1, False, 1.000000, 475, 0.502646 (stdev 0.499725), 0:00:00, 0
A: cycle: 945
average reward: 0.701587 (stdev 0.457458)
B: cycle: 945
average reward: 0.502646 (stdev 0.499725)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 946, 1, 1, 0, False, 1.000000, 664, 0.701903 (stdev 0.457320), 0:00:00.046887, 2838
B: 946, 1, 1, 1, False, 1.000000, 476, 0.503171 (stdev 0.499729), 0:00:00, 0
A: cycle: 946
average reward: 0.701903 (stdev 0.457320)
B: cycle: 946
average reward: 0.503171 (stdev 0.499729)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 947, 0, 1, 1, False, 1.000000, 665, 0.702218 (stdev 0.457181), 0:00:00.046875, 2841
B: 947, 0, 0, 1, False, 1.000000, 476, 0.502640 (stdev 0.499726), 0:00:00, 0
A: cycle: 947
average reward: 0.702218 (stdev 0.457181)
B: cycle: 947
average reward: 0.502640 (stdev 0.499726)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 948, 1, 1, 0, False, 1.000000, 666, 0.702532 (stdev 0.457042), 0:00:00.031238, 2844
B: 948, 1, 1, 0, False, 1.000000, 477, 0.503165 (stdev 0.499729), 0:00:00, 0
A: cycle: 948
average reward: 0.702532 (stdev 0.457042)
B: cycle: 948
average reward: 0.503165 (stdev 0.499729)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 949, 0, 1, 1, False, 1.000000, 667, 0.702845 (stdev 0.456903), 0:00:00.046886, 2847
B: 949, 0, 1, 0, False, 1.000000, 478, 0.503688 (stdev 0.499726), 0:00:00, 0
A: cycle: 949
average reward: 0.702845 (stdev 0.456903)
B: cycle: 949
average reward: 0.503688 (stdev 0.499726)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 950, 1, 1, 0, False, 1.000000, 668, 0.703158 (stdev 0.456765), 0:00:00.046880, 2850
B: 950, 1, 0, 0, False, 1.000000, 478, 0.503158 (stdev 0.499723), 0:00:00, 0
A: cycle: 950
average reward: 0.703158 (stdev 0.456765)
B: cycle: 950
average reward: 0.503158 (stdev 0.499723)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1
1
0
1
0
0
0
0
0
0
1
0
1
1
0
0
1
0
0
1
1
1
0
0
1
0
0
1
1
1
0
1
0
0
1
1
1
1
1
1
0
0
1
1
1
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
0
1
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
1
0
1
1
1
1
0
1
0
1
1
1
1
0
1
1
1
0
1
1
0
0
1
0
0
0
0
0
1
0
1
0
0
0
0
1
0
1
0
1
1
0



A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 951, 0, 1, 1, False, 1.000000, 669, 0.703470 (stdev 0.456626), 0:00:00.046858, 2853
B: 951, 0, 1, 1, False, 1.000000, 479, 0.503680 (stdev 0.499727), 0:00:00, 0
A: cycle: 951
average reward: 0.703470 (stdev 0.456626)
B: cycle: 951
average reward: 0.503680 (stdev 0.499727)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 952, 1, 1, 0, False, 1.000000, 670, 0.703782 (stdev 0.456487), 0:00:00.046876, 2856
B: 952, 1, 1, 0, False, 1.000000, 480, 0.504202 (stdev 0.499724), 0:00:00, 0
A: cycle: 952
average reward: 0.703782 (stdev 0.456487)
B: cycle: 952
average reward: 0.504202 (stdev 0.499724)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 953, 0, 1, 1, False, 1.000000, 671, 0.704092 (stdev 0.456349), 0:00:00.031249, 2859
B: 953, 0, 1, 0, False, 1.000000, 481, 0.504722 (stdev 0.499720), 0:00:00, 0
A: cycle: 953
average reward: 0.704092 (stdev 0.456349)
B: cycle: 953
average reward: 0.504722 (stdev 0.499720)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 954, 1, 1, 1, False, 1.000000, 672, 0.704403 (stdev 0.456210), 0:00:00.046892, 2862
B: 954, 1, 0, 1, False, 1.000000, 481, 0.504193 (stdev 0.499716), 0:00:00, 0
A: cycle: 954
average reward: 0.704403 (stdev 0.456210)
B: cycle: 954
average reward: 0.504193 (stdev 0.499716)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 955, 0, 0, 1, False, 1.000000, 672, 0.703665 (stdev 0.456072), 0:00:00.046875, 2865
B: 955, 0, 0, 1, False, 1.000000, 481, 0.503665 (stdev 0.499721), 0:00:00, 0
A: cycle: 955
average reward: 0.703665 (stdev 0.456072)
B: cycle: 955
average reward: 0.503665 (stdev 0.499721)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 956, 1, 1, 0, False, 1.000000, 673, 0.703975 (stdev 0.456402), 0:00:00.046875, 2868
B: 956, 1, 1, 1, False, 1.000000, 482, 0.504184 (stdev 0.499725), 0:00:00, 0
A: cycle: 956
average reward: 0.703975 (stdev 0.456402)
B: cycle: 956
average reward: 0.504184 (stdev 0.499725)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 957, 0, 1, 1, False, 1.000000, 674, 0.704284 (stdev 0.456264), 0:00:00.046875, 2871
B: 957, 0, 0, 0, False, 1.000000, 482, 0.503657 (stdev 0.499721), 0:00:00, 0
A: cycle: 957
average reward: 0.704284 (stdev 0.456264)
B: cycle: 957
average reward: 0.503657 (stdev 0.499721)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 958, 1, 1, 0, False, 1.000000, 675, 0.704593 (stdev 0.456126), 0:00:00.046874, 2874
B: 958, 1, 0, 0, False, 1.000000, 482, 0.503132 (stdev 0.499726), 0:00:00, 0
A: cycle: 958
average reward: 0.704593 (stdev 0.456126)
B: cycle: 958
average reward: 0.503132 (stdev 0.499726)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 959, 0, 1, 1, False, 1.000000, 676, 0.704901 (stdev 0.455988), 0:00:00.046874, 2877
B: 959, 0, 1, 0, False, 1.000000, 483, 0.503650 (stdev 0.499729), 0:00:00, 0
A: cycle: 959
average reward: 0.704901 (stdev 0.455988)
B: cycle: 959
average reward: 0.503650 (stdev 0.499729)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 960, 1, 1, 0, False, 1.000000, 677, 0.705208 (stdev 0.455850), 0:00:00.046859, 2880
B: 960, 1, 0, 1, False, 1.000000, 483, 0.503125 (stdev 0.499726), 0:00:00, 0
A: cycle: 960
average reward: 0.705208 (stdev 0.455850)
B: cycle: 960
average reward: 0.503125 (stdev 0.499726)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 961, 0, 1, 1, False, 1.000000, 678, 0.705515 (stdev 0.455712), 0:00:00.046892, 2883
B: 961, 0, 0, 0, False, 1.000000, 483, 0.502601 (stdev 0.499730), 0:00:00, 0
A: cycle: 961
average reward: 0.705515 (stdev 0.455712)
B: cycle: 961
average reward: 0.502601 (stdev 0.499730)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 962, 1, 1, 0, False, 1.000000, 679, 0.705821 (stdev 0.455574), 0:00:00.046874, 2886
B: 962, 1, 0, 1, False, 1.000000, 483, 0.502079 (stdev 0.499733), 0:00:00, 0
A: cycle: 962
average reward: 0.705821 (stdev 0.455574)
B: cycle: 962
average reward: 0.502079 (stdev 0.499733)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 963, 0, 1, 1, False, 1.000000, 680, 0.706127 (stdev 0.455436), 0:00:00.046870, 2889
B: 963, 0, 0, 1, False, 1.000000, 483, 0.501558 (stdev 0.499736), 0:00:00, 0
A: cycle: 963
average reward: 0.706127 (stdev 0.455436)
B: cycle: 963
average reward: 0.501558 (stdev 0.499736)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 964, 1, 1, 0, False, 1.000000, 681, 0.706432 (stdev 0.455298), 0:00:00.046863, 2892
B: 964, 1, 1, 1, False, 1.000000, 484, 0.502075 (stdev 0.499738), 0:00:00, 0
A: cycle: 964
average reward: 0.706432 (stdev 0.455298)
B: cycle: 964
average reward: 0.502075 (stdev 0.499738)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 965, 0, 1, 1, False, 1.000000, 682, 0.706736 (stdev 0.455161), 0:00:00.046875, 2895
B: 965, 0, 0, 1, False, 1.000000, 484, 0.501554 (stdev 0.499737), 0:00:00, 0
A: cycle: 965
average reward: 0.706736 (stdev 0.455161)
B: cycle: 965
average reward: 0.501554 (stdev 0.499737)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 966, 1, 1, 1, False, 1.000000, 683, 0.707039 (stdev 0.455023), 0:00:00.046874, 2898
B: 966, 1, 1, 1, False, 1.000000, 485, 0.502070 (stdev 0.499739), 0:00:00, 0
A: cycle: 966
average reward: 0.707039 (stdev 0.455023)
B: cycle: 966
average reward: 0.502070 (stdev 0.499739)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 967, 0, 0, 1, False, 1.000000, 683, 0.706308 (stdev 0.454885), 0:00:00.046875, 2901
B: 967, 0, 0, 0, False, 1.000000, 485, 0.501551 (stdev 0.499737), 0:00:00, 0
A: cycle: 967
average reward: 0.706308 (stdev 0.454885)
B: cycle: 967
average reward: 0.501551 (stdev 0.499737)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 968, 1, 1, 0, False, 1.000000, 684, 0.706612 (stdev 0.455217), 0:00:00.046888, 2904
B: 968, 1, 0, 1, False, 1.000000, 485, 0.501033 (stdev 0.499739), 0:00:00, 0
A: cycle: 968
average reward: 0.706612 (stdev 0.455217)
B: cycle: 968
average reward: 0.501033 (stdev 0.499739)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 969, 0, 1, 1, False, 1.000000, 685, 0.706914 (stdev 0.455080), 0:00:00.046862, 2907
B: 969, 0, 0, 0, False, 1.000000, 485, 0.500516 (stdev 0.499741), 0:00:00, 0
A: cycle: 969
average reward: 0.706914 (stdev 0.455080)
B: cycle: 969
average reward: 0.500516 (stdev 0.499741)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 970, 1, 1, 0, False, 1.000000, 686, 0.707216 (stdev 0.454943), 0:00:00.046875, 2910
B: 970, 1, 0, 1, False, 1.000000, 485, 0.500000 (stdev 0.499742), 0:00:00, 0
A: cycle: 970
average reward: 0.707216 (stdev 0.454943)
B: cycle: 970
average reward: 0.500000 (stdev 0.499742)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 971, 0, 1, 1, False, 1.000000, 687, 0.707518 (stdev 0.454806), 0:00:00.046874, 2913
B: 971, 0, 0, 0, False, 1.000000, 485, 0.499485 (stdev 0.499742), 0:00:00, 0
A: cycle: 971
average reward: 0.707518 (stdev 0.454806)
B: cycle: 971
average reward: 0.499485 (stdev 0.499742)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 972, 1, 1, 0, False, 1.000000, 688, 0.707819 (stdev 0.454668), 0:00:00.046875, 2916
B: 972, 1, 0, 1, False, 1.000000, 485, 0.498971 (stdev 0.499742), 0:00:00, 0
A: cycle: 972
average reward: 0.707819 (stdev 0.454668)
B: cycle: 972
average reward: 0.498971 (stdev 0.499742)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 973, 0, 1, 1, False, 1.000000, 689, 0.708119 (stdev 0.454531), 0:00:00.031262, 2919
B: 973, 0, 0, 0, False, 1.000000, 485, 0.498458 (stdev 0.499742), 0:00:00, 0
A: cycle: 973
average reward: 0.708119 (stdev 0.454531)
B: cycle: 973
average reward: 0.498458 (stdev 0.499742)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 974, 1, 1, 0, False, 1.000000, 690, 0.708419 (stdev 0.454394), 0:00:00.046863, 2922
B: 974, 1, 0, 0, False, 1.000000, 485, 0.497947 (stdev 0.499741), 0:00:00, 0
A: cycle: 974
average reward: 0.708419 (stdev 0.454394)
B: cycle: 974
average reward: 0.497947 (stdev 0.499741)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 975, 0, 1, 1, False, 1.000000, 691, 0.708718 (stdev 0.454257), 0:00:00.046886, 2925
B: 975, 0, 1, 0, False, 1.000000, 486, 0.498462 (stdev 0.499739), 0:00:00, 0
A: cycle: 975
average reward: 0.708718 (stdev 0.454257)
B: cycle: 975
average reward: 0.498462 (stdev 0.499739)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 976, 1, 1, 0, False, 1.000000, 692, 0.709016 (stdev 0.454120), 0:00:00.046875, 2928
B: 976, 1, 0, 0, False, 1.000000, 486, 0.497951 (stdev 0.499741), 0:00:00, 0
A: cycle: 976
average reward: 0.709016 (stdev 0.454120)
B: cycle: 976
average reward: 0.497951 (stdev 0.499741)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 977, 0, 1, 1, False, 1.000000, 693, 0.709314 (stdev 0.453983), 0:00:00.046863, 2931
B: 977, 0, 1, 1, False, 1.000000, 487, 0.498465 (stdev 0.499740), 0:00:00, 0
A: cycle: 977
average reward: 0.709314 (stdev 0.453983)
B: cycle: 977
average reward: 0.498465 (stdev 0.499740)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 978, 1, 1, 0, False, 1.000000, 694, 0.709611 (stdev 0.453847), 0:00:00.046875, 2934
B: 978, 1, 1, 0, False, 1.000000, 488, 0.498978 (stdev 0.499742), 0:00:00, 0
A: cycle: 978
average reward: 0.709611 (stdev 0.453847)
B: cycle: 978
average reward: 0.498978 (stdev 0.499742)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 979, 0, 1, 1, False, 1.000000, 695, 0.709908 (stdev 0.453710), 0:00:00.031250, 2937
B: 979, 0, 1, 1, False, 1.000000, 489, 0.499489 (stdev 0.499744), 0:00:00, 0
A: cycle: 979
average reward: 0.709908 (stdev 0.453710)
B: cycle: 979
average reward: 0.499489 (stdev 0.499744)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 980, 1, 1, 1, False, 1.000000, 696, 0.710204 (stdev 0.453573), 0:00:00.046887, 2940
B: 980, 1, 1, 1, False, 1.000000, 490, 0.500000 (stdev 0.499745), 0:00:00, 0
A: cycle: 980
average reward: 0.710204 (stdev 0.453573)
B: cycle: 980
average reward: 0.500000 (stdev 0.499745)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 981, 0, 0, 1, False, 1.000000, 696, 0.709480 (stdev 0.453436), 0:00:00.046879, 2943
B: 981, 0, 0, 1, False, 1.000000, 490, 0.499490 (stdev 0.499745), 0:00:00, 0
A: cycle: 981
average reward: 0.709480 (stdev 0.453436)
B: cycle: 981
average reward: 0.499490 (stdev 0.499745)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 982, 1, 1, 0, False, 1.000000, 697, 0.709776 (stdev 0.453771), 0:00:00.046872, 2946
B: 982, 1, 1, 0, False, 1.000000, 491, 0.500000 (stdev 0.499745), 0:00:00, 0
A: cycle: 982
average reward: 0.709776 (stdev 0.453771)
B: cycle: 982
average reward: 0.500000 (stdev 0.499745)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 983, 0, 1, 1, False, 1.000000, 698, 0.710071 (stdev 0.453635), 0:00:00.046873, 2949
B: 983, 0, 1, 0, False, 1.000000, 492, 0.500509 (stdev 0.499746), 0:00:00, 0
A: cycle: 983
average reward: 0.710071 (stdev 0.453635)
B: cycle: 983
average reward: 0.500509 (stdev 0.499746)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 984, 1, 1, 1, False, 1.000000, 699, 0.710366 (stdev 0.453498), 0:00:00.046875, 2952
B: 984, 1, 0, 1, False, 1.000000, 492, 0.500000 (stdev 0.499746), 0:00:00, 0
A: cycle: 984
average reward: 0.710366 (stdev 0.453498)
B: cycle: 984
average reward: 0.500000 (stdev 0.499746)
A: action = high, observation = low, reward = wrong (0)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 985, 0, 0, 1, False, 1.000000, 699, 0.709645 (stdev 0.453362), 0:00:00.031251, 2955
B: 985, 0, 0, 1, False, 1.000000, 492, 0.499492 (stdev 0.499746), 0:00:00, 0
A: cycle: 985
average reward: 0.709645 (stdev 0.453362)
B: cycle: 985
average reward: 0.499492 (stdev 0.499746)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 986, 1, 1, 0, False, 1.000000, 700, 0.709939 (stdev 0.453696), 0:00:00.031243, 2958
B: 986, 1, 1, 1, False, 1.000000, 493, 0.500000 (stdev 0.499746), 0:00:00, 0
A: cycle: 986
average reward: 0.709939 (stdev 0.453696)
B: cycle: 986
average reward: 0.500000 (stdev 0.499746)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 987, 0, 1, 1, False, 1.000000, 701, 0.710233 (stdev 0.453560), 0:00:00.046875, 2961
B: 987, 0, 0, 1, False, 1.000000, 493, 0.499493 (stdev 0.499747), 0:00:00, 0
A: cycle: 987
average reward: 0.710233 (stdev 0.453560)
B: cycle: 987
average reward: 0.499493 (stdev 0.499747)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 988, 1, 1, 0, False, 1.000000, 702, 0.710526 (stdev 0.453424), 0:00:00.046875, 2964
B: 988, 1, 1, 1, False, 1.000000, 494, 0.500000 (stdev 0.499747), 0:00:00, 0
A: cycle: 988
average reward: 0.710526 (stdev 0.453424)
B: cycle: 988
average reward: 0.500000 (stdev 0.499747)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 989, 0, 1, 1, False, 1.000000, 703, 0.710819 (stdev 0.453289), 0:00:00.046875, 2967
B: 989, 0, 0, 1, False, 1.000000, 494, 0.499494 (stdev 0.499747), 0:00:00, 0
A: cycle: 989
average reward: 0.710819 (stdev 0.453289)
B: cycle: 989
average reward: 0.499494 (stdev 0.499747)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 990, 1, 1, 0, False, 1.000000, 704, 0.711111 (stdev 0.453153), 0:00:00.046875, 2970
B: 990, 1, 1, 0, False, 1.000000, 495, 0.500000 (stdev 0.499747), 0:00:00, 0
A: cycle: 990
average reward: 0.711111 (stdev 0.453153)
B: cycle: 990
average reward: 0.500000 (stdev 0.499747)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 991, 0, 1, 1, False, 1.000000, 705, 0.711403 (stdev 0.453017), 0:00:00.046876, 2973
B: 991, 0, 1, 1, False, 1.000000, 496, 0.500505 (stdev 0.499748), 0:00:00, 0
A: cycle: 991
average reward: 0.711403 (stdev 0.453017)
B: cycle: 991
average reward: 0.500505 (stdev 0.499748)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 992, 1, 1, 0, False, 1.000000, 706, 0.711694 (stdev 0.452882), 0:00:00.031249, 2976
B: 992, 1, 1, 0, False, 1.000000, 497, 0.501008 (stdev 0.499748), 0:00:00, 0
A: cycle: 992
average reward: 0.711694 (stdev 0.452882)
B: cycle: 992
average reward: 0.501008 (stdev 0.499748)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 993, 0, 1, 1, False, 1.000000, 707, 0.711984 (stdev 0.452746), 0:00:00.046874, 2979
B: 993, 0, 1, 0, False, 1.000000, 498, 0.501511 (stdev 0.499747), 0:00:00, 0
A: cycle: 993
average reward: 0.711984 (stdev 0.452746)
B: cycle: 993
average reward: 0.501511 (stdev 0.499747)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 994, 1, 1, 0, False, 1.000000, 708, 0.712274 (stdev 0.452611), 0:00:00.046875, 2982
B: 994, 1, 0, 1, False, 1.000000, 498, 0.501006 (stdev 0.499746), 0:00:00, 0
A: cycle: 994
average reward: 0.712274 (stdev 0.452611)
B: cycle: 994
average reward: 0.501006 (stdev 0.499746)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 995, 0, 1, 1, False, 1.000000, 709, 0.712563 (stdev 0.452475), 0:00:00.046863, 2985
B: 995, 0, 0, 0, False, 1.000000, 498, 0.500503 (stdev 0.499748), 0:00:00, 0
A: cycle: 995
average reward: 0.712563 (stdev 0.452475)
B: cycle: 995
average reward: 0.500503 (stdev 0.499748)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 996, 1, 1, 0, False, 1.000000, 710, 0.712851 (stdev 0.452340), 0:00:00.046875, 2988
B: 996, 1, 0, 0, False, 1.000000, 498, 0.500000 (stdev 0.499749), 0:00:00, 0
A: cycle: 996
average reward: 0.712851 (stdev 0.452340)
B: cycle: 996
average reward: 0.500000 (stdev 0.499749)
A: action = low, observation = low, reward = right! (1)
B: action = low, observation = low, reward = right! (1)
Agent is trying to choose the best action, which may take some time...
A: 997, 0, 1, 1, False, 1.000000, 711, 0.713139 (stdev 0.452205), 0:00:00.046887, 2991
B: 997, 0, 1, 0, False, 1.000000, 499, 0.500502 (stdev 0.499749), 0:00:00, 0
A: cycle: 997
average reward: 0.713139 (stdev 0.452205)
B: cycle: 997
average reward: 0.500502 (stdev 0.499749)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 998, 1, 1, 0, False, 1.000000, 712, 0.713427 (stdev 0.452069), 0:00:00.031250, 2994
B: 998, 1, 0, 1, False, 1.000000, 499, 0.500000 (stdev 0.499749), 0:00:00, 0
A: cycle: 998
average reward: 0.713427 (stdev 0.452069)
B: cycle: 998
average reward: 0.500000 (stdev 0.499749)
A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 999, 0, 1, 1, False, 1.000000, 713, 0.713714 (stdev 0.451934), 0:00:00.046876, 2997
B: 999, 0, 0, 0, False, 1.000000, 499, 0.499499 (stdev 0.499750), 0:00:00, 0
A: cycle: 999
average reward: 0.713714 (stdev 0.451934)
B: cycle: 999
average reward: 0.499499 (stdev 0.499750)
A: action = high, observation = high, reward = right! (1)
B: action = low, observation = high, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 1000, 1, 1, 0, False, 1.000000, 714, 0.714000 (stdev 0.451799), 0:00:00.046873, 3000
B: 1000, 1, 0, 1, False, 1.000000, 499, 0.499000 (stdev 0.499750), 0:00:00, 0
A: cycle: 1000
average reward: 0.714000 (stdev 0.451799)
B: cycle: 1000
average reward: 0.499000 (stdev 0.499750)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1
1
0
1
0
0
0
0
0
0
1
0
1
1
0
0
1
0
0
1
1
1
0
0
1
0
0
1
1
1
0
1
0
0
1
1
1
1
1
1
0
0
1
1
1
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
0
1
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
1
0
1
1
1
1
0
1
0
1
1
1
1
0
1
1
1
0
1
1
0
0
1
0
0
0
0
0
1
0
1
0
0
0
0
1
0
1
0
1
1
0
1
1
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
1
1
0
0
1
0
1
0
1
1
1
1
0
0
0
1
0
0
0



A: action = low, observation = low, reward = right! (1)
B: action = high, observation = low, reward = wrong (0)
Agent is trying to choose the best action, which may take some time...
A: 1001, 0, 1, 1, False, 1.000000, 715, 0.714286 (stdev 0.451664), 0:00:00.046864, 3003
B: 1001, 0, 0, 1, False, 1.000000, 499, 0.498501 (stdev 0.499749), 0:00:00, 0
A: cycle: 1001
average reward: 0.714286 (stdev 0.451664)
B: cycle: 1001
average reward: 0.498501 (stdev 0.499749)
A: action = high, observation = high, reward = right! (1)
B: action = high, observation = high, reward = right! (1)
A: SUMMARY:
agent age: 1001
average reward: 0.714286 (stdev 0.451664)
B: SUMMARY:
agent age: 1001
average reward: 0.498501 (stdev 0.499749)

Statistical summary for gathered reward data:

0
1
0
0
0
1
0
1
0
0
0
1
0
0
1
0
1
1
1
1
0
1
0
0
1
1
0
1
0
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
1
0
0
1
0
1
1
1
0
0
1
1
1
1
1
0
0
1
0
0
1
1
1
1
1
0
1
0
0
0
1
1
1
1
0
0
0
1
0
1
1
1
1
0
1
0
1
0
1
0
0
0
1
1
0
0
1
0
0
1
1
1
1
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
1
0
1
0
0
0
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
0
0
0
1
0
1
0
0
1
1
0
1
0
0
0
0
1
0
0
0
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
0
1
0
0
0
1
1
0
0
1
1
0
0
1
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
0
0
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
0
0
0
1
0
0
1
0
1
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
0
0
1
0
1
1
1
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
0
1
0
0
1
1
1
1
1
0
1
1
0
0
0
0
1
0
0
0
1
0
0
1
1
0
1
0
1
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
0
1
1
1
1
1
0
1
0
0
0
1
1
0
0
1
0
0
0
0
1
1
1
1
0
0
1
0
0
1
1
0
1
1
0
1
0
0
1
0
0
0
1
1
1
0
1
0
0
0
0
1
1
0
1
1
0
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
1
0
1
1
1
1
1
0
0
0
0
1
1
0
1
0
0
1
0
0
0
1
0
0
0
0
1
0
1
1
0
0
0
1
1
0
1
1
0
1
0
1
1
1
0
1
0
0
1
1
0
1
0
1
0
0
1
1
0
0
0
0
1
0
1
0
1
1
0
1
0
1
1
0
0
0
1
0
1
0
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
0
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
0
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
0
1
0
1
1
1
1
1
0
1
0
1
0
1
1
0
1
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
1
0
1
0
1
1
1
0
1
0
0
0
1
1
1
0
0
1
1
1
0
1
0
0
1
0
1
1
1
0
1
1
1
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
1
1
1
0
0
1
1
1
0
1
1
1
1
0
0
1
0
1
1
1
1
1
0
0
0
0
0
0
1
0
0
0
1
1
0
1
1
1
0
0
1
1
0
0
1
0
1
0
0
1
0
1
1
1
1
1
0
1
1
0
1
0
1
1
0
1
1
1
1
1
0
0
1
0
1
1
0
1
0
0
0
1
0
1
0
1
1
1
1
0
1
0
0
0
0
1
0
1
0
0
1
0
1
0
0
1
0
1
0
0
1
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
1
1
0
1
0
0
1
0
1
0
1
0
0
1
1
0
1
1
1
1
0
1
0
1
1
1
1
1
1
1
0
0
0
1
0
1
1
1
0
1
1
1
0
1
0
1
0
0
1
0
0
1
0
1
1
1
0
0
1
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
1
0
1
1
1
0
0
1
1
1
1
0
1
0
0
1
0
0
1
0
0
0
0
0
0
1
1
1
0
1
1
0
1
1
1
1
0
1
0
1
1
0
0
0
1
0
1
1
1
0
0
1
1
0
0
0
1
0
0
1
1
0
0
1
1
1
0
0
1
1
0
1
0
1
1
0
0
1
0
1
1
0
1
1
1
0
0
0
1
1
1
0
0
1
1
0
1
0
0
0
0
0
0
1
1
1
0
0
1
0
0
1
1
1
0
0
0
0
1
1
1
1
1
1
0
1
1
0
1
1
1
0
1
1
0
0
0
0
1
1
1
0
1
0
1
1
1
1
1
0
0
1
1
1
0
0
1
0
1
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
0
0
0
1
1
0
1
1
0
0
1
0
0
0
0
1
1
0
1
0
0
1
1
1
0
0
0
1
1
0
1
1
0
0
1
1
1
0
1
1
1
1
0
1
1
1
1
0
1
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
0
1
0
0
1
1
0
0
1
1
1
1
1
1
0
0
0
0
0
1
0
1
1
1
1
0
1
0
0
1
0
1
1
0
0
1
0
0
1
1
0
0
1
1
0
1
1
1
0
1
1
1
0
0
1
0
0
0
0
1
1
1
0
0
0
1
0
0
0
0
1
0
0
1
1
1
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
1
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
0
1
1
1
0
1
1
1
0
1
1
0
0
1
1
1
1
0
0
0
1
0
1
0
1
1
1
1
0
0
1
0
0
0
0
0
0
0
0
0
1
1
1
1
1
0
1
0
1
1
0
1
1
1
1
0
1
1
0
1
0
0
0
0
0
0
1
0
1
1
0
0
1
0
0
1
1
1
0
0
1
0
0
1
1
1
0
1
0
0
1
1
1
1
1
1
0
0
1
1
1
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
1
1
1
1
0
0
1
1
0
0
1
0
1
0
1
0
0
0
0
1
1
0
0
0
0
0
0
0
1
1
0
1
0
0
1
0
1
1
0
1
0
1
0
1
1
1
0
1
0
1
1
1
1
0
1
0
1
1
1
1
0
1
1
1
0
1
1
0
0
1
0
0
0
0
0
1
0
1
0
0
0
0
1
0
1
0
1
1
0
1
1
1
0
0
1
0
0
1
0
0
0
0
1
0
1
0
0
0
0
0
0
0
0
1
0
1
1
1
1
0
1
1
0
0
1
0
1
0
1
1
1
1
0
0
0
1
0
0
0
0



