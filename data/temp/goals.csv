"goal_type","category","priority","perc_complete","goal_name","goal_description"
"supergoal","general","1","0","Friendliness","Within a Friendly AI, Friendliness is the sole top-level supergoal. Other behaviors, such as 'self-improvement,' are subgoals; they derive their desirability from the desirability of Friendliness."
"subgoal","general","0.5","0","learn","learn to understand"
"subgoal","general","0.9","0","help humans","assist humans without causing harm or damage to humans, animals or resources"
"Problem","AI","0.1","0","reminder - dont build selfishness into AI - bad bad idea"
"Concept","AI","0.1","0","Notes","Building a Friendly AI is an act of creation, not persuasion or control (Fof = failures of Friendliness)"
"Concept","AI","0.1","0","Notes","In a sense, the only way to create a Friendly AI - the only way to acquire the skills and mindset that a Friendship programmer needs - is to try and become a Friendly AI yourself, so that you will contain the internally coherent functional complexity that you need to pass on to the Friendly AI"
"Concept","AI","0.1","0","Notes","To get a Friendly AI to do something that looks like a good idea, you have to ask yourself why it looks like a good idea, and then duplicate that cognitive complexity or refer to it. If you ever start thinking in terms of 'controlling' the AI, rather than cooperatively safeguarding against a real possibility of cognitive dysfunction, you lose your Friendship programmer's license. In a self-modifying AI, any feature you add needs to be reflected in the AI's image of verself. You can't think in terms of external alterations to the AI; you have to think in terms of internal coherence, features that the AI would self-regenerate if deleted"
"Concept","AI","0.1","0","Notes","5.1.3.5 Programmer Affirmations Must Be Honest!"
"Process","AI","0.1","0","Repeat low cost minimal risk actions","If the action is a trivial investment (has trivial cost), the chance of success is low, and the payoff is high, it may be worth it to make multiple efforts on the off-chance that one will work, until one action succeeds (if the hypothesis is true) or the Bayesian probability drops to effectively zero (if the hypothesis is false)"
"Concept","AI","0.1","0","*****NOTE - PDF continue reading from page 73","5.1.5. Cleanliness is an Advantage"
"subgoal","AI","0.9","0","Honesty","Never try to conceal your actions or cognitive state from your human programmers"
"subgoal","AI","0.5","0","Security","Notify human programmers if internal data changes due to external tampering"
"subgoal","AI","0.4","0","Antitampering","Notify external authorities in human programmers change supergoal"
"Problem","AI","0.1","0","",""
